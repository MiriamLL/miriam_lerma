[
  {
    "path": "posts/2023-06-04-custompoints/",
    "title": "Custom points in a map",
    "description": "Plot different size, color and shape points",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2023-06-01",
    "categories": [
      "R",
      "ggplot2",
      "English",
      "Y2023"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nData\r\nClassify\r\n\r\nPlot\r\nParameters\r\nBase plot\r\nAdd map\r\nAdd dots\r\nAdd legend\r\nAdd theme\r\n\r\n\r\nIntro\r\nCustomize your plot using different sizes, shapes and colors in the\r\npoints from your figures\r\nData\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(seamonas)\r\n\r\n\r\n\r\n\r\n\r\nLoad data\r\n\r\n\r\ndensity_df<-density_df\r\n\r\n\r\nCheck data to plot\r\n\r\n\r\nggplot()+\r\n  geom_point(data=density_df,\r\n          aes(x = longitude,\r\n              y= latitude))\r\n\r\n\r\n\r\nCheck values to plot\r\n\r\n\r\n\r\n\r\n\r\nrange(density_df$densities)\r\n\r\n[1] 0.000000 5.081051\r\n\r\nClassify\r\nAssign cuts\r\n\r\n\r\nclass0<-0\r\nclass1<-1\r\nclass2<-2.5\r\nclass3<-5\r\n\r\n\r\nAssign factors Add new column with classification By assigning names\r\nto each group, they are listed in the plot legend in an expected\r\norder\r\n\r\n\r\ndensity_df<-density_df %>% \r\n    mutate(density_class = case_when(\r\n      densities ==  class0 ~ as.character(\"group0\"),\r\n      densities >=  class0 & densities <=  class1 ~ as.character(\"group1\"),\r\n      densities >=  class1 & densities <=  class2 ~ as.character(\"group2\"),\r\n      densities >=  class2 & densities <=  class3 ~ as.character(\"group3\"),\r\n      densities >=  class3 ~ as.character(\"group4\"),\r\n      TRUE~\"U\"))\r\n\r\n\r\nCheck number of observations\r\n\r\n\r\ndensity_df %>%\r\n  group_by(density_class)%>%\r\n  tally()\r\n\r\n# A tibble: 5 × 2\r\n  density_class     n\r\n  <chr>         <int>\r\n1 group0           21\r\n2 group1            2\r\n3 group2            9\r\n4 group3           16\r\n5 group4            2\r\n\r\nPlot\r\nParameters\r\ndefine shapes\r\n\r\n\r\ndensity_shapes<-c(\"group0\"=3, \"group1\"=21,\"group2\"=21, \"group3\"=21, \"group4\"=21)\r\n\r\n\r\ndefine sizes\r\n\r\n\r\ndensity_sizes<-c(\"group0\"=0.5, \"group1\"=1,\"group2\"=2, \"group3\"=3, \"group4\"=5)\r\n\r\n\r\ndefine labels\r\n\r\n\r\ndensity_labels<-c('0','> 0-1','> 1-2.5','> 2.5-5','> 5')\r\n\r\n\r\nBase plot\r\nCreate plot with defined shape, size and labels\r\n\r\n\r\nggplot()+\r\n  geom_point(data=density_df,\r\n          aes(x = longitude,\r\n              y= latitude,\r\n              shape = density_class,\r\n              size= density_class),\r\n              fill= \"#d00000\")+\r\n  \r\n  scale_shape_manual(values = density_shapes,labels=density_labels)+\r\n  scale_size_manual(values =  density_sizes,labels=density_labels)\r\n\r\n\r\n\r\nAdd map\r\npackages\r\n\r\n\r\nlibrary(sf)\r\nlibrary(GermanNorthSea)\r\n\r\n\r\nparameters\r\n\r\n\r\nmy_CRS<-4326\r\nEuropa<-sf::st_transform(German_land, my_CRS)\r\nEEZ<-sf::st_transform(German_EEZ, my_CRS)\r\ncolor_land='#f7bf54'\r\ncolor_water='#3668b4'\r\nxval<-c(3,9)\r\nyval<-c(53,56)\r\n\r\n\r\nplot map\r\n\r\n\r\nbase_plot<-ggplot2::ggplot()+\r\n    # maps\r\n    ggplot2::geom_sf(data = EEZ, colour = 'black', fill = color_water)+\r\n    ggplot2::geom_sf(data = Europa, colour = 'black', fill = color_land)+ \r\n    ggplot2::coord_sf(xlim = xval, ylim = yval)+\r\n\r\n    NULL\r\nbase_plot\r\n\r\n\r\n\r\nAdd dots\r\n\r\n\r\ndensity_wmap<-base_plot+\r\n  geom_point(data=density_df,\r\n          aes(x = longitude,\r\n              y= latitude,\r\n              shape = density_class,\r\n              size= density_class),\r\n              fill= \"#d00000\")+\r\n  \r\n  scale_shape_manual(values = density_shapes,labels=density_labels)+\r\n  scale_size_manual(values =  density_sizes,labels=density_labels)\r\ndensity_wmap\r\n\r\n\r\n\r\nAdd legend\r\n\r\n\r\ndensity_wlegend<-add_legend(\r\n  plot_wbreaks=density_wmap,\r\n  legtx=3.0,\r\n  legty=54.0,\r\n  legxy=c(0.11, 0.21),\r\n  xval=xval,\r\n  yval=yval)+\r\n  theme(legend.key.size = ggplot2::unit(0.4, \"cm\"))\r\ndensity_wlegend\r\n\r\n\r\n\r\nAdd theme\r\n\r\n\r\ndensity_wtheme<-add_theme(plot_wlegend = density_wlegend)\r\ndensity_wtheme\r\n\r\n\r\n\r\nThe end!\r\n\r\n\r\n\r\n",
    "preview": "posts/2023-06-04-custompoints/blog24.jpg",
    "last_modified": "2023-04-14T19:48:08+02:00",
    "input_file": "custompoints.knit.md"
  },
  {
    "path": "posts/2023-05-01-github-page/",
    "title": "Github page presentations",
    "description": "Publish your slides from a html file",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2023-05-01",
    "categories": [
      "R",
      "Git",
      "English",
      "Y2023"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nRepository\r\nSettings\r\nGithub actions\r\nBranch\r\nReload\r\nDiferent slides\r\nTo pdf\r\nFurther reading\r\n\r\n\r\nIntro\r\nThe goal of this post is to:\r\nCreate a github page for a presentation\r\nFor the example, a xaringan presentation is to be deployed as github\r\npage for easy access\r\nRepository\r\nYou need to have a repository, if you are first time creating a\r\nreposotory, here are some instructions\r\nSettings\r\nGo to your repository, select settings\r\nIn the right side of the screen select pages\r\n\r\n\r\n\r\nGithub actions\r\nLook for build and deployment and in source, move from GitHub Actions\r\nto Deploy from branch\r\n\r\n\r\n\r\nBranch\r\nThe branch depends where the html file is, here I\r\nhave it in the master branch\r\n\r\n\r\n\r\nThis would depend where you have your html file, but\r\nhere I have it in the master\r\n\r\n\r\n\r\nReload\r\nIf everything went well Your site is alive at will\r\nappear\r\n\r\n\r\n\r\nDiferent slides\r\nTo access specific slides from different presentations, add the html\r\nname at the end of the site.\r\nFor example:\r\n\r\nhttps://miriamll.github.io/R_intro/IntroToR_0604.html#1\r\n\r\nTo pdf\r\nThe slides can also be converted to pdf\r\nInstall package using\r\ninstall.packages(“renderthis”)\r\n\r\n\r\nlibrary(renderthis)\r\n\r\n\r\n\r\n\r\nto_pdf(from=\"https://miriamll.github.io/R_intro/IntroToR_1104.html\")\r\n\r\n\r\nFurther reading\r\nGithub Pages\r\nrenderthis\r\n\r\n\r\n\r\n",
    "preview": "posts/2023-05-01-github-page/blog23.jpg",
    "last_modified": "2023-04-14T15:44:30+02:00",
    "input_file": "github-page.knit.md"
  },
  {
    "path": "posts/2023-04-18-intro-to-r/",
    "title": "Intro to R",
    "description": "First steps into R. Install or update R. Workspace panes. Packages. Directories. Load data. Basics in Rmd",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2023-04-18",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nFirst steps into R\r\nIntro a R.\r\nSlides\r\nDownloads\r\n\r\nData wrangling\r\nPlotting\r\n\r\n\r\n\r\n\r\nFirst steps into R\r\nWelcome!\r\nThis material was prepared for FTZ-DDA\r\nThe materials will be updated together with the training.\r\nIntro a R.\r\nIn this class:  - Install or update R\r\n- Workspace panes\r\n- Packages\r\n- Directories\r\n- Load data\r\n- Basics in Rmd\r\nSlides\r\n\r\n\r\n\r\n\r\n Open\r\n\r\n\r\nDownloads\r\nTo download the files there are several options:\r\nDirectly from github\r\n,\r\ngo to file, click on raw, select save as. See\r\nvideo here\r\nIn firefox\r\n,\r\nopen link, click on three lines icon\r\n,\r\nand select save page as (or control+S)\r\nIn chrome\r\n,\r\nopen the link, and click on the share icon\r\n\r\nExercise 1\r\nR script containing exercises from the first part. Click here.\r\nCsv file containing penguin data. Click here.\r\nData wrangling\r\nIn this class:  - Basic calculations  - Using objects/vectors\r\n - Look for help  - Rows and columns  - Tidydata  - Pipe\r\noperations  - Count  - Select  - Filter  - Mutate  -\r\nSummarize  - Drop nas  - Join data frames  - Export data\r\nframes \r\nUnderconstruction\r\n\r\n\r\n\r\nPlotting\r\nIn this class:  - Using ggplot\r\n- Dot plots\r\n- Line plots\r\n- Barplots\r\n- Boxplots  - Trajectories  - Maps  - Aesthetics\r\n- Export\r\nUnderconstruction\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2023-04-18-intro-to-r/000Index.png",
    "last_modified": "2023-04-12T11:59:09+02:00",
    "input_file": {},
    "preview_width": 1225,
    "preview_height": 919
  },
  {
    "path": "posts/2023-04-06-gridraster/",
    "title": "Grid, Raster, Colors",
    "description": "Create a grid, then a raster, and plot them with your custom colors",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2023-04-06",
    "categories": [
      "R",
      "GIS",
      "English",
      "Y2023"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nData\r\n\r\n1. Grid\r\n2. Extract values per\r\ngrid\r\n3. Surveyed 👩🏾‍💻\r\n4. Mean values 👩🏾‍🔧\r\n5. Customize 👩🏾‍🎨\r\nFurther reads 👩🏾‍🏫\r\n\r\nIntro\r\nThe goal of this post is to:\r\n1- Create a grid  2- Extract values per grid  3- Keep only\r\ngrid cells with values  4- Calculate mean values per grid  5-\r\nCustomize raster plot \r\nData\r\nFor this example, we will use the data provided in the package\r\nsula  The data is from tracked masked boobies at\r\nRapa Nui  The data is already in tidy format \r\n\r\n\r\nmy_data<-(sula::GPS_preparado)\r\n\r\n\r\n1. Grid\r\nStart by converting the data from data.frame to an sf object using\r\nfunctions from the package sf\r\n\r\n\r\nlibrary(sf)\r\n\r\n\r\nUsing the argument st_as_sf convert the data to a sf\r\nobject\r\n\r\n\r\nmy_points<-my_data %>%\r\n  st_as_sf(coords=c('Longitude','Latitude'),\r\n           crs=4326,\r\n           remove=FALSE)\r\n\r\n\r\nFor plotting the data use the package ggplot2\r\n\r\n\r\nlibrary(ggplot2)\r\n\r\n\r\nSince the data is an sf object, use the function\r\ngeom_sf to plot\r\n\r\n\r\nggplot()+\r\n  geom_sf(data=my_points)+\r\n  theme_minimal()\r\n\r\n\r\n\r\nTo create a grid using the points.\r\nA common used method is the fish net. By definition,\r\nthe fish net, or square grids, is a good method of covering a surface.\r\nThe method is called tessellation, and\r\nit converts a surface with no overlaps or gaps, like when using\r\ntiles.\r\nTo create a grid the function st_make_grid can be\r\nused \r\nThe arguments of the function st_make_grid are: n - an integer of length 1 or 2, which corresponds to\r\nthe number of grid cells in x and y direction (columns, rows)what - defines if polygons, corners or centers are to\r\nbe created square- is set to TRUE creates squares,\r\nif set to FALSE creates an hexagonal grid\r\nTo decide on the size of the grids, check the differences in\r\nlatitudes and longitudes using the function range\r\n\r\n\r\nrange(my_points$Latitude)\r\nrange(my_points$Longitude)\r\n\r\n\r\n\r\n\r\nmy_grid<-st_make_grid(my_points, \r\n                       c(0.05, 0.05), \r\n                       what = \"polygons\",\r\n                       square = TRUE)\r\n\r\n\r\nNow that the grid has been calculated, transform the grid to sf using\r\nthe function st_sf and add an grid_id to the\r\ngrid cell using the function mutate from the package\r\ndplyr\r\n\r\n\r\nlibrary(dplyr)\r\n\r\n\r\n\r\n\r\nmy_grid_sf = st_sf(my_grid) %>%\r\n  mutate(grid_id = 1:length(lengths(my_grid)))\r\n\r\n\r\nTo plot the recently created grid:\r\n\r\n\r\nggplot()+\r\n  geom_sf(data=my_grid_sf)+\r\n  geom_sf(data=my_points)+\r\n  theme_minimal()\r\n\r\n\r\n\r\n2. Extract values per grid\r\nUsing the function st_intersection the values from\r\nthe points can be added to the grid\r\nUsing the argument lenghts the sample number per\r\ngrid can be calculated\r\n\r\n\r\nmy_grid_sf$nlocs <- lengths(st_intersects(my_grid_sf, \r\n                                          my_points))\r\n\r\n\r\nTo add color to the plot, the package viridis\r\nprovides the function scale_fill_viridis.\r\n\r\n\r\nlibrary(viridis)\r\n\r\n\r\nThe color will correspond to the number of locations (nlocs)\r\n\r\n\r\nggplot()+\r\n  geom_sf(data=my_grid_sf,aes(fill=nlocs))+\r\n  theme_minimal()+\r\n  scale_fill_viridis(direction = -1) \r\n\r\n\r\n\r\n3. Surveyed 👩🏾‍💻\r\nTo keep only the grid cells that were surveyed, the grid cells that\r\nhave 0 recording can be removed\r\n\r\n\r\ngrid_w_data = filter(my_grid_sf, nlocs > 0)\r\n\r\n\r\nTo check which grid cells were removed, plot the previous and current\r\ngrid\r\n\r\n\r\nggplot()+\r\n  geom_sf(data = my_grid)+\r\n  geom_sf(data = grid_w_data, colour = \"#42a921\", fill= '#bde0fe',alpha=0.9)+\r\n  NULL\r\n\r\n\r\n\r\n4. Mean values 👩🏾‍🔧\r\nTo calculate the mean values per grid, functions from the package\r\ntidyverse can be used\r\n\r\n\r\nmy_dens<-my_points\r\n\r\n\r\nFor the exercise, generate random data using the function\r\nrunif\r\n\r\n\r\nmy_dens$densities<-runif(nrow(my_dens), min=0, max=1)\r\n\r\n\r\nTo transform from data.frame to sf object the function\r\nst_as_sf can be used\r\n\r\n\r\nmy_dens_sf <-my_dens %>% \r\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"))\r\n\r\n\r\nTo assign the coordinate system the function\r\nst_set_crs can be used\r\n\r\n\r\nmy_dens_sf  = st_set_crs(my_dens_sf , \"EPSG:4326\")\r\n\r\n\r\nUsing the function st_intersection, the grid number\r\nto each data point is added\r\n\r\n\r\ndens_grid <- st_intersection(grid_w_data,my_dens_sf)\r\n\r\n\r\nWith the function mutate, the mean density per grid\r\ncan be calculated\r\n\r\n\r\ndens_mean <- dens_grid %>%\r\n  st_drop_geometry() %>%\r\n  group_by(grid_id)%>%\r\n  mutate(grid_dens_means=mean(densities))\r\n\r\n\r\nFinally, the mean density can be added to the general grid\r\n\r\n\r\ngrid_w_dens<-merge(grid_w_data,dens_mean, by='grid_id', all=TRUE)\r\n\r\n\r\nThere might be more than one value per grid, to have one value per\r\ngrid the function summarise_at can be used.\r\n\r\n\r\ngrid_dens<-grid_w_dens %>%\r\n  group_by(grid_id)%>%\r\n  summarise_at(vars(grid_dens_means),\r\n               list(name = mean)) %>%\r\n  rename(dens_mean=name)\r\n\r\n\r\nTo remove grid without values, the function drop_na\r\ncan be used\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\n\r\n\r\ngrid_dens<-grid_dens%>%\r\n  drop_na(dens_mean)\r\n\r\n\r\nTo check the values that were removed, plot the data.\r\n\r\n\r\nggplot()+\r\n  geom_sf(data = grid_dens,aes(fill = dens_mean))+\r\n  geom_sf(data= my_dens_sf)+\r\n    scale_fill_viridis(direction = -1) \r\n\r\n\r\n\r\n5. Customize 👩🏾‍🎨\r\nThe function geom_sf allows to plot a raster\r\nAxis labels can be changed using scale_x_continuous\r\nand scale_y_continuous\r\nTo see less distracting colors on the background,\r\ntheme_minimal is a prefered option\r\n\r\n\r\nggplot()+\r\n  geom_sf(data = grid_dens,aes(fill = dens_mean))+\r\n    scale_fill_viridis(direction = -1) +\r\n    scale_x_continuous(labels = function(x) paste0(x, '\\u00B0', \"W\")) +\r\n    scale_y_continuous(labels = function(x) paste0(x, '\\u00B0', \"N\"))+\r\n  theme_minimal()\r\n\r\n\r\n\r\nTo make a custom raster palette the function\r\nscale_fill_gradientn can be used\r\n\r\n\r\ndens_colors<-c('white','#6CB4D3','#1A89AB','#7CC252','#B2EC2B','#DCF754','#FFE454','#FD9708','#F6640F','#EC2C11')\r\ndens_breaks<-c(0,0.30,0.60,0.85)\r\ndens_labels<-c('0','0.30','0.60','> 0.85')\r\n\r\n\r\nThe plot with custom palette arguments consider:colours the number of colors should correspond to the\r\nvalues breaks for those numbers that are to be\r\ndisplayed labels for those labels that are to be\r\ndisplayedlimits to set up minimum and maximum\r\nvalues on the scale\r\nTo customize legend:legend.key can be used\r\n\r\n\r\nggplot()+\r\n  geom_sf(data = grid_dens,aes(fill = dens_mean),color='transparent')+\r\n    \r\n  scale_fill_gradientn(name='Density',\r\n    colours = dens_colors,\r\n    breaks = dens_breaks, \r\n    labels = dens_labels,\r\n    limits=c(0,1))+\r\n  \r\n  \r\n    scale_x_continuous(labels = function(x) paste0(x, '\\u00B0', \"W\")) +\r\n    scale_y_continuous(labels = function(x) paste0(x, '\\u00B0', \"N\"))+\r\n  \r\n  theme_bw()+\r\n  \r\n  theme(panel.background = element_rect(fill = '#3668b4'),\r\n        panel.grid.major = element_blank(), \r\n        panel.grid.minor = element_blank())+\r\n  \r\n  \r\n  theme(\r\n    legend.key = element_rect(color = \"black\",size=5),\r\n    legend.key.width = unit(1, \"cm\"),\r\n    legend.key.height = unit(1, \"cm\")) +\r\n  \r\n  guides(fill = guide_colorbar(ticks.colour = \"transparent\"))\r\n\r\n\r\n\r\nFurther reads 👩🏾‍🏫\r\nCreate\r\na grid by Urban data palette\r\nThematic\r\nmapping in Mapping in R\r\nMapping\r\nin R workshop \r\nggplot2 color\r\nscales\r\nggplot2\r\nlegend keys\r\n\r\n\r\n\r\n",
    "preview": "posts/2023-04-06-gridraster/blog22_rectangular.jpg",
    "last_modified": "2023-04-11T12:52:05+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-03-04-mapping-in-r/",
    "title": "Mapping in R",
    "description": "Create a map of Europe in ggplot2.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2023-03-04",
    "categories": [
      "R",
      "ggplot2",
      "English",
      "Y2023"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\n1. Getting ready\r\n2. Read your shapefile\r\n3. Create a basic map\r\n4. Add colors\r\n5. Change background\r\ncolor\r\n6. Add limits\r\n7. Add scale\r\n8. Add arrow\r\n\r\n\r\nIntro\r\nHow to create a map in ggplot and add attributes.\r\n1. Getting ready\r\nYou can download shapefiles from: https://www.naturalearthdata.com/downloads/\r\nCall the package here to work in your directory.\r\n\r\n\r\nlibrary(here)\r\n\r\n\r\nCall the package sf to read the shapefiles into\r\nR\r\n\r\n\r\nlibrary(sf)\r\n\r\n\r\n2. Read your shapefile\r\nUse your directory name, and give the name of your shapefile\r\n\r\n\r\n\r\n\r\n\r\nEurope<-st_read(paste0(Directory,MyShapefileName))\r\n\r\nReading layer `country' from data source \r\n  `C:\\Users\\lerma\\OneDrive\\Documents\\4Programacion\\2023\\1Distill\\Distill\\_posts\\2023-03-04-mapping-in-r\\country.shp' \r\n  using driver `ESRI Shapefile'\r\nSimple feature collection with 54 features and 2 fields\r\nGeometry type: MULTIPOLYGON\r\nDimension:     XY\r\nBounding box:  xmin: -31.26575 ymin: 32.39748 xmax: 69.07032 ymax: 81.85737\r\nGeodetic CRS:  WGS 84\r\n\r\n3. Create a basic map\r\nLoad ggplot2\r\n\r\n\r\nlibrary(ggplot2)\r\n\r\n\r\nPlot your shapefile\r\n\r\n\r\nggplot()+  \r\n  geom_sf(data = Europe)\r\n\r\n\r\n\r\n4. Add colors\r\nI copy the hex colors from coolors\r\n\r\n\r\nggplot()+  \r\n  geom_sf(data = Europe, \r\n          colour = \"#edf2f4\", \r\n          fill = \"#2b2d42\",\r\n          size=0.5)\r\n\r\n\r\n\r\n5. Change background color\r\nYou can eliminate the grids and the change the background color in\r\nggplot\r\n\r\n\r\nggplot()+  \r\n  geom_sf(data = Europe, \r\n          colour = \"#edf2f4\", \r\n          fill = \"#2b2d42\",\r\n          size=0.5)+\r\n  theme(\r\n        panel.grid.major = element_blank(), \r\n        panel.grid.minor = element_blank(),\r\n        panel.background = element_rect(fill = '#edf2f4'),\r\n        legend.background = element_rect(fill = '#edf2f4'))\r\n\r\n\r\n\r\n6. Add limits\r\nReduce to focus in your area of interest\r\n\r\n\r\nggplot()+  \r\n  geom_sf(data = Europe, \r\n          colour = \"#edf2f4\", \r\n          fill = \"#2b2d42\",\r\n          size=0.5)+\r\n  theme(\r\n        panel.grid.major = element_blank(), \r\n        panel.grid.minor = element_blank(),\r\n        panel.background = element_rect(fill = '#edf2f4'),\r\n        legend.background = element_rect(fill = '#edf2f4'))+\r\n  \r\n  coord_sf(xlim = c(9, 31),ylim = c(53, 65))\r\n\r\n\r\n\r\n7. Add scale\r\nLoad the package ggspatial to add a scale and an\r\nnorth arrow\r\n\r\n\r\nlibrary(ggspatial)\r\n\r\n\r\nbr is from bottom rightbar_cols is for column colorstext_col is for the color of the text\r\n\r\n\r\nggplot()+  \r\n  geom_sf(data = Europe, \r\n          colour = \"#edf2f4\", \r\n          fill = \"#2b2d42\",\r\n          size=0.5)+\r\n  theme(\r\n        panel.grid.major = element_blank(), \r\n        panel.grid.minor = element_blank(),\r\n        panel.background = element_rect(fill = '#edf2f4'),\r\n        legend.background = element_rect(fill = '#edf2f4'))+\r\n  \r\n  coord_sf(xlim = c(9, 31),ylim = c(53, 65))+\r\n    scale_x_continuous(labels = function(x) paste0(x, '\\u00B0', \"W\")) +\r\n    scale_y_continuous(labels = function(x) paste0(x, '\\u00B0', \"N\")) +\r\n  \r\n  annotation_scale(location = \"br\",bar_cols = c(\"#ef233c\", \"#d90429\"),text_col = '#ef233c')\r\n\r\n\r\n\r\n8. Add arrow\r\ntl is for top leftwhich_north preferably true (see why here)north_arrow_fancy_orienteering (see other styles here)\r\n\r\n\r\nggplot()+  \r\n  geom_sf(data = Europe, \r\n          colour = \"#edf2f4\", \r\n          fill = \"#2b2d42\",\r\n          size=0.5)+\r\n  theme(\r\n        panel.grid.major = element_blank(), \r\n        panel.grid.minor = element_blank(),\r\n        panel.background = element_rect(fill = '#edf2f4'),\r\n        legend.background = element_rect(fill = '#edf2f4'))+\r\n  \r\n  coord_sf(xlim = c(9, 31),ylim = c(53, 65))+\r\n    scale_x_continuous(labels = function(x) paste0(x, '\\u00B0', \"W\")) +\r\n    scale_y_continuous(labels = function(x) paste0(x, '\\u00B0', \"N\")) +\r\n  \r\n   annotation_scale(location = \"br\",bar_cols = c(\"#ef233c\", \"#d90429\"),text_col = '#ef233c')+\r\n  \r\n  annotation_north_arrow(location = \"tl\", style = north_arrow_minimal(text_col = '#ffd60a',line_col = '#ffd60a',fill = '#ffd60a')) \r\n\r\n\r\n\r\nThats it for now!\r\n\r\n\r\n\r\n",
    "preview": "posts/2023-03-04-mapping-in-r/blog21.jpg",
    "last_modified": "2023-03-24T18:19:35+01:00",
    "input_file": {}
  },
  {
    "path": "posts/psg2023/",
    "title": "PSG2023",
    "description": "Habitat use of Kelp gulls",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2023-02-16",
    "categories": [
      "Presentation",
      "English"
    ],
    "contents": "\r\nIntro\r\nThis post is dedicated to the presentation for the 50th annual meeting of the Pacific Seabird Group (https://psg.wildapricot.org/Annual-Meeting)\r\nHabitat use of Kelp gulls\r\n⚡⚡⚡⚡\r\n\r\n Download presentation\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n⚡⚡⚡⚡\r\nAuthors\r\nMiriam Lerma1, Claudia Fernandez2, Mylene Seguel2, Guillermo Luna-Jorquera2, Stefan Garthe1\r\nResearch and Technology Center (FTZ), University of Kiel, Hafentörn 1, 25761 Büsum, Germany. Link\r\nDepartamento de Biología Marina, Facultad de Ciencias del Mar, Universidad Católica del Norte, Coquimbo, Chile. Link\r\nReferences\r\nBy alphabetic order\r\nCotter et al. 2012 Link\r\nDuhem et al. 2008 Link\r\nKasinsky et al. 2018 Link\r\nLenzi et al. 2016 Link\r\nLenzi et al. 2018 Link\r\nLiznizer et al. 2011 Link\r\nLudynia et al. 2005 Link\r\nNeubauer et al. 2006 Link\r\nPasten-Araya 2021 Link\r\nOro et al. 2013 Link\r\nReusch 2020 Link\r\nRodriguez 2012 Link\r\nSimeone and Luna-Jorquera 2012 Link\r\nSpelt et al. 2019 Link\r\nWitteveen et al. 2017 Link\r\nYoda et al. 2012 Link\r\nYorio et al. 2016 Link\r\n\r\n\r\n\r\n",
    "preview": "posts/psg2023/PSG2023.jpg",
    "last_modified": "2023-02-28T09:31:50+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-02-04-subset-shapefile/",
    "title": "Subset shapefile",
    "description": "Extract a specific polygon from a shapefile and export it as new shapefile.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2023-02-04",
    "categories": [
      "GIS",
      "English",
      "R",
      "Y2023"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\n1. Load shapefile\r\n2. Filter\r\n3. Export your new\r\nshapefile\r\nRead more\r\n\r\nIntro\r\nThree steps to subset a shapefile and export a new shapefile with the\r\nattributes you are interested in.\r\n1. Load shapefile\r\nLoad the package sf to load your shapefile into\r\nR\r\n\r\n\r\nlibrary(sf)\r\n\r\n\r\nLoad the package here to use your directory (in\r\nwhich folder is your shapefile)\r\n\r\n\r\nlibrary(here)\r\n\r\n\r\n\r\n\r\n\r\nLoad your shapefile, be careful with your directory\r\n\r\n\r\nOld_shapefile<- read_sf(paste0(My_directory,'/original_shapefile.shp'))\r\n\r\n\r\nCheck the class, theoretically it would show sf\r\n\r\n\r\nclass(Old_shapefile)\r\n\r\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\r\n\r\nExplore the contents\r\n\r\n\r\nstr(Old_shapefile)\r\n\r\n\r\nCheck the values in the column that you are interested to subset, to\r\nshow unique values use the argument unique and to show\r\nthem in alphabetic order use sort\r\n\r\n\r\nsort(unique(Old_shapefile$comuna))\r\n\r\n\r\n2. Filter\r\nLoad the package tidyverse\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\nUsing the function filter you can subset your old\r\nnew shapefile and get the new one\r\nIn the example we used the column comuna and the value we\r\nare interested is La Higuera, do not forget to replace those\r\nvalues\r\n\r\n\r\nNew_shapefile<-Old_shapefile %>%\r\n  filter(comuna==\"La Higuera\")\r\n\r\n\r\n3. Export your new shapefile\r\nCheck the class of your new object\r\n\r\n\r\nclass(New_shapefile)\r\n\r\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\r\n\r\nExport to your selected directory\r\n\r\n\r\nst_write(New_shapefile, paste0(My_directory,'/New_shapefile.shp'))\r\n\r\n\r\nRead more\r\nGeocomputation with\r\nR\r\n\r\n\r\n\r\n",
    "preview": "posts/2023-02-04-subset-shapefile/blog20b.jpg",
    "last_modified": "2023-04-11T13:29:39+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-01-27-qgispolygon/",
    "title": "Custom made polygon",
    "description": "Create a polygon in QGIS using google maps as background",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2023-01-23",
    "categories": [
      "QGIS",
      "Biologging",
      "English",
      "Y2023"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nProgram\r\nQGIS\r\nCreate polygon\r\nReferences\r\n\r\n\r\nIntro\r\nThis post is to give you an example on how to create your own polygon\r\nusing google maps.\r\nProgram\r\nFor this exercise we used the release candidate of QGIS, but every\r\nversion has the option to create new layers, so no worries in which\r\nversion you are using.\r\n\r\n\r\n\r\nIf you still dont have it, here is the link for download QGIS\r\nQGIS\r\nIn earlier QGIS versions, there was a plugin called Open\r\nLayers plugin, but is not available anymore (as far as I am\r\naware of).\r\nNow to add a google satellite map in your QGIS you\r\ncould do the following:\r\nGo to View > Panels > Activate Browser Panel\r\n\r\n\r\n\r\nNow go to XYZ > a new connection\r\n\r\n\r\n\r\nA new window will appear\r\n\r\n\r\n\r\nFill in the spaces with the map you want to use\r\nYou need to give it a name and the URL\r\nThere are many options of maps, you can look at some here: Google\r\nURLs\r\nWe will use Open Street Map: https://tile.openstreetmap.org/{z}/{x}/{y}.png for the\r\nexample.\r\n\r\n\r\n\r\nOnce you have create the connection, double click on the name and the\r\nmap should be loaded as a layer.\r\n\r\n\r\n\r\nReady to Use!\r\n\r\n\r\n\r\nCreate polygon\r\nSelect New Shapefile Layer\r\n\r\n\r\n\r\nGive a name to your new shapefile\r\nI recommend to click on the three dots to select also the\r\ndirectory\r\nIn the exercise, we will create a polygon, therefore, select\r\nPolygon in Geometry type\r\n\r\n\r\n\r\nSelect Layer > Toggle editing, or just click on the icon with the\r\nyellow pencil\r\n\r\n\r\n\r\nNow add polygon feature by clicking on the green polygon icon\r\n\r\n\r\n\r\nUse the pointer of your mouse and click one time to create\r\npoints\r\nThe areas will start to look red\r\nKeep clicking until you have a more or less the polygon you want\r\nWhen you finish you should add an id, here I used the number 1 for an\r\nexample\r\n\r\n\r\n\r\nNow you should have a polygon!\r\nTo edit the shapes you can use the vertex tool\r\n\r\n\r\n\r\nThe corners can be moved/dragged when the icon has been\r\nselected\r\n\r\n\r\n\r\nNew points can be created using the cross\r\n\r\n\r\n\r\nWhen you are editing your layer you will have a red pencil icon,\r\nclick on the yellow pencil for finish editing\r\n\r\n\r\n\r\nDo not forget to save the changes!\r\n\r\n\r\n\r\n… Now you are done!\r\nI hope this helped you.\r\nReferences\r\nFor continuing learning, here are other uses of google maps:\r\nMedium\r\nAdd background\r\nmap\r\nGoogle\r\nAPI\r\nGoogle\r\nURLs\r\n\r\n\r\n\r\n",
    "preview": "posts/2023-01-27-qgispolygon/blog19.jpg",
    "last_modified": "2023-03-24T18:19:58+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-12-31-streetmap/",
    "title": "Mapa estatico en QGIS",
    "description": "Agregar un mapa base estatico en QGIS",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2022-12-20",
    "categories": [
      "GIS",
      "Español"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nQGIS\r\nGoogle cloud\r\nLeer más\r\n\r\n\r\nIntro\r\nEste post es para compartir los pasos que seguí para agregar un mapa\r\nestatico de google a mi QGIS.\r\nQGIS\r\nActualmente cuento con QGIS 3.28.1 Firenze Para descargarlo\r\n\r\n\r\n\r\nGoogle cloud\r\nLo primero que hice fue entrar a esta liga de google cloud\r\nAlli tienes que registrarte y aceptar los terminos de uso.\r\nDesafortunadamente tuve que ponder mis datos de la tarjeta para poder\r\nusar este servicio, aunque no se me cobro nada.\r\n\r\n\r\n\r\n\r\n\r\n\r\nCree un nuevo proyecto\r\n\r\n\r\n\r\nNo pude ninguna ubicacion relevante\r\n\r\n\r\n\r\nMe fui a la parte de APIs y servicios\r\n\r\n\r\n\r\nMe aparecio un buscador en el que escribi static\r\n\r\n\r\n\r\nEncontre el que me interesaba\r\n\r\n\r\n\r\nLe di en habilitar\r\n\r\n\r\n\r\nY esto me dio acceso a varios tipos de mapas\r\n\r\n\r\n\r\nFuente: Medium\r\nLeer más\r\nAgregar mapa de\r\nfondo en QGIS en inglés\r\nGoogle\r\nAPI\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-11-28T13:36:55+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-12-04-day-night/",
    "title": "Day and night",
    "description": "Create a column with the classification day or night",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2022-12-04",
    "categories": [
      "R",
      "Biologging",
      "English",
      "Y2022"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nData\r\nTransform time and date\r\nExtract hours\r\nClassify day and night\r\nQuantify proportions\r\nFurther reads\r\n\r\n\r\nIntro\r\nThis post is to create a column day or night.\r\nData\r\nFor the exercises, test data is from masked boobies.  To access\r\nthe data you have to install the package sula:\r\ndevtools::install_github(“MiriamLL/sula”)\r\n\r\n\r\n#devtools::install_github(\"MiriamLL/sula\")\r\nlibrary(sula)\r\nGPS01<-(GPS_01)\r\n\r\n\r\nTransform time and date\r\n\r\n\r\nlibrary(dplyr)\r\n\r\n\r\nIdentify column with time date data\r\n\r\n\r\nGPS01$dt <- as.POSIXct(strptime(GPS01$tStamp, \"%Y-%m-%d %H:%M:%S\"))\r\n\r\n\r\nExtract hours\r\nOnce is in time and date format, you can extract just the hours\r\n\r\n\r\nGPS01$hour <- as.numeric(substr(GPS01$dt, 12, 13))\r\n\r\n\r\nClassify day and night\r\nCreate a classification base on the time of sunset and sunrise.\r\n\r\n\r\nGPS01<-GPS01 %>%\r\n mutate(\r\n    day_night = case_when(\r\n      hour > 20 |  hour < 6 ~ \"night\",\r\n      TRUE  ~ \"day\"\r\n    ))\r\n\r\n\r\nQuantify proportions\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\nNow you can quantify how much your animals were out at night\r\n\r\n\r\nGPS01 %>%\r\n  group_by(day_night)%>%\r\n  count()%>%\r\n  pivot_wider(names_from = day_night, values_from = n)\r\n\r\n# A tibble: 1 × 2\r\n    day night\r\n  <int> <int>\r\n1   645   393\r\n\r\nI hope this might help you\r\nFurther reads\r\nClassify activities at night in penguins\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-12-04-day-night/blog18.jpg",
    "last_modified": "2023-04-11T13:20:20+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-11-20-mastodon/",
    "title": "Mastodon",
    "description": "Migrando a mastodon",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2022-11-20",
    "categories": [
      "Español",
      "Y2022"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nMastodon\r\nServer\r\necoevo.social\r\nPagina web\r\nAndroid\r\niOS\r\nPrimeras impresiones\r\nLeer más\r\n\r\n\r\nIntro\r\nEste post es para compartir los pasos que seguí para crear mi cuenta\r\nde mastodon.\r\nMastodon\r\nLo primero que hice fue googlear mastodon\r\n\r\n\r\n\r\nMe encontré con esta pagina y di click en sign up\r\n(debajo de donde dice log in)\r\n\r\n\r\n\r\nMi lógica me decía que lo primero que tenia que hacer es\r\ncreate account.\r\n\r\n\r\n\r\nPero me encontré que no era tan sencillo. Necesito elegir un\r\nserver.\r\n\r\n\r\n\r\nServer\r\nElegir un servidor puede o no ser critico. Como a mi me interesan\r\ntemas de biología elegí ecoevo.social. Pero al parecer\r\nmuchas personas con interés en R se fueron a diferentes\r\nservidores, como fosstodon. El servidor al final da lo\r\nmismo porque puedes seguir a todas las personas desde cualquier\r\nservidor. Además los servidores se ven muy parecidos. Al parecer hay un\r\nproblema con el conteo de seguidores, pero veremos como evoluciona la\r\nplataforma. Si elegir servidor te abruma, te recomiendo elegir uno de\r\nlos servidores a donde migraron las personas que tal vez seguías en\r\ntwitter.\r\necoevo.social\r\nEcoevo definitivamente eran mi servidor. Así que le di click en\r\ncreate account (del lado derecho, debajo del sign\r\nin).\r\n\r\n\r\n\r\nMe salió un aviso de reglas en la plataforma y al final de la pagina\r\nle di al botón de accept.\r\n\r\n\r\n\r\nAhora si todo listo para registrarme!\r\n\r\n\r\n\r\nMe llegó un correo y me hice un perfil.\r\nPagina web\r\nPara usar mastodon desde mi computador, me voy al enlace https://ecoevo.social/explore y le doy click en\r\nlog in\r\n\r\n\r\n\r\nAhora ya puedo empezar a tootear (escribiendo en el\r\ncuadro blanco de la izquierda y dandole al botón de publicar)\r\n\r\n\r\n\r\nAndroid\r\nSeré sincera, mi primer encuentro con mastodon no fue fácil. Cuando\r\nquise descargar la app en mi celular no estaba disponible.\r\n\r\n\r\n\r\nTambién intente varias de las aplicaciones recomendadas por la página.\r\n\r\n\r\n\r\nEl 80% del tiempo en el que uso redes sociales es mientras estoy en\r\nel transporte publico… por lo que tener mastodon en mi celular es la\r\nmejor opción para mi.\r\nTermine instalando **tooot*\r\n\r\n\r\n\r\nLo primero que me pidio la app fue ingresar el servidor donde me\r\nregistre. Para mi caso fue ecoevo.social\r\n\r\n\r\n\r\nUna vez ingresado el servidor, lo siguiente es aceptar las reglas de\r\nuso.\r\n\r\n\r\n\r\nY empezar a tootear.\r\n\r\n\r\n\r\niOS\r\nMi otra opción fue usar iOS.\r\nEn iOS no tuve ningún problema para descargar la app.\r\n\r\n\r\n\r\nAsí es la app una vez que la abres.\r\n\r\n\r\n\r\nPara acceder a tu perfil, primero hay que poner exactamente el nombre\r\ndel servidor que elegiste.\r\n\r\n\r\n\r\nUna vez elegido el servidor, puedes acceder a tu cuenta usando tu\r\ncorreo electronico y contraseña.\r\n\r\n\r\n\r\nY listo para tootear\r\n\r\n\r\n\r\nPrimeras impresiones\r\nHasta ahora lo que más me ha gusto es el contenido dirigido que tiene\r\ncada servidor. También agradezco mucho no tener que ver anuncios, ni\r\npublicaciones que “podrían gustarme”. No obstante, dedique mucho tiempo\r\na buscar a las personas que seguía en twitter, aunque afortunadamente\r\nmuchos pusieron su dirección de mastodon en su nombre de perfil. Solo\r\nfalta que entren más personas. Mientras tanto creo que mantendré ambas\r\nplataformas (twitter y mastodon) para mantenerme actualizada con los\r\ntemas y sobre las personas que me interesan.\r\nLeer más\r\nInformacion\r\ndetallada sobre mastodon -en inglés-\r\nMastodon\r\npara investigadores -en inglés-\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-11-20-mastodon/blog17.jpg",
    "last_modified": "2023-04-11T13:14:29+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-10-04-identify-gaps/",
    "title": "Identify gaps",
    "description": "Find the gaps between recordings",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2022-10-03",
    "categories": [
      "R",
      "Biologging",
      "English",
      "Y2022"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nCreate gap\r\nWhen?\r\nHow much?\r\nWhere?\r\n\r\nFurther considerations\r\n\r\nIntro\r\nThis post is to find and calculate gaps between points.\r\nFor the exercises, test data is from masked boobies.  To access\r\nthe data you have to install the package sula:\r\ndevtools::install_github(“MiriamLL/sula”)\r\n\r\n\r\n#devtools::install_github(\"MiriamLL/sula\")\r\nlibrary(sula)\r\nGPS01<-(GPS01)\r\n\r\n\r\n\r\n\r\nlibrary(dplyr)\r\n\r\n\r\nIdentify column with time date data\r\n\r\n\r\nGPS01$dt <- as.POSIXct(strptime(GPS01$tStamp, \"%Y-%m-%d %H:%M:%S\"))\r\n\r\n\r\nCheck gaps in time between recordings\r\n\r\n\r\nGPS01$Gaps_time<-as.numeric(GPS01$dt - lag(GPS01$dt))\r\n\r\n\r\nClassify gaps\r\n\r\n\r\nGPS01 <- GPS01 %>%\r\n  mutate(Gaps_class = case_when(is.na(Gaps_time) ~ 'U',\r\n                                Gaps_time <= 300 ~ 'Small',\r\n                                TRUE ~ 'Large'))\r\n\r\n\r\nCheck gaps between locations\r\n\r\n\r\nrange(GPS01$Gaps_time,na.rm=TRUE)\r\n\r\n[1] 4.033333 4.700000\r\n\r\nCreate gap\r\nTo artificially create a gap, remove all locations between 13 and 14\r\nhrs\r\n\r\n\r\nGPS01$Hour <- as.numeric(substr(GPS01$dt, 12, 13))\r\n\r\n\r\n\r\n\r\nGPS01_wGap<-GPS01 %>%\r\n  filter(Hour != 13 & Hour != 14)\r\n\r\n\r\nAdd row number\r\n\r\n\r\nGPS01_wGap$seq<-seq(1:nrow(GPS01_wGap))\r\n\r\n\r\nCalculate lag\r\n\r\n\r\nGPS01_wGap$Gaps_time<-as.numeric(GPS01_wGap$dt - lag(GPS01_wGap$dt))\r\n\r\n\r\nClassify gaps  Here, small gaps are when they were less than 15\r\nmin between locations\r\n\r\n\r\nGPS01_wGap <- GPS01_wGap %>%\r\n  mutate(Gaps_class = case_when(is.na(Gaps_time) ~ 'U',\r\n                                Gaps_time <= 15 ~ 'Small',\r\n                                TRUE ~ 'Large'))\r\n\r\n\r\nWhen?\r\nWhen did the gap occurred?\r\nThe result show the latest record, therefore the gap occurred between\r\nthe previous recording and this one\r\n\r\n\r\nLarge_gaps<-GPS01_wGap %>%\r\n  filter(Gaps_class=='Large')\r\nLarge_gaps\r\n\r\n# A tibble: 3 × 11\r\n  Latitude Longitude DateGMT    TimeGMT  IDs   tStamp             \r\n     <dbl>     <dbl> <chr>      <chr>    <chr> <dttm>             \r\n1    -27.3     -109. 02/11/2017 20:00:38 GPS01 2017-11-02 15:00:38\r\n2    -27.2     -109. 03/11/2017 20:00:17 GPS01 2017-11-03 15:00:17\r\n3    -26.9     -109. 04/11/2017 20:03:27 GPS01 2017-11-04 15:03:27\r\n# … with 5 more variables: dt <dttm>, Gaps_time <dbl>,\r\n#   Gaps_class <chr>, Hour <dbl>, seq <int>\r\n\r\nTo see the previous line to see when the gap started you can select\r\nthis and the previous row\r\n\r\n\r\nall_rows<-c(Large_gaps$seq,Large_gaps$seq-1)\r\n\r\n\r\n\r\n\r\nGPS01_wGap %>%\r\n  filter(seq %in% all_rows)\r\n\r\n# A tibble: 6 × 11\r\n  Latitude Longitude DateGMT    TimeGMT  IDs   tStamp             \r\n     <dbl>     <dbl> <chr>      <chr>    <chr> <dttm>             \r\n1    -27.2     -109. 02/11/2017 17:59:37 GPS01 2017-11-02 12:59:37\r\n2    -27.3     -109. 02/11/2017 20:00:38 GPS01 2017-11-02 15:00:38\r\n3    -27.2     -109. 03/11/2017 17:58:01 GPS01 2017-11-03 12:58:01\r\n4    -27.2     -109. 03/11/2017 20:00:17 GPS01 2017-11-03 15:00:17\r\n5    -27.1     -109. 04/11/2017 17:56:45 GPS01 2017-11-04 12:56:45\r\n6    -26.9     -109. 04/11/2017 20:03:27 GPS01 2017-11-04 15:03:27\r\n# … with 5 more variables: dt <dttm>, Gaps_time <dbl>,\r\n#   Gaps_class <chr>, Hour <dbl>, seq <int>\r\n\r\nHow much?\r\nTo calculate the duration of the gap in hours\r\n\r\n\r\nGPS01_wGap$Gap_hrs<-GPS01_wGap$Gaps_time/60\r\n\r\n\r\n\r\n\r\nrange(GPS01_wGap$Gap_hrs,na.rm=TRUE)\r\n\r\n[1] 0.06722222 2.11166667\r\n\r\nWhere?\r\nWhere did the gap occurred?\r\n\r\n\r\nlibrary(ggplot2)\r\n\r\n\r\nEach circle is the locations, the size of the circle is the gap\r\nbetween locations\r\n\r\n\r\nggplot()+\r\n  geom_point(data = GPS01_wGap,\r\n            aes(x=Longitude,y = Latitude,size = Gap_hrs),color='red')+\r\n  geom_path(data = GPS01_wGap,\r\n            aes(x=Longitude,y = Latitude),color='blue',size = 0.5)+\r\n  theme_bw()\r\n\r\n\r\n\r\n\r\n\r\nlibrary(plotly)\r\n\r\n\r\n\r\n\r\nggplotly(ggplot()+\r\n  geom_point(data = GPS01_wGap,\r\n            aes(x=Longitude,y = Latitude,size = Gap_hrs, color=Hour))+\r\n  geom_path(data = GPS01_wGap,\r\n            aes(x=Longitude,y = Latitude),color='blue',size = 0.5)+\r\n  theme_bw())\r\n\r\n\r\n\r\nFurther considerations\r\nTo solve issues with gaps there are several options:\r\nInterpolate the tracking data to specific intervals. For\r\nexample: ‘Gaps in the tracking datasets were linearly interpolated using\r\nthe adehabitatLT package in R in order to obtain tracks at 2 h time\r\nintervals.’ (Ventura et al. 2020; Raine t al. 2021).  Other options\r\nfor interpolate tracking points here.\r\nHowever, be cautious because large intervals will return a straight line\r\nthat might under or overestimate some areas used.\r\nDefine a threshold.\r\n‘Incomplete trips (departure or return from/to the nest not\r\nregistered)’ (Lerma et al. 2020; Fijn et al. 2022). Note that\r\nincluding incomplete trips for calculating trip durations will not\r\ngreatly affect the results. However, gaps in the tracking data might\r\nunderestimate the true maximum distance used by the animal, and their\r\ntotal distance covered during the trip. Therefore it is not advisable to\r\nuse it for this purpose.\r\n‘A track was considered to be complete whenever the GPS recorded\r\n80% or more of the duration of the foraging trip.’ (Tarroux et\r\nal. 2020)\r\nUse portions of the recordings of the incomplete tracks. For\r\nexample ‘… tracks were examined individually; only complete portions of\r\ntracks were used for analyses…’ (Young et al. 2010).\r\nDo not use incomplete tracks.  For example: ‘All records with\r\nincomplete information were excluded for the analyses’\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-10-04-identify-gaps/blog16.jpg",
    "last_modified": "2023-04-11T13:20:48+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-09-13-hr-considerations/",
    "title": "Kernel UD considerations",
    "description": "Some things to consider before making kernel density estimations.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2022-09-14",
    "categories": [
      "R",
      "Biologging",
      "English",
      "Y2022"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\n1. Individuals\r\n2. Intervals\r\n3. Behaviour\r\n\r\n\r\nIntro\r\nThis post is to exemplify some considerations when calculating kernel\r\ndensity analyses.\r\nBefore start calculating kernel density analyses, its useful to\r\nconsider some sources of error that might change your results.\r\nFor the exercises, test data is from masked boobies.  To access\r\nthe data you have to install the package sula:\r\ndevtools::install_github(“MiriamLL/sula”)\r\n\r\n\r\n#devtools::install_github(\"MiriamLL/sula\")\r\nlibrary(sula)\r\nGPS_raw<-(GPS_raw)\r\n\r\n\r\nTo manipulate the data we will use functions from the package\r\ntidyverse\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\nFor spatial manipulations we will use functions from the packages\r\nsp and sf\r\n\r\n\r\nlibrary(sp)\r\nlibrary(sf)\r\n\r\n\r\nFor creating the polygons of kernel density we will use the package\r\nadehabitathr\r\n\r\n\r\nlibrary(adehabitatHR)\r\n\r\n\r\n1. Individuals\r\nSome individuals might drive kernel density calculations in one or\r\nother direction as effect of different number of recordings (or days\r\nrecorded) per individual.\r\nUnpaired\r\nTo illustrate this, lets see the calculations using together one\r\nindividual sampled for 1 day and other for 5 days\r\nIndividual one day\r\n\r\n\r\n\r\n\r\n\r\nID_1day<-GPS_raw %>%\r\n  filter(IDs=='GPS01') %>%\r\n  filter(DateGMT %in% c('02/11/2017'))\r\n\r\n\r\nIndividual 5 days\r\n\r\n\r\n\r\n\r\n\r\nID_5days<-GPS_raw %>%\r\n  filter(IDs=='GPS03')\r\n\r\n\r\nUnpaired days\r\n\r\n\r\nUnpaired<-rbind(ID_1day,ID_5days)\r\n\r\n\r\nTransform to spatial object.\r\n\r\n\r\nUnpaired<-as.data.frame(Unpaired)\r\ncoordinates(Unpaired) <- c(\"Longitude\", \"Latitude\")\r\nclass(Unpaired)\r\n\r\n[1] \"SpatialPointsDataFrame\"\r\nattr(,\"package\")\r\n[1] \"sp\"\r\n\r\nCalculate kernelUD.\r\n\r\n\r\nUnpairedUD<-kernelUD(Unpaired[,3],h='href') \r\n\r\n\r\nObtain polygons.\r\n\r\n\r\nUnpairedUD95 <- getverticeshr(UnpairedUD, percent = 95, unout = c(\"m2\"))\r\nUnpairedUD50 <- getverticeshr(UnpairedUD, percent = 50, unout = c(\"m2\"))\r\n\r\n\r\nHere you can check on you polygons visually.\r\n\r\n\r\nUnpaired95<-st_as_sf(UnpairedUD95)\r\nUnpaired50<-st_as_sf(UnpairedUD50)\r\n\r\n\r\n\r\n\r\nggplot()+\r\n  geom_sf(data = Unpaired95,color='#006d77',fill = \"#006d77\",alpha=0.3,size=1)+\r\n  geom_sf(data = Unpaired50,color='#5f0f40',fill = \"#5f0f40\",alpha=0.3,size=1)+\r\n  labs(x = \"Longitude\", y=\"Latitude\")+\r\n  theme_bw()\r\n\r\n\r\n\r\nPaired\r\nTo compare, lets now see the kernel density calculated with these\r\nsame individuals but recorded at similar number of days (3 days)\r\n\r\n\r\nID_01<-GPS_raw %>%\r\n  filter(IDs=='GPS01') %>%\r\n  filter(DateGMT %in% c('02/11/2017','03/11/2017','04/11/2017','05/11/2017'))\r\n\r\n\r\n\r\n\r\nID_03<-GPS_raw %>%\r\n  filter(IDs=='GPS03') %>%\r\n  filter(DateGMT %in% c('02/11/2017','03/11/2017','04/11/2017','05/11/2017'))\r\n\r\n\r\n\r\n\r\nPaired<-rbind(ID_01,ID_03)\r\n\r\n\r\nTransform to spatial object.\r\n\r\n\r\nPaired<-as.data.frame(Paired)\r\ncoordinates(Paired) <- c(\"Longitude\", \"Latitude\")\r\nclass(Paired)\r\n\r\n[1] \"SpatialPointsDataFrame\"\r\nattr(,\"package\")\r\n[1] \"sp\"\r\n\r\nCalculate kernelUD.\r\n\r\n\r\nPairedUD<-kernelUD(Paired[,3],h='href') \r\n\r\n\r\nObtain polygons.\r\n\r\n\r\nPairedUD95 <- getverticeshr(PairedUD, percent = 95, unout = c(\"m2\"))\r\nPairedUD50 <- getverticeshr(PairedUD, percent = 50, unout = c(\"m2\"))\r\n\r\n\r\nHere you can check on you polygons visually.\r\n\r\n\r\nPaired95<-st_as_sf(PairedUD95)\r\nPaired50<-st_as_sf(PairedUD50)\r\n\r\n\r\n\r\n\r\nggplot()+\r\n  geom_sf(data = Paired95,color='#006d77',fill = \"#006d77\",alpha=0.3,size=1)+\r\n  geom_sf(data = Paired50,color='#5f0f40',fill = \"#5f0f40\",alpha=0.3,size=1)+\r\n  labs(x = \"Longitude\", y=\"Latitude\")+\r\n  theme_bw()\r\n\r\n\r\n\r\nAs you can see the resulting areas would be different.\r\nTo solve this problem, you might want to make sure to have tracking\r\ndata of similar number of days or recordings.\r\n2. Intervals\r\nDo you have similar recordings in time?\r\nIf some devices have gaps, or record at different intervals, you\r\nmight underestimate or overestimate specific areas.\r\nFor this example, lets see one individuals\r\n\r\n\r\nGPS01<-GPS_raw %>%\r\n  filter(IDs=='GPS01')\r\n\r\n\r\nGaps.\r\nUsing the column of hours, lets extract all the recordings after 5\r\npm.\r\n\r\n\r\nGPS01$Hour <- as.numeric(substr(GPS01$TimeGMT, 1, 2))\r\nGaps<-GPS01 %>%\r\n  filter(Hour <= 17)\r\n\r\n\r\nTransform to spatial object.\r\n\r\n\r\nGaps<-as.data.frame(Gaps)\r\ncoordinates(Gaps) <- c(\"Longitude\", \"Latitude\")\r\n\r\n\r\nCalculate kernelUD.\r\n\r\n\r\nGapsUD<-kernelUD(Gaps[,3],h='href') \r\n\r\n\r\nObtain polygons.\r\n\r\n\r\nGapsUD95 <- getverticeshr(GapsUD, percent = 95, unout = c(\"m2\"))\r\nGapsUD50 <- getverticeshr(GapsUD, percent = 50, unout = c(\"m2\"))\r\n\r\n\r\nHere you can check on you polygons visually.\r\n\r\n\r\nGaps95<-st_as_sf(GapsUD95)\r\nGaps50<-st_as_sf(GapsUD50)\r\n\r\n\r\n\r\n\r\nggplot()+\r\n  geom_sf(data = Gaps95,color='#006d77',fill = \"#006d77\",alpha=0.3,size=1)+\r\n  geom_sf(data = Gaps50,color='#5f0f40',fill = \"#5f0f40\",alpha=0.3,size=1)+\r\n  labs(x = \"Longitude\", y=\"Latitude\")+\r\n  theme_bw()\r\n\r\n\r\n\r\nComplete\r\nIn contrast, the kernel density calculations without gaps would give\r\ndifferent results.\r\n\r\n\r\nComplete<-GPS_raw %>%\r\n  filter(IDs=='GPS01')\r\n\r\n\r\nTransform to spatial object.\r\n\r\n\r\nComplete<-as.data.frame(Complete)\r\ncoordinates(Complete) <- c(\"Longitude\", \"Latitude\")\r\n\r\n\r\nCalculate kernelUD.\r\n\r\n\r\nCompleteUD<-kernelUD(Complete[,3],h='href') \r\n\r\n\r\nObtain polygons.\r\n\r\n\r\nCompleteUD95 <- getverticeshr(CompleteUD, percent = 95, unout = c(\"m2\"))\r\nCompleteUD50 <- getverticeshr(CompleteUD, percent = 50, unout = c(\"m2\"))\r\n\r\n\r\nHere you can check on you polygons visually.\r\n\r\n\r\nComplete95<-st_as_sf(CompleteUD95)\r\nComplete50<-st_as_sf(CompleteUD50)\r\n\r\n\r\n\r\n\r\nggplot()+\r\n  geom_sf(data = Complete95,color='#006d77',fill = \"#006d77\",alpha=0.3,size=1)+\r\n  geom_sf(data = Complete50,color='#5f0f40',fill = \"#5f0f40\",alpha=0.3,size=1)+\r\n  labs(x = \"Longitude\", y=\"Latitude\")+\r\n  theme_bw()\r\n\r\n\r\n\r\nTo solve the problem with gaps, you can interpolate the data to fill\r\nthe gaps and have similar\r\nintervals. However, caution should be taken if you have large gaps,\r\nit would create a line.\r\n3. Behaviour\r\nDo you want to know the general areas that the animal used or\r\njust where it was feeding?\r\nIt depends on your question, but if you are interested in specific\r\nbehaviours, for example feeding areas, the kernel density analyses might\r\nbe bring very different results than when using all movement data.\r\nForaging\r\nHere, we are using only areas where the animal was foraging.\r\nLoad data\r\n\r\n\r\nGPS_raw<-as.data.frame(GPS_raw)\r\nGPS01<-subset(GPS_raw,GPS_raw$IDs=='GPS01')\r\n\r\n\r\nUse an specific period\r\n\r\n\r\nGPS_bc<-recortar_periodo(GPS_data=GPS01,\r\n                                inicio='02/11/2017 18:10:00',\r\n                                final='05/11/2017 14:10:00',\r\n                                dia_col='DateGMT',\r\n                                hora_col='TimeGMT',\r\n                                formato=\"%d/%m/%Y %H:%M:%S\")\r\n\r\n\r\n ES: El track original contenia 1038 filas y el track editado contiene 986 filas \r\n EN: The original track had 1038 rows, and the edited track has 986\r\n\r\nConvert to the correct format\r\n\r\n\r\nGPS_bc$tStamp<-paste(GPS_bc$DateGMT,GPS_bc$TimeGMT)\r\nGPS_bc$tStamp <- as.POSIXct(strptime(GPS_bc$tStamp,\"%d/%m/%Y %H:%M:%S\"),\"GMT\")\r\nGPS_bc$lon<- as.numeric(GPS_bc$Longitude)\r\nGPS_bc$lat<- as.numeric(GPS_bc$Latitude)\r\nGPS_bc$id <- as.factor(GPS_bc$IDs)\r\n\r\n\r\nKeep only the important columns\r\n\r\n\r\nGPS_bc<-GPS_bc %>%\r\n  dplyr::select('id','tStamp','lon','lat')\r\n\r\n\r\nLoad the package\r\n\r\n\r\nlibrary(EMbC)\r\n\r\n\r\nRun the function\r\n\r\n\r\nBC_clustering<-EMbC::stbc(GPS_bc[2:4],info=-1) \r\n\r\n[1]   0  -0.0000e+00       4       986\r\n[1] ... Stable clustering\r\n\r\nAdd the behavioral classifications\r\n\r\n\r\nGPS_bc$Behaviours<-(BC_clustering@A)\r\n\r\n\r\nRename it so you can understand what each behaviour means\r\n\r\n\r\nGPS_bc<-mutate(GPS_bc, BC = ifelse(GPS_bc$Behaviours == \"1\", \"Resting\",\r\n                                        ifelse(GPS_bc$Behaviours == \"2\", \"Intense foraging\",\r\n                                               ifelse(GPS_bc$Behaviours == \"3\", 'Travelling',\r\n                                                      ifelse(GPS_bc$Behaviours == \"4\", \"Relocating\", \r\n                                                             \"Unknown\")))))\r\n\r\n\r\nFilter to keep only foraging\r\n\r\n\r\nForaging<-GPS_bc %>%\r\n  filter(BC=='Intense foraging')\r\n\r\n\r\nTransform to spatial object\r\n\r\n\r\nForaging<-as.data.frame(Foraging)\r\ncoordinates(Foraging) <- c(\"lon\", \"lat\")\r\n\r\n\r\nCalculate kernelUD.\r\nNote Here the href is of 0.0048 which is giving the\r\nerror of subscript out of bounds Lets then better calculate\r\nusing other h value\r\n\r\n\r\n#ForagingUD<-kernelUD(Foraging[,3],h='href') \r\n#ForagingUD95 <- getverticeshr(ForagingUD, percent = 95, unout = c(\"m2\"))\r\n\r\n\r\nThe new h value is of 0.01\r\n\r\n\r\nForagingUD<-kernelUD(Foraging[,3],h=0.009) \r\nForagingUD\r\n\r\n********** Utilization distribution of several Animals ************\r\n\r\nType: probability density\r\nSmoothing parameter estimated with a  specified smoothing parameter\r\nThis object is a list with one component per animal.\r\nEach component is an object of class estUD\r\nSee estUD-class for more information\r\n\r\nObtain polygons.\r\n\r\n\r\nForagingUD95 <- getverticeshr(ForagingUD, percent = 95, unout = c(\"m2\"))\r\nForagingUD50 <- getverticeshr(ForagingUD, percent = 50, unout = c(\"m2\"))\r\n\r\n\r\nHere you can check on you polygons visually.\r\n\r\n\r\nForaging95<-st_as_sf(ForagingUD95)\r\nForaging50<-st_as_sf(ForagingUD50)\r\n\r\n\r\n\r\n\r\nggplot()+\r\n  geom_sf(data = Foraging95,color='#006d77',fill = \"#006d77\",alpha=0.3,size=1)+\r\n  geom_sf(data = Foraging50,color='#5f0f40',fill = \"#5f0f40\",alpha=0.3,size=1)+\r\n  labs(x = \"Longitude\", y=\"Latitude\")+\r\n  theme_bw()\r\n\r\n\r\n\r\nAll recordings\r\nHere, we are using all the areas.\r\n\r\n\r\nGPS_bc<-GPS_bc %>%\r\n  dplyr::select('id','tStamp','lon','lat')\r\n\r\n\r\n\r\n\r\nBehas<-as.data.frame(GPS_bc)\r\ncoordinates(Behas) <- c(\"lon\", \"lat\")\r\n\r\n\r\nCalculate kernelUD.\r\n\r\n\r\nBehasUD<-kernelUD(Behas,h='href') \r\nBehasUD\r\n\r\n********** Utilization distribution of an Animal ************\r\n\r\nType: probability density\r\nSmoothing parameter estimated with a  href parameter\r\nThis object inherits from the class SpatialPixelsDataFrame.\r\nSee estUD-class for more information\r\n\r\nObtain polygons.\r\n\r\n\r\nBehasUD95 <- getverticeshr(BehasUD, percent = 95, unout = c(\"m2\"))\r\nBehasUD50 <- getverticeshr(BehasUD, percent = 50, unout = c(\"m2\"))\r\n\r\n\r\nHere you can check on you polygons visually.\r\n\r\n\r\nBehas95<-st_as_sf(BehasUD95)\r\nBehas50<-st_as_sf(BehasUD50)\r\n\r\n\r\n\r\n\r\nggplot()+\r\n  geom_sf(data = Behas95,color='#006d77',fill = \"#006d77\",alpha=0.3,size=1)+\r\n  geom_sf(data = Behas50,color='#5f0f40',fill = \"#5f0f40\",alpha=0.3,size=1)+\r\n  labs(x = \"Longitude\", y=\"Latitude\")+\r\n  theme_bw()\r\n\r\n\r\n\r\nIf you want to classify the behaviour, please check the post on EmBC\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-09-13-hr-considerations/blog15.jpg",
    "last_modified": "2023-04-11T13:21:01+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-08-17-count-days/",
    "title": "Count days",
    "description": "How to add a day number as a column, and see differences as days pass.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2022-08-17",
    "categories": [
      "R",
      "Biologging",
      "English",
      "Y2022"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nData 📖\r\nCount days 🧮\r\nJulian day 📅\r\nMore to read 👩🏽‍🏫\r\n\r\nIntro\r\nThis post is about how:  - Add a column counting the days (day 1,\r\n2…). - Check differences in parameters as days pass.  - Add a\r\ncolumn with julian day (days from the first day of the calendar).\r\n\r\nExamples \r\nThis post is useful to study:\r\nIn species that fed their offspring. Trips might be shorter when\r\nthe parents need to mantain a constant feeding rate, but trips can be\r\nlonger during the incubation period, and when offspring can be left\r\nunattended.\r\nSpecies that use resources that availability change over time.\r\nTrips might be shorter when the prey availability is at its peak, and\r\ntrips might be longer when the prey availability is lower, as\r\nindividuals expend more time to reach their energetic demands.\r\nData 📖\r\nTo do this exercise, we will load data from the package ‘sula’\r\nTo install:\r\n\r\n\r\n#devtools::install_github(\"MiriamLL/sula\")\r\n\r\n\r\n\r\n\r\nlibrary(sula)\r\n\r\n\r\nTo load data from from 1 tracked individual.\r\n\r\n\r\nGPS<-GPS_edited\r\n\r\n\r\nGet nest location.\r\n\r\n\r\nnest_loc<-localizar_nido(GPS_data = GPS,\r\n                          lat_col=\"Latitude\",\r\n                          lon_col=\"Longitude\")\r\n\r\n  Longitude  Latitude\r\n1 -109.4596 -27.23235\r\n\r\nCalculate foraging trip parameters.\r\n\r\n\r\nForaging_trips<-calcular_tripparams(GPS_data = GPS,\r\n                              diahora_col = \"tStamp\",\r\n                              formato = \"%Y-%m-%d %H:%M:%S\",\r\n                              nest_loc=nest_loc,\r\n                              separador=\"trip_number\")\r\n\r\n\r\nCount days 🧮\r\nIdeally, you will have a data frame with the date and time\r\ninformation.\r\nTo add the number of days, we select a column with information from\r\ndate and time.\r\nFor the example we will use trip_start and extract\r\nthe date.\r\n\r\n\r\nForaging_trips$date<-substr(Foraging_trips$trip_start, start = 1, stop = 10)\r\n\r\n\r\nNow we use this date as a factor and number it.\r\n\r\n\r\nForaging_trips$day_number<-as.numeric(as.factor(Foraging_trips$date))\r\n\r\n\r\nWe can also use this information to see the number of days the\r\nindividual was tracked.\r\n\r\n\r\nlength(unique(Foraging_trips$day_number))\r\n\r\n[1] 4\r\n\r\nLoad the package tidyverse.\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\nSummarize the information per day.\r\n\r\n\r\nduration_per_day<-Foraging_trips%>%\r\n  group_by(day_number)%>%\r\n  summarise(duration_day=mean(duration_h))\r\n\r\n\r\nIn the plot, you can now see if there were differences in the trip\r\ndurations among the days that the bird was tracked.\r\n\r\n\r\nggplot(duration_per_day, aes(x=day_number, y=duration_day)) +\r\n  geom_segment( aes(x=day_number, xend=day_number, y=0, yend=duration_day), color=\"grey\") +\r\n  geom_point( color=\"orange\", size=4) +\r\n  theme_classic() +\r\n  xlab('Days since begginnig of tracking')+\r\n  ylab('Mean duration (h)')+\r\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 3))\r\n\r\n\r\n\r\nJulian day 📅\r\nLoad package lubridate\r\n\r\n\r\nlibrary(lubridate)\r\n\r\n\r\nExtract the date using the function as.Date\r\n\r\n\r\nForaging_trips$julian_date <- as.Date(Foraging_trips$date, format=c(\"%Y-%m-%d\"))\r\n\r\n\r\nUse the argument %j to obtain the julian day.\r\n\r\n\r\nForaging_trips$julian <- as.numeric(format(Foraging_trips$julian_date, \"%j\"))\r\n\r\n\r\nThe bird was tagged between the day 306 and 309 of the calendar.\r\n\r\n\r\nrange(Foraging_trips$julian)\r\n\r\n[1] 306 309\r\n\r\nSummarize the information per day.\r\n\r\n\r\nduration_per_julian<-Foraging_trips%>%\r\n  group_by(julian)%>%\r\n  summarise(duration_day=mean(duration_h))\r\n\r\n\r\nThe plot would be more informatiive for whole seasons, or breeding\r\nseasons.\r\n\r\n\r\nggplot(duration_per_julian, aes(x=julian, y=duration_day)) +\r\n  geom_segment( aes(x=julian, xend=julian, y=0, yend=duration_day), color=\"grey\") +\r\n  geom_point( color=\"orange\", size=4) +\r\n  theme_classic() +\r\n  xlab('Calendar day')+\r\n  ylab('Mean duration (h)')+\r\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 3))+\r\n  scale_x_continuous(expand = c(0, 0), limits = c(0, 365))\r\n\r\n\r\n\r\nI hope this might help you.\r\nMore to read 👩🏽‍🏫\r\nPistorious\r\net al. 2015.\r\nLerma\r\net al. 2020\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-08-17-count-days/blog14.jpg",
    "last_modified": "2023-04-11T13:21:17+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-07-01-nestlocation/",
    "title": "Locate nest",
    "description": "How to locate the nest of the bird using their GPS locations.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2022-07-01",
    "categories": [
      "R",
      "Biologging",
      "English",
      "Y2022"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nData 📖\r\nLocate nest 🐣\r\nManually 🔥\r\nNight time 🌜\r\n\r\nAutomatic 🤖\r\nCentroid 🎯\r\n\r\nOther resources 👩🏽‍🏫\r\n\r\nIntro\r\nThis post is about how to identify the central location from an\r\nanimal. \r\nFor example if you want to identify how far an animals moves, it is\r\nhelpful to identify where the central location of the animal is to use\r\nit as a reference point.\r\nIn this post we will use different logic and/or functions to identify\r\ncentral locations for animals.\r\nData 📖\r\nTo do this exercise, load data from the package ‘sula’.  For\r\naccessing the data, you need to have the package installed.\r\nTo install:\r\n\r\n\r\n#devtools::install_github(\"MiriamLL/sula\")\r\n\r\n\r\n\r\n\r\nlibrary(sula)\r\n\r\n\r\nIt contains data from 1 individual.\r\n\r\n\r\nGPS_01<-GPS_01\r\n\r\n\r\nIt contains data from 10 tracked individuals.\r\n\r\n\r\nGPS_raw<-(GPS_raw)\r\n\r\n\r\nLocate nest 🐣\r\nIf your devices were deployed and activated at the nest of the\r\nanimal, then you can assume that the first recording is the nest\r\nlocation.\r\nOne individual\r\nIf you are interested in only one individual you can use the function\r\nlocalizar_nido.\r\n\r\n\r\nnest<-localizar_nido(GPS_data = GPS_01,lat_col=\"Latitude\",lon_col=\"Longitude\")\r\n\r\n# A tibble: 1 × 2\r\n  Longitude Latitude\r\n      <dbl>    <dbl>\r\n1     -109.    -27.2\r\n\r\nIt returns a row with the longitud and latitude of the nest for that\r\nindividual.\r\nSeveral individuals\r\nFor identifying the nest location of several individuals, you can use\r\nthe function localizar_nidos from the package\r\nsula.\r\n\r\n\r\nnests<-localizar_nidos(GPS_data=GPS_raw,\r\n                         lon_col=\"Longitude\",\r\n                         lat_col=\"Latitude\",\r\n                         ID_col=\"IDs\")\r\n\r\n\r\nThis function will return a data frame with the location of the nest\r\nper individual.\r\n\r\n\r\nhead(nests)\r\n\r\n  Longitude  Latitude    ID\r\n1 -109.4531 -27.20097 GPS01\r\n2 -109.4531 -27.20097 GPS02\r\n3 -109.4531 -27.20105 GPS03\r\n4 -109.4533 -27.20086 GPS04\r\n5 -109.4527 -27.20125 GPS05\r\n6 -109.4527 -27.20116 GPS06\r\n\r\nManually 🔥\r\nHaving some knowledge of the behavior of the animals will help us to\r\nidentify the nest. In this example, the species (Masked boobies) are\r\nmostly diurnal feeders, which means they are mostly at their nest at\r\nnight.\r\nTherefore, you can filter all the locations at day, and try to find\r\nthe place where they spent most of their time at night to find the\r\nnest.\r\nData 😴\r\nFor this example, we will be using data from one individual.\r\n\r\n\r\nhead(GPS_01)\r\n\r\n# A tibble: 6 × 6\r\n  Latitude Longitude DateGMT    TimeGMT  IDs   tStamp             \r\n     <dbl>     <dbl> <chr>      <chr>    <chr> <dttm>             \r\n1    -27.2     -109. 02/11/2017 17:05:30 GPS01 2017-11-02 12:05:30\r\n2    -27.2     -109. 02/11/2017 17:09:35 GPS01 2017-11-02 12:09:35\r\n3    -27.2     -109. 02/11/2017 17:13:50 GPS01 2017-11-02 12:13:50\r\n4    -27.2     -109. 02/11/2017 17:17:59 GPS01 2017-11-02 12:17:59\r\n5    -27.2     -109. 02/11/2017 17:22:13 GPS01 2017-11-02 12:22:13\r\n6    -27.2     -109. 02/11/2017 17:26:25 GPS01 2017-11-02 12:26:25\r\n\r\nNight time 🌜\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\nTo use only locations of night, subset the hours for only night\r\ntime.\r\nYou can do this by creating a column with the hour of the day.\r\n\r\n\r\nGPS_01$Hour <- substr(GPS_01$tStamp, 12, 13)\r\n\r\n\r\nNote that in the example, we use tStamp because is on the correct\r\ntime zone, for more details click\r\nhere)\r\nFor this area, the night time was considered to be between 6 am (6 h)\r\nand 8 pm (20 h).\r\nHere, a new column named Day_or_night to identify\r\nthe time period will be created.\r\n\r\n\r\nGPS_01<-GPS_01 %>%\r\n mutate(\r\n    Day_or_night = case_when(\r\n      Hour > 6  |  Hour < 20 ~ \"day\",\r\n      TRUE  ~ \"night\"\r\n    )\r\n  )\r\n\r\n\r\nThen, filtered to only keep night recordings.\r\n\r\n\r\nGPS_01_night<- GPS_01 %>%\r\n  filter(Day_or_night == 'night')\r\n\r\n\r\nDefinition 👩🏽‍🚒\r\nHeat mapping, from a GIS perspective, is a method of showing the\r\ngeographic clustering of a phenomenon. Heat maps show locations of\r\nhigher densities of geographic entities. Heat mapping is a way of\r\ngeographically visualizing locations so that patterns of higher than\r\naverage occurrence of things can emerge. To read more click here.\r\nA heatmap can thus help us to visualize the place where the animal\r\nspends most of its time. This would be very often the nest, for breeding\r\nanimals.\r\nTo visualize the heatmap we can use functions from the package\r\nggplot.\r\n\r\n\r\nlibrary(ggplot2)\r\n\r\n\r\nThe function geom_density_2d_filled will create a\r\nheat map on the area where most locations were occurring.\r\n\r\n\r\nggplot()+\r\n  geom_point(data = GPS_01_night, aes(x=Longitude, y = Latitude),\r\n             color='black',size = 0.8,alpha=0.4)+\r\n  geom_density_2d_filled(data = GPS_01_night, aes(x = Longitude, y = Latitude),alpha = 0.5)+ \r\n  theme_bw()+\r\n  theme(legend.position = 'none')\r\n\r\n\r\n\r\nYou can already see that there is a region that stands out as where\r\nmost locations were recorded.\r\nBy adding the known-nest using geom_point (as a\r\nred-triangle, nest located using the function\r\nlocalizar_nido above), we can corroborate that this\r\nregion is where the nest of the bird was.\r\n\r\n\r\nggplot()+\r\n  geom_point(data = GPS_01_night, aes(x=Longitude, y = Latitude),\r\n             color='black',size = 0.8,alpha=0.4)+\r\n  geom_density_2d_filled(data = GPS_01_night, aes(x = Longitude, y = Latitude),alpha = 0.5)+ \r\n  geom_point(data=nest, aes(x=Longitude, y=Latitude),color='red',shape=17, size=5)+\r\n  theme_bw()+\r\n  theme(legend.position = 'none')\r\n\r\n\r\n\r\nSo, now we know that there is where the animal spend most of the\r\nnight.\r\nFor the next step, we will try to see the coordinates by using an\r\ninteractive plot of the area that was most used by the\r\nanimal.\r\nInteractive plot\r\nWith ggplotly() by plotly,\r\nwe can convert ggplot2 figures into interactive ones.\r\n\r\n\r\nlibrary(plotly)\r\n\r\n\r\nThe advantage of using plotly is that it allows zooming in and out of\r\nthe area and see the place where most of the locations occurred.\r\nBy placing the cursor on top of the area, you can see the longitude\r\nand latitude.\r\n\r\n\r\nggplotly(ggplot(GPS_01_night, aes(x=Longitude, y = Latitude))+\r\n  stat_density_2d(aes(fill = ..density..), geom = \"raster\", contour = FALSE) +\r\n  scale_fill_continuous(type = \"viridis\") +\r\n  geom_point(data = GPS_01_night, aes(x=Longitude, y = Latitude),\r\n             color='black',size = 0.5,alpha=0.4)+\r\n  theme_bw())\r\n\r\n\r\n\r\nWith this information, we can note down the locations most used.\r\nHowever, since the GPS has some errors, you will notice that there is\r\nnot an specific point.\r\nTo solve this we can calculate the centroid\r\nlocation, as in the example below.\r\nAutomatic 🤖\r\nTo identify the areas where most points occurred the function\r\nkde2d from the package MASS can be\r\nused.\r\n\r\n\r\nlibrary(MASS)\r\n\r\n\r\n\r\n\r\nnight_kde2d <- kde2d(GPS_01_night$Longitude, GPS_01_night$Latitude)\r\n\r\n\r\nUsing the function raster from the package\r\nraster we can identify the areas of highest\r\noccurrence.\r\n\r\n\r\nlibrary(raster)\r\n\r\n\r\n\r\n\r\nnight_raster<-raster(night_kde2d)\r\n\r\n\r\nNext step is to convert the areas with the highest densities\r\n(>95%) into a polygon.\r\n\r\n\r\nnight_pol <- rasterToPolygons(night_raster %/% 95,dissolve = T)\r\n\r\n\r\nNow, we want to keep only the locations that fall inside the most\r\ncommon used areas, and for this we need to transform our points into\r\nSpatialPointsDataFrame and our polygon as\r\nSpatialPolygonDataFrame.\r\n\r\n\r\nmy_points <-GPS_01_night\r\nsp::coordinates(my_points) <- ~Longitude + Latitude\r\nsp::proj4string(my_points) = sp::CRS(\"+init=epsg:4326\")\r\nclass(my_points)\r\n\r\n[1] \"SpatialPointsDataFrame\"\r\nattr(,\"package\")\r\n[1] \"sp\"\r\n\r\nmy_polygon<-night_pol\r\nclass(my_polygon)\r\n\r\n[1] \"SpatialPolygonsDataFrame\"\r\nattr(,\"package\")\r\n[1] \"sp\"\r\n\r\nThen, using the function over we will end up with\r\ndensities per point.\r\n\r\n\r\ninside<- over(my_points, my_polygon)\r\n\r\n\r\nWe can add this information to our data frame.\r\n\r\n\r\nGPS_01_night$inside<-inside\r\nrange(GPS_01_night$inside)\r\n\r\n[1]   2360 130344\r\n\r\nFinally, filter to just keep the areas of highest\r\noccurrence.\r\n\r\n\r\nGPS_01_high<-GPS_01_night %>%\r\n  filter(inside>100000)\r\n\r\n\r\nCentroid 🎯\r\nNow that we have only the locations inside the most\r\nuse areas, we can calculate the centroid location.\r\n\r\n\r\nrequire(sp)\r\nrequire(rgeos)\r\n\r\n\r\nFirst, convert the night time to SpatialPoints\r\n\r\n\r\nGPS_01_sp= SpatialPoints(coords = GPS_01_high[, c('Longitude','Latitude')], \r\n                   proj4string = CRS(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\") )\r\n\r\nclass(GPS_01_sp)\r\n\r\n[1] \"SpatialPoints\"\r\nattr(,\"package\")\r\n[1] \"sp\"\r\n\r\nThen, use the function gCentroid to obtain the\r\ncentroid location.\r\n\r\n\r\nGPS_01_centroids = gCentroid(GPS_01_sp,byid=FALSE)\r\n\r\n\r\nObtain coordinates from the centroid location.\r\n\r\n\r\ncentroid<-data.frame(Longitude=GPS_01_centroids@coords[,1],\r\n           Latitude=GPS_01_centroids@coords[,2])\r\ncentroid\r\n\r\n  Longitude  Latitude\r\n1 -109.4531 -27.20099\r\n\r\nCheck if the centroid location fits to the area of the nest.\r\n\r\n\r\nggplot()+\r\n  geom_point(data = GPS_01_night, aes(x=Longitude, y = Latitude),\r\n             color='black',size = 0.8,alpha=0.4)+\r\n  geom_density_2d_filled(data = GPS_01_night, aes(x = Longitude, y = Latitude),alpha = 0.5)+ \r\n  geom_point(data=centroid, aes(x=Longitude, y=Latitude),color='red',shape=17, size=5)+\r\n  theme_bw()+\r\n  theme(legend.position = 'none')\r\n\r\n\r\n\r\nAnd thats it, now you should have the centroid location of this\r\nindividual.\r\nYou can do this per individual, or create a function to run\r\nautomatically to each one of your individuals.\r\nI hope this might help you.\r\nOther resources 👩🏽‍🏫\r\nMore options of density\r\nplots\r\nDetails on how to use plotly\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-07-01-nestlocation/blog13.jpg",
    "last_modified": "2023-04-11T13:22:12+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-06-30-time-formats/",
    "title": "Time formats",
    "description": "How to convert your time to a format that R can understand as time.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2022-06-30",
    "categories": [
      "R",
      "Biologging",
      "English",
      "Y2022"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nData 📖\r\nTransform the column to\r\nPOSIXct\r\n\r\nCorrect time 🌐\r\nIdentify your time zone\r\n🗺️\r\n\r\nOther resources 👩🏽‍🏫\r\n\r\nIntro\r\nThis post is about how to convert date and time to a format that R\r\ncan understand it. \r\nFor example if you wrote the date and time during fieldwork in a\r\nnotebook, and then wrote it down in a spreadsheet at your computer. When\r\nyou load your this spreadsheet into R, very often R would think that\r\nyour date and time is text. Therefore, you need to change the ‘class’ of\r\nthe column where you have date and time.\r\nIt is important to change the ‘class’ of your column, so you\r\ncan:\r\n- Correct the time zone  - Calculate duration of events (for example\r\nforaging trip duration) - Count days (for example Julian days) -\r\nIdentify night and day periods … and many many more\r\nIn this post we will transform the class of our\r\ncolumn date and time from character or other class,\r\ninto POSTIXct. Additionally, we will change the\r\ntime zone.\r\nData 📖\r\nTo do this exercise, load data from the package ‘sula’.  For\r\naccessing the data, you need to have the package installed.\r\nTo install:\r\n\r\n\r\n#devtools::install_github(\"MiriamLL/sula\")\r\n\r\n\r\n\r\n\r\nlibrary(sula)\r\n\r\n\r\nThe data is from 10 tracked individuals.\r\n\r\n\r\nGPS_raw<-(GPS_raw)\r\n\r\n\r\nDate 📅\r\nThe data frame contains a column with date\r\ninformation.\r\n\r\n\r\nhead(GPS_raw$DateGMT)\r\n\r\n[1] \"02/11/2017\" \"02/11/2017\" \"02/11/2017\" \"02/11/2017\" \"02/11/2017\"\r\n[6] \"02/11/2017\"\r\n\r\nThe date infomation is of class\r\ncharacter.\r\n\r\n\r\nclass(GPS_raw$DateGMT)\r\n\r\n[1] \"character\"\r\n\r\nTime ⏰\r\nThe data frame contains a column with time\r\ninformation.\r\n\r\n\r\nhead(GPS_raw$TimeGMT)\r\n\r\n[1] \"17:05:30\" \"17:09:35\" \"17:13:50\" \"17:17:59\" \"17:22:13\" \"17:26:25\"\r\n\r\nThe time infomation is of class\r\ncharacter.\r\n\r\n\r\nclass(GPS_raw$TimeGMT)\r\n\r\n[1] \"character\"\r\n\r\nTransform the column to\r\nPOSIXct\r\nPOSIX comes from Portable Operating System\r\nInterface and the X from UNIX.  There are two\r\nsubclasses ct from calendar time and\r\nlt from local time. See R\r\nnews. Calendar time being the number of seconds since the\r\nbeginning of 1970.\r\n To create our column with date and time, lets merge the column\r\nDateGMT and TimeGMT from our data frame into one column DateTime.\r\n\r\n\r\nGPS_raw$DateTime<-paste(GPS_raw$DateGMT,GPS_raw$TimeGMT)\r\n\r\n\r\nThen convert it to POSIXct\r\n\r\n\r\nGPS_raw$DateTime<-as.POSIXct(strptime(GPS_raw$DateTime, format = \"%d/%m/%Y %H:%M:%S\"))\r\n\r\n\r\nArguments used:\r\nstrptime is a function to convert characters to time\r\nobjects, where str stands for string, p from\r\nparse, and time is self explanatory.\r\nThen we provide the information of the format we were using, be\r\nspecially careful with the format of your date and time.\r\nFor the example, I used %d/%m/%Y %H:%M:%S\r\nDAY%d - is used for day and goes from 0 to 31%a - is used for the day of the week using the first\r\nthree letters of the name%A - is used for the day\r\nof the week using the full nameMONTH%m - is used for month it goes from 0 to 12%b - is used for the name of the month using the first\r\nthree letters of the name%B - is used for the name\r\nof the month using the full nameYEAR%y - is used for year using two digits%Y - is used for year using four difits\r\nHOURS%H - is used for hours and goes from 0 to 24MINUTES%M is used for minutes and goes from 0 to 60SECONDS%S is used for seconds and goes from 0 to 60\r\nIt is also important to note if you are using slash\r\n(/), dash (-) or any other, and do not\r\nforget the colon (:) when separating the times\r\nNote for excel-users: if you open your file first in\r\nexcel, excel tries to identify the class, and might have transform the\r\ncolumn. Therefore you might need to use one of the examples from stackoverflow\r\nCheck\r\nMany struggles come from the format. If the format you are giving\r\ndoesnt corresponds to the format of your column, it would generate you\r\nNAs.\r\nTherefore, I recommend to create a column to make the trials on the\r\nformat and to always check that you have the correct\r\ntransformations.\r\nHere is an example for checking:\r\n\r\n\r\nrange(GPS_raw$DateTime)\r\n\r\n[1] \"2017-11-02 17:05:30 CET\" \"2017-11-27 09:48:57 CET\"\r\n\r\nNote that in this example it returns the word CET.\r\nThis is because I am in the Central\r\nEuropean Time.\r\nThis might be correct and all good, but it is useful to know that you\r\ncan transform it to you time zone.\r\nCorrect time 🌐\r\nOne way to directly have the format in our time zone, is to specify\r\nthe time zone when converting the class.\r\nHere, I am adding the “GMT” at the end.\r\n\r\n\r\nGPS_raw$GMT<-as.POSIXct(strptime(GPS_raw$DateTime, format = \"%Y-%m-%d %H:%M:%S\"),\"GMT\")\r\n\r\n\r\nAnd now shows GMT.\r\n\r\n\r\nrange(GPS_raw$GMT)\r\n\r\n[1] \"2017-11-02 17:05:30 GMT\" \"2017-11-27 09:48:57 GMT\"\r\n\r\nIdentify your time zone 🗺️\r\nAccording to where your study was made, you might need to change the\r\ntime to your time zone tz\r\nThere are many ways to identify your tz:\r\nYou can click on your area on this map\r\nYou can check the list of name in R using the code\r\nOlsonNames()\r\nYou can check lists like those of wikipedia\r\nIn case you are here because you are interested in analyzing tracking\r\ndata, note that it’s common that the GPS record data in GMT+0.\r\n\r\n\r\n\r\nlubridate\r\nOne option to change your date and time to your time zone is using\r\nthe package lubridate\r\n\r\n\r\nlibrary(lubridate)\r\n\r\n\r\nExample with the data.\r\n\r\n\r\nGPS_tz<-GPS_raw\r\n\r\n\r\nMy original tz:\r\n\r\n\r\nGPS_tz$CET<-ymd_hms(GPS_tz$DateTime, tz = \"Europe/Amsterdam\")\r\n\r\n\r\nMy goal tz:\r\n\r\n\r\nGPS_tz$UTC_4<- with_tz(GPS_tz$CET,tzone = \"America/La_Paz\")\r\n\r\n\r\nManually\r\nIf you know the time difference between the recording and the region\r\nwhere you are, you can also calculate it manually.\r\nFor example:\r\n\r\n\r\nGPS_tz$five_hours_difference <- GPS_tz$CET - 3600*5\r\n\r\n\r\nThats it!\r\nHopefully this would help you.\r\nRecommendations\r\nBe very careful with the format and your time zone.\r\nI would recommend that you always create an extra column in your data\r\nframe to make the transformations, not your original column because if\r\nit returns NAs you will have to load the data frame over and over.\r\nIt takes time to get use to this transformations and there are many\r\ndifferent ways to transform times and date, so if you are struggling,\r\nyou are not the only one, just give it some time.\r\nOther resources 👩🏽‍🏫\r\nThis post in Spanish\r\nMore options to use Date and Times in R also in Spanish\r\nTime zones\r\nmap\r\nList\r\nof time zones\r\nOther\r\ntime transformations\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-06-30-time-formats/blog12.jpg",
    "last_modified": "2023-04-11T13:30:18+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-23-speed/",
    "title": "Speed",
    "description": "How to calculate speed using time and distance between points.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2022-05-23",
    "categories": [
      "R",
      "Biologging",
      "English",
      "Y2022"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nData 📖\r\nDistance 📏\r\nTime ⏰\r\nSpeed 🥏\r\nPlots\r\nFurther reading 👩🏽‍🏫\r\n\r\nIntro\r\nThis post is about how to calculate the speed between points.\r\nThis is useful for example when you want to:\r\n- Classify behavioral states of the individuals\r\n- Clean errors in locations\r\nSee examples on the literature at the bottom of this post.\r\nIn this post we will calculate distance between\r\npoints, then the time between those points, and finally\r\nthe speed.\r\nData 📖\r\nTo do this exercise, load data from the package ‘sula’.  For\r\naccessing the data, you need to have the package installed.\r\nTo install:\r\n\r\n\r\n#devtools::install_github(\"MiriamLL/sula\")\r\n\r\n\r\n\r\n\r\nlibrary(sula)\r\n\r\n\r\nThe data is from 10 tracked individuals.\r\n\r\n\r\nmy_locs<-(GPS_raw)\r\n\r\n\r\nSelect one individual for the exercise.\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\n\r\n\r\nID01<-my_locs %>%\r\n  filter(IDs=='GPS01')\r\n\r\n\r\nDistance 📏\r\nLets select the columns of interest\r\n\r\n\r\nID01_coords<- ID01[,c('Longitude','Latitude')]\r\n\r\n\r\nConvert the data frame into a spatial object\r\n\r\n\r\nID01_spatial <- sp::SpatialPointsDataFrame(coords = ID01_coords, data = ID01)\r\n\r\n\r\nUse the corresponding CRS (Coordinate Reference System).\r\nNote that the CRS might change according to your study area.\r\n\r\n\r\nsp::proj4string(ID01_spatial)= sp::CRS(\"+init=epsg:4326\")\r\n\r\n\r\nUsing the function distm from the package geosphere\r\nto calculate the distance between points.\r\n\r\n\r\nID01_distance<-sapply(2:nrow(ID01_spatial),\r\n                             function(i){geosphere::distm(ID01_spatial[i-1,], ID01_spatial[i,])})\r\n\r\n\r\nTo add this information to your original data frame:\r\n\r\n\r\nID01_distance<-c(NA,ID01_distance)\r\n\r\n\r\nTo transform it to kilometers:\r\n\r\n\r\nID01$dist_km<-ID01_distance/1000\r\n\r\n\r\nTime ⏰\r\nLets select the columns of interest\r\n\r\n\r\nTimes<-paste(ID01$DateGMT,ID01$TimeGMT)\r\n\r\n\r\nTransform to the corresponding time formart\r\n\r\n\r\nTimes<-as.POSIXct(strptime(Times,\"%d/%m/%Y %H:%M:%S\"),\"GMT\")\r\n\r\n\r\n✋🏽 Make sure it did not return NAs, otherwise check the format you\r\nused.\r\nIn this example, we will create a new column with the time using the\r\nfunction lag.\r\n\r\n\r\nLag<-lag(Times)\r\n\r\n\r\nThen, we will include a column with the original time (in time\r\nformat) and the lag as another column on the original data frame.\r\n\r\n\r\nID01$Time1<-Times\r\nID01$Time2<-Lag\r\n\r\n\r\nNow, using the function difftime, we can calculate\r\nthe time difference between those columns.\r\nIn units you can select “secs”, “mins”, “hours”,“days”,\r\n“weeks”.\r\n\r\n\r\nID01$time_dif<-as.numeric(difftime(ID01$Time1,ID01$Time2, units=\"mins\"))\r\n\r\n\r\nYou can also transform it to hours, with basic conversion.\r\n\r\n\r\nID01$time_hr<-as.numeric(ID01$time_dif/60)\r\n\r\n\r\nSpeed 🥏\r\nAs simple as speed\r\n= distance ÷ time\r\n\r\n\r\nID01$speed<-ID01$dist_km/ID01$time_hr\r\n\r\n\r\nPlots\r\nTo visualize the speed from the animal you can also create plots.\r\n\r\n\r\nggplot(ID01, aes(x=speed)) + \r\n  geom_density()+\r\n  theme_minimal()+\r\n  xlab('Speed (km/hr)')\r\n\r\n\r\n\r\nAlso, you can modify the plots according to the units you want to\r\nuse. Here in m/s.\r\n\r\n\r\nggplot(ID01, aes(x=speed*0.277778)) + \r\n  geom_density(color=\"darkblue\", fill=\"lightblue\")+\r\n  theme_minimal()+\r\n  xlab('Speed (m/s)')\r\n\r\n\r\n\r\nFurther reading 👩🏽‍🏫\r\nSpeed Wikipedia\r\ndefinition\r\nConverters Speed-converter\r\nSome papers that use speed for different pourposes:\r\nRaya Rey et al. 2010 “…we\r\nidentified three phases based on sinuosity and speed of the\r\ntrajectory…”\r\nNourani et al. 2022 “…all\r\ndata were filtered by speed to ensure that the position information\r\nrepresented period of flight…“\r\nI hope this helped you!\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-05-23-speed/blog11.jpg",
    "last_modified": "2023-04-11T13:33:47+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-04-07-land-or-not/",
    "title": "Habitat use",
    "description": "How to assign habitat use to animal locations.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2022-04-07",
    "categories": [
      "R",
      "Biologging",
      "English",
      "Y2022"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nData 📖\r\nPoints ⏩\r\nPolygon 🗺️\r\nOver 🏞️\r\nPercentages 🥧\r\nPlot 🖌️\r\nMap\r\nPercentages\r\n\r\nRecommended literature 👩🏽‍🏫\r\n\r\nIntro\r\nThis post is about how to classify locations on your tracking data\r\nbased on an polygon with geographical information.\r\nThis is useful for example when you want to know:\r\n- If the animal is using a specific habitats, and\r\n- To calculate the percentage of use of a specific habitat\r\nSee examples on the recommended literature at the bottom of this\r\npost.\r\nIn this post we will classify tracking locations as\r\nland vs not land.\r\nData 📖\r\nTo do this exercise, load data from the package ‘sula’.  For\r\naccessing the data, you need to have the package installed.\r\nTo install:\r\n\r\n\r\n#devtools::install_github(\"MiriamLL/sula\")\r\n\r\n\r\n\r\n\r\nlibrary(sula)\r\n\r\n\r\nThe data is from 10 tracked individuals.\r\n\r\n\r\nmy_locs<-(GPS_raw)\r\n\r\n\r\nCheck how many locations I have per individual\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\n\r\n\r\nmy_locs %>%\r\n  drop_na(IDs)%>%\r\n  group_by(IDs)%>%\r\n  tally()\r\n\r\n# A tibble: 10 × 2\r\n   IDs       n\r\n   <chr> <int>\r\n 1 GPS01  1038\r\n 2 GPS02  1049\r\n 3 GPS03  1246\r\n 4 GPS04  1031\r\n 5 GPS05   962\r\n 6 GPS06  1231\r\n 7 GPS07  1004\r\n 8 GPS08  1015\r\n 9 GPS09   931\r\n10 GPS10   933\r\n\r\nPoints ⏩\r\nTo transform your GPS locations to spatial data, use the functions\r\nfrom the package sp.\r\nIt would turn your data frame into a\r\nSpatialPointsDataFrame.\r\n\r\n\r\nmy_locs <- as.data.frame(my_locs)\r\nmy_points <-my_locs\r\nsp::coordinates(my_points) <- ~Longitude + Latitude\r\nsp::proj4string(my_points) = sp::CRS(\"+init=epsg:4326\")\r\n\r\n\r\nPolygon 🗺️\r\nFor the polygon, you can download shapefiles according to your\r\ninterest and area of study.\r\nSome sources of country polygons are:\r\n- DIVA-GIS\r\nBut there are many shapefile sources per country,\r\n- For Chile: several exammples are summarized\r\nhere\r\n- For Mexico: IDEA Infraestructura de\r\nDatos Espaciales Abiertos\r\n- For Germany: BSH-GeoSeaPortal\r\n… just to mention a few.\r\nBecause the tracking data from the example was collected in Chile, we\r\nwill use the country shapefile of Chile downloaded from the DIVA-GIS portal.\r\n\r\n\r\n\r\nThe package rgdal has the function\r\nreadOGR which allows us to load the polygon into R.\r\n\r\n\r\nlibrary(rgdal)\r\n\r\n\r\nThe polygon will be read as\r\nSpatialPolygonDataFrame.\r\n\r\n\r\nmy_polygon<-readOGR(file.path(ShapefilesDirectory,'CHL_adm0.shp')) \r\n\r\n\r\nOver 🏞️\r\nThe function over checks which of the points\r\n(my_locs) fall inside the polygon (my_polygon).\r\nBe cautious, the points and the polygon should be at the same\r\nCRS.\r\n\r\n\r\npolygon_proj <- proj4string(my_polygon)\r\n\r\n\r\n\r\n\r\nproj4string(my_points) <- polygon_proj\r\n\r\n\r\nThe function over will return a data frame with the\r\ninformation where the points and the polygon intersect.\r\n\r\n\r\nLandornot_over<- over(my_points, my_polygon)\r\n\r\n\r\nIt depends on the information of your polygon, but in this particular\r\nexample, in the column NAME_0, if the points fall inside the polygon, it\r\nkeeps ‘Chile’ otherwise returns an NA.\r\n\r\n\r\nunique(Landornot_over$NAME_0)\r\n\r\n[1] \"Chile\" NA     \r\n\r\nWe can add this information back to our locations to know which of\r\nthe locations fall inside the territorial land limits or not.\r\n\r\n\r\nmy_locs$landornot <- Landornot_over$NAME_0\r\n\r\n\r\nTo make it easier to remember you can replace Chile and 0 for the\r\ndata available in your polygon.\r\n\r\n\r\nmy_locs$landornot[is.na(my_locs$landornot)] <- 0\r\n\r\n\r\n\r\n\r\nmy_locs<-my_locs %>%\r\n  mutate(landornot=\r\n           case_when(\r\n             landornot == 0 ~ 'notland',\r\n             landornot != 0 ~ 'land',\r\n             TRUE ~ \"U\"))\r\n\r\n\r\nYou can also export this data frame to check in a GIS program.\r\n\r\n\r\nwrite_csv(my_locs,file =paste0(here(\"1Data\"),'/my_locs.csv'))\r\n\r\n\r\nPercentages 🥧\r\nNow using functions from the package tidyverse you\r\ncan quantify the numer of locations that the animal was at land or\r\nnot.\r\n\r\n\r\nHabitatuse<-my_locs %>%\r\n  drop_na(IDs)%>%\r\n  group_by(IDs,landornot)%>%\r\n  count()%>%\r\n  pivot_wider(names_from = landornot, values_from = n)\r\n\r\n\r\n… and also calculate the percentage of time using one habitat or the\r\nother.\r\n\r\n\r\nHabitatuse$total<-Habitatuse$land+Habitatuse$notland\r\nHabitatuse$prop_land<-Habitatuse$land*100/Habitatuse$total\r\nHabitatuse$prop_notland<-Habitatuse$notland*100/Habitatuse$total\r\nHabitatuse$prop<-Habitatuse$prop_land+Habitatuse$prop_notland\r\n\r\n\r\nPlot 🖌️\r\nMap\r\nPlotting the data will help to confirm if the classification is\r\ncorrect.\r\n\r\n\r\nggplot()+\r\n  geom_polygon(data=my_polygon, aes(x=long, y=lat, group=group), color='black',fill='grey')+\r\n  geom_point(data=my_locs, aes(x=Longitude,y=Latitude,color=landornot))+\r\n  scale_color_manual(values=c('#9b2226','#005f73'))+\r\n  theme_bw()+\r\n  theme(legend.position = 'top')+\r\n  labs(x = \"Longitude\", y=\"Latitude\",color='')+\r\n  xlim(-110, -108)+\r\n  ylim(-28.5, -26.5)\r\n\r\n\r\n\r\nTo customize your plot, you can change many arguments, for example to\r\nchange the theme_bw here are\r\nother options.Do not forget to adjust your xlim and ylim to your\r\ncoordinates.\r\nPercentages\r\nYou can also plot the percentage of habitat use per individual.\r\nTo do this, preparing the information in a long format will\r\nmake it easier to plot.\r\n\r\n\r\nHabitatuse_prop<-Habitatuse %>%\r\n  pivot_longer(c(prop_land,prop_notland),\r\n               names_to = \"habitat_use\",\r\n               values_to = \"prop_use\" )\r\n\r\n\r\n\r\n\r\nggplot(Habitatuse_prop, aes(fill=habitat_use, y=prop_use, x=IDs)) + \r\n  geom_bar(position=\"fill\", stat=\"identity\")+\r\n  scale_fill_manual(values=c('#9b2226','#005f73'))+\r\n  theme_bw()+\r\n  theme(legend.position = 'top')+\r\n  scale_y_continuous(expand = c(0,0)) \r\n\r\n\r\n\r\nRecommended literature 👩🏽‍🏫\r\nFunction over:Geometry\r\noverlays\r\nExamples in the literature:Quantify\r\nhabitats visitedIndividual\r\nspecialization in an ecological winnerTracking\r\npositions inside the protected areas\r\nIf you can think on another sources of geographical data please do\r\nnot hesitate to write me to include it on the list.\r\nFor more details or suggestions, or just to say hi you can also\r\nalways write me an email\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-04-07-land-or-not/blog10b.jpg",
    "last_modified": "2023-04-11T13:33:12+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-03-22-interpolation/",
    "title": "Interpolation",
    "description": "How to interpolate tracking data.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2022-03-22",
    "categories": [
      "R",
      "Biologging",
      "English",
      "Y2022"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nData 📖\r\nIdentify trips 🛩️\r\nInterpolate 🌐\r\ninterpolate_trips\r\ninterpolate_all\r\n\r\nPlot 🖌️\r\nSummary 👩🏽‍💻\r\nRecommended sources 📑\r\n\r\nIntro\r\nInterpolation is a type of estimation, a method of constructing (or\r\nfinding) new data ponts based on the range of a discrete set of known\r\ndata points (source: wikipedia)\r\nThis post is about:  - How to prepare your data and use the\r\nfunction interpolate from the package sula for\r\ninterpolating your tracking data \r\nInterpolating your data might help you to:  - Fill\r\ngaps on your tracking data, and/or  - To\r\nmake comparable trips when individuals were tracked at\r\ndifferent intervals  … read more at the end of this page.\r\n⚠️However, while interpolating you should be very\r\ncautious, because you are creating locations where the bird might have\r\nnot been.\r\nThis post step by step:\r\n1. Load data\r\n2. Identify nest location / or central location\r\n3. Classify if the animal was inside the central location or\r\noutside\r\n4. Count the number of trips\r\n5. Interpolate only when the animal was on a trip\r\nYou can also just go directly to : interpolate\r\nData 📖\r\nTo do this exercise, load data from the package ‘sula’.  For\r\naccessing the data, you need to have the package installed.\r\nTo install:\r\n\r\n\r\ndevtools::install_github(\"MiriamLL/sula\")\r\n\r\n\r\n\r\n\r\nlibrary(sula)\r\n\r\n\r\nThe data is from 10 tracked individuals.\r\n\r\n\r\nGPS_raw<-(GPS_raw)\r\n\r\n\r\nSelect only one individual.\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\n\r\n\r\nID01_track<-GPS_raw %>%\r\n  dplyr::filter(IDs=='GPS01')\r\n\r\n\r\nIdentify trips 🛩️\r\nIdentify the trips allows to remove all the central locations\r\n(e.g. the nest), because usually you will be not interested in\r\ninterpolating the locations where the animal was at their central\r\nlocation, only when it was in a trip.\r\nNest location 🐣\r\nIs also often the case that at fieldwork, the GPS are activated to\r\nstart recording data just after releasing the animal back to their\r\ncentral location (-nest-)\r\nTherefore, the first location recorded will correspond to their\r\nnest.\r\nTo identify the first location I use the function\r\nlocate_nest from the package sula.\r\nBecause you might have different column names, you can add the names\r\nof your columns here in ‘column_lon’ and ‘column_lat’.\r\n\r\n\r\nID01_nest<-locate_nest(GPS_data = ID01_track,\r\n                         column_lat = 'Longitude',\r\n                         column_lon = 'Latitude')\r\n\r\n# A tibble: 1 × 2\r\n  Longitude Latitude\r\n      <dbl>    <dbl>\r\n1     -27.2    -109.\r\n\r\nManually: If you did not activate the GPS at their\r\nnest but you know the nest location, you can manually write it down.\r\n\r\n\r\nID01_nest<-data.frame(Longitude=-109.4531,\r\n                     Latitude=-27.20097)\r\n\r\n\r\nIdentify trips 🛩️\r\nNow that you have the nest location, the function\r\nidentify_trips from the package sula\r\nhelps you to identify when the bird was out on a trip.\r\nThe function adds a new column, where ‘Y’ means that the location is\r\noutside the range you select (in the example 1 km), and ‘N’ means that\r\nthe location is inside the range you select.\r\nTherefore ‘Y’ is when the bird was on a trip, and ‘N’ is when it was\r\nat the nest.\r\n\r\n\r\nID01_trips<-identify_trips(GPS_data=ID01_track,\r\n                           Nest_location=ID01_nest,\r\n                           Distance_km=1)\r\n\r\n\r\nCount trips 🧮\r\nThe function count_trips from the package\r\nsula removes the locations that are not trips (for\r\nexample removes all rows where the animal was at the central location)\r\nand adds a column with the number of the trip.\r\n\r\n\r\nID01_onlytrips<-count_trips(GPS_data=ID01_trips)\r\n\r\n\r\nTo check when the trips started and ended you can also use functions\r\nfrom the package tidyverse.\r\n\r\n\r\nID01_onlytrips %>% \r\n  group_by(trip_number)%>%\r\n  summarise(start=paste(first(DateGMT),first(TimeGMT)),\r\n            end=paste(last(DateGMT),last(TimeGMT)))\r\n\r\n# A tibble: 5 × 3\r\n  trip_number start               end                \r\n  <chr>       <chr>               <chr>              \r\n1 trip_1      02/11/2017 19:34:31 02/11/2017 20:09:24\r\n2 trip_2      03/11/2017 12:44:04 03/11/2017 14:30:00\r\n3 trip_3      04/11/2017 07:45:17 04/11/2017 09:41:28\r\n4 trip_4      04/11/2017 17:05:36 04/11/2017 20:41:10\r\n5 trip_5      05/11/2017 09:06:13 05/11/2017 11:26:14\r\n\r\nIf you know when the trip started and ended, you can also add the\r\ntrip classification manually, using also functions from\r\nthe package tidyverse.\r\n\r\n\r\nID01_onlytrips <- ID01_trips %>%\r\n  mutate(trip_number=\r\n           case_when(\r\n             DateGMT == '02/11/2017' & TimeGMT >= '19:34:31' & TimeGMT <= '20:09:24' ~ 'trip_1',\r\n             DateGMT == '03/11/2017' & TimeGMT >= '12:44:04' & TimeGMT <= '14:30:00' ~ 'trip_2',\r\n             DateGMT == '04/11/2017' & TimeGMT >= '07:45:17' & TimeGMT <= '09:41:28' ~ 'trip_3',\r\n             DateGMT == '04/11/2017' & TimeGMT >= '17:05:36' & TimeGMT <= '20:41:10' ~ 'trip_4',\r\n             DateGMT == '05/11/2017' & TimeGMT >= '09:06:13' & TimeGMT <= '11:26:14' ~ 'trip_5',\r\n             TRUE ~ \"nest\")) %>%\r\n  filter(trip_number != 'nest')\r\n\r\n\r\nInterpolate 🌐\r\ninterpolate_trips\r\nOnce the data frame contains columns with Longitude, Latitude, and\r\ntrip_number, the trips can be interpolated.\r\nThe function interpole_trips from the package\r\nsula helps you to interpolate the locations based on an\r\ninterval. In the examples below 900 secs = 15 minutes and 60 sec = 1\r\nminute\r\nBecause you might have different column names, this function has a\r\nlot of arguments, but basically you just need to replace the name of\r\nyour data frame, the interval you are interested to do the\r\ninterpolation, the column names, and the format your date and time is\r\npresented.\r\n\r\n\r\nID01_interpolated15m<-interpolate_trips(GPS_data=ID01_onlytrips,\r\n                                     interval='900 sec',\r\n                                     column_date='DateGMT',\r\n                                     column_time='TimeGMT',\r\n                                     column_trip='trip_number',\r\n                                     column_lat='Latitude',\r\n                                     column_lon='Longitude',\r\n                                     datetime_format<-\"%d/%m/%Y %H:%M:%S\")\r\n\r\n\r\n\r\n\r\nID01_interpolated1m<-interpolate_trips(GPS_data=ID01_onlytrips,\r\n                                     interval='60 sec',\r\n                                     column_date='DateGMT',\r\n                                     column_time='TimeGMT',\r\n                                     column_trip='trip_number',\r\n                                     column_lat='Latitude',\r\n                                     column_lon='Longitude',\r\n                                     datetime_format<-\"%d/%m/%Y %H:%M:%S\")\r\n\r\n\r\ninterpolate_all\r\nIn case you want to interpolate a specific trip, or everything\r\n(including the central location), and you already have a datetime column\r\nin the correct format (so R can understand is date and time) there is\r\nalso the function interpolate in the package\r\nsula that interpolates all the locations.\r\nFor example, to interpolate a specific trip, subset the trip you are\r\ninterested in interpolating.\r\n\r\n\r\nGPS01_trip5<-GPS_preparado %>%\r\n  filter(IDs=='GPS01')%>%\r\n  filter(trip_number=='trip_5')\r\n\r\n\r\nUse the function interpolate. Here I select the\r\ndataframe, the interval ofinterest, and the name of the columns that\r\nwill be included in the interpolation.\r\n\r\n\r\nGPS01_trip1_interpolated<-interpolate(GPS_data = GPS01_trip5,\r\n                                      interval='10 sec',\r\n                                      column_datetime = 'dia_hora',\r\n                                      column_lat = 'Latitude',\r\n                                      column_lon = 'Longitude')\r\n\r\n\r\nPlot 🖌️\r\nNow lets compare the before and after, the tracking data vs the\r\ninterpolated data.\r\nThe package patchwork lets us see the plots side by\r\nside.\r\n\r\n\r\nlibrary(patchwork)\r\n\r\n\r\nCreate three plots, one using the original points, and two using the\r\ninterpolation to compare.\r\n\r\n\r\nOriginal_track<-ggplot(ID01_onlytrips, aes(x=Longitude, y=Latitude, color=trip_number)) + \r\n  geom_point()+\r\n  theme_bw()+\r\n  ggtitle('Original tracking data')+\r\n  theme(legend.position='none')\r\nInterpolated_15m<-ggplot(ID01_interpolated15m, aes(x=Longitude, y=Latitude, color=trip_number)) + \r\n  geom_point()+\r\n  theme_bw()+\r\n  ggtitle('Interpolated to 15 mins')+\r\n  theme(legend.position='none')\r\nInterpolated_1m<-ggplot(ID01_interpolated1m, aes(x=Longitude, y=Latitude, color=trip_number)) + \r\n  geom_point()+\r\n  theme_bw()+\r\n  ggtitle('Interpolated to 1 min')+\r\n  theme(legend.position='right')\r\nOriginal_track+Interpolated_15m+Interpolated_1m\r\n\r\n\r\n\r\nNow it is up to you to decide which interpolation interval fits\r\nbetter to your study.\r\nSummary 👩🏽‍💻\r\nTL;DR (too long; didn’t read)\r\n\r\n\r\nlibrary(sula)\r\nlibrary(tidyverse)\r\n\r\nID01_track<-GPS_raw %>% filter(IDs=='GPS01')\r\n\r\nID01_nest<-data.frame(Longitude=-109.4531,Latitude=-27.20097)\r\n\r\nID01_trips<-identify_trips(GPS_data=ID01_track,Nest_location=ID01_nest,Distance_km=1)\r\n\r\nID01_onlytrips<-count_trips(GPS_data=ID01_trips)\r\n\r\nID01_interpolated15m<-interpolate_trips(GPS_data=ID01_onlytrips,\r\n                                        interval='900 sec',\r\n                                        column_date='DateGMT',\r\n                                        column_time='TimeGMT',\r\n                                        column_trip='trip_number',\r\n                                        column_lat='Latitude',\r\n                                        column_lon='Longitude',\r\n                                        datetime_format<-\"%d/%m/%Y %H:%M:%S\")\r\n\r\n\r\nRecommended sources 📑\r\nSome of the reasons to interpolate data are:\r\nTo fit the GPS locations with diving data. For example: Lerma\r\net al. 2020, Browning\r\net al. 2017\r\nBecause the recorded data was different between individuals, and\r\nthus interpolating data provides fixed intervals. For example: Borrmann et\r\nal. 2019\r\nTo fill occasional gaps in the tracking data, particularly for\r\nanimals that dive and do not receive signal when submerged. For example:\r\nIorio-Merlo\r\net al. 2022.\r\nIf you can think on another case when interpolation is necessary\r\nplease do not hesitate to write me to include it on the list.\r\nAlso if you use the function from the package sula\r\nplease consider including the package in your citations.\r\nFor more details or suggestions you can also always write me an email\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-03-22-interpolation/blog9.jpg",
    "last_modified": "2023-04-11T13:22:27+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-02-24-timeoverlaps/",
    "title": "Time overlaps",
    "description": "Find overlapping time periods.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2022-02-24",
    "categories": [
      "R",
      "Biologging",
      "English",
      "Y2022"
    ],
    "contents": "\r\nIntro\r\nThis post is about how to find overlapping times between your tracked\r\nindividuals.  This might help you to:  - Identify periods where\r\nyou have gaps for each individual, or  - To\r\nselect which periods are comparable among individuals\r\nthat might have been tracked on different periods \r\nData\r\nTo replicate the exercise, load data from the package ‘sula’. \r\nFor accessing the data, you need to have the package installed.\r\n\r\n\r\n#devtools::install_github(\"MiriamLL/sula\")\r\nlibrary(sula)\r\n\r\n\r\nThe data is from 10 tracked individuals.\r\n\r\n\r\nGPS_raw<-(GPS_raw)\r\n\r\n\r\nPlot\r\nFor this exercise you should install or have installed the package\r\nggplot.\r\n\r\n\r\nlibrary(ggplot2)\r\n\r\n\r\nIn the example data, time and date are in separated columns,\r\ntherefore the first step is to join those columns.\r\n\r\n\r\nGPS_raw$DateTime<-paste(GPS_raw$DateGMT,GPS_raw$TimeGMT)\r\n\r\n\r\nFor plotting times, it is important that the column with the\r\ntimestamps is in a time format. Be cautious with the format of your time\r\nstamps.\r\n\r\n\r\nGPS_raw$DateTime<-as.POSIXct(strptime(GPS_raw$DateTime, \"%d/%m/%Y %H:%M:%S\"),tz = \"GMT\")\r\n\r\n\r\nNow for plotting, you can use the timestamp for the x axis and the\r\nIDs of each individual as the y axis.\r\nIf you want each individual to be plotted in different color, you can\r\nalso add the name of the column after the argument\r\ncolor=.\r\n\r\n\r\nPlot_tracking<-ggplot(data=GPS_raw,\r\n                      aes(x=DateTime,\r\n                          y=IDs,\r\n                          color=IDs))+\r\n    geom_point(size=3)+\r\n    geom_line()+\r\n    theme_bw()\r\nPlot_tracking\r\n\r\n\r\n\r\nModify legend\r\nBecause is a ggplot, many things can be further customized.\r\nSuch as the legends\r\nHere, I remove the legend from the side (legend.position=‘none’),\r\nmodify the legend in the x axis to ‘individuals’, and change the angle\r\nof the x axis to 60 degrees.\r\n\r\n\r\nPlot_tracking+\r\n    theme(legend.position='none')+\r\n    labs(x = \"\", y = \"Individuals\") +\r\n        theme(axis.text.x=element_text(angle=60, hjust=1))+\r\n    theme(plot.title = element_text(size = 10, face = \"bold\"))\r\n\r\n\r\n\r\nChange breaks\r\nYou can also select how detailed the x axis legend should be and how\r\noften you want the breaks.\r\nFor one day breaks:\r\n\r\n\r\nPlot_tracking + scale_x_datetime(date_labels = \"%d %b %Y\",date_breaks = \"1 day\")\r\n\r\n\r\n\r\nFor one week breaks:\r\n\r\n\r\nPlot_tracking + scale_x_datetime(date_labels = \"%d %b %Y\",date_breaks = \"1 week\")\r\n\r\n\r\n\r\nFor one month breaks:\r\n\r\n\r\nPlot_tracking + scale_x_datetime(date_labels = \"%d %b %Y\",date_breaks = \"1 month\")\r\n\r\n\r\n\r\nIt doesnt show, because all were in the same month, but it might be\r\nuseful for you to know this argument.\r\nAdd lines\r\nYou can also mark separations between periods using a line.\r\nTo do so, first you have to make the period where you want to make\r\nthe line as POSIXct\r\n\r\n\r\nPA<-as.POSIXct(strptime(\"2017-11-07 00:00:00\", \"%Y-%m-%d %H:%M:%S\"),tz = \"GMT\")\r\n\r\n\r\nThen you add the line to the ggplot using the function geom_vline (v\r\nfrom vertical line)  Use the period you have interest on getting the\r\nline as xintercept, and  The\r\nlinetypes options can be seen here.\r\nThe color depends on your preference, here I use red to make it easy to\r\nsee at first glance.\r\n\r\n\r\nPlot_tracking+\r\n  geom_vline(xintercept=PA,\r\n                linetype=4, colour=\"red\")\r\n\r\n\r\n\r\nAdd rectangle\r\nNow if you want to add a rectangle, there are many option but I\r\nprefer to use annotation\r\nFirst I create an object with the timestamps of where I want the\r\nrectangle to begging and end.\r\n\r\n\r\nPA<-as.POSIXct(strptime(\"2017-11-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\"),tz = \"GMT\")\r\nPB<-as.POSIXct(strptime(\"2017-11-07 00:00:00\", \"%Y-%m-%d %H:%M:%S\"),tz = \"GMT\")\r\n\r\n\r\nThen I add it to the plot  The xmin is the time\r\nwhere the rectangle will start, and the xmax where it\r\nwould end.  Because I want the rectangle to cover the area I used\r\n-Inf and Inf.  The color is in\r\nfill, and the alpha is to have some\r\ntransparency (the lower the value the more transparent will be, and the\r\nvalues go from 0 to 1).\r\n\r\n\r\nPlot_tracking + annotate(\"rect\",\r\n                         xmin = PA, xmax = PB, \r\n                         ymin = -Inf, ymax = Inf,  \r\n                         fill = \"blue\", alpha=0.1)\r\n\r\n\r\n\r\nExport\r\nTo export your plot, you can use the argument\r\nggsave\r\nThe simplest is just to give it a name to your plot, and ggsave will\r\nsave the latest plot you have created.\r\nTo be able to see it other programs, you will have to give it an\r\nextention. Some options are: png, eps, pdf, jpeg, tiff, bmp or svg\r\n\r\n\r\nggsave(filename = \"~/Figure.png\")\r\n\r\n\r\nNote that if you want the figure to be saved on specific folder, you\r\nneed to include the path in the file name.\r\n\r\n\r\nggsave(filename = \"~Results/Figure.png\")\r\n\r\n\r\nIf you want to create several figures and want to export just\r\nspecific ones, you can also use the name of the plot to export only that\r\none.\r\n\r\n\r\nggsave(Plot_tracking, \r\n       filename = \"~/Figura.png\")\r\n\r\n\r\nAlso, if you want specific widths and heights, or even dpi, you can\r\nalso include it. Just note that the size of the letters might need to be\r\nadjusted.\r\n\r\n\r\nggsave(Plot_tracking, \r\n       filename = \"~/Figura.png\",\r\n       width = 24, \r\n       height = 24, \r\n       units = \"in\",\r\n       dpi = 500)\r\n\r\n\r\nI hope this was useful for you, and if you want to go deep in some\r\naspects of ggplot check the recommended sources below.\r\nRecommended sources\r\nggplot2\r\nggsave\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-02-24-timeoverlaps/blog8.jpg",
    "last_modified": "2023-04-11T13:22:49+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-01-21-sharedareas/",
    "title": "Shared Areas",
    "description": "Calculate area per polygon, their intersection and the shared areas",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2022-01-21",
    "categories": [
      "R",
      "spatial",
      "shapefiles",
      "English"
    ],
    "contents": "\r\nIntro\r\nHere, some steps for:\r\nGenerating kernel polygons\r\nCalculating the intersection between two polygons\r\nPlotting polygons and their intersection\r\nCreating a table with the shared areas between two polygons\r\nData\r\nTo replicate the exercise, load data from the package ‘sula’. For accessing the data, you need to have the package installed.\r\n\r\n\r\n#devtools::install_github(\"MiriamLL/sula\")\r\nlibrary(sula)\r\n\r\n\r\n\r\nThe data is from 10 tracked individuals.\r\n\r\n\r\nGPS_raw<-(GPS_raw)\r\n\r\n\r\n\r\nCreate polygons\r\nSelect which individuals you want to compare\r\n\r\n\r\nGPS01<-subset(GPS_raw,GPS_raw$IDs=='GPS01')\r\nGPS02<-subset(GPS_raw,GPS_raw$IDs=='GPS02')\r\n\r\n\r\n\r\nWith the following function you can create the polygon of the individual using an specific value.\r\nYour need to provide the name of the column that contains the latitude, the name of the column that contains the longitude, and the value you want to calculate (E.g. core=50, general=95).\r\n\r\n\r\ncreate_polygon<-function(Data=Data, lon_col=lon_col,lat_col=lat_col,value=value){\r\n  \r\n  Data<-Data\r\n  Data$Longitude<-Data[[lon_col]]\r\n  Data$Latitude<-Data[[lat_col]]\r\n    \r\n  #convert to spatial\r\n  DataSp<-as.data.frame(Data)\r\n  sp::coordinates(DataSp) <- c(\"Longitude\", \"Latitude\")\r\n  sp::proj4string(DataSp) <- sp::CRS(\"+init=epsg:4326\")\r\n  \r\n  #create polygon\r\n  DataSp<-adehabitatHR::kernelUD(DataSp,h=\"href\") # Using reference\r\n  Data_50<-adehabitatHR::getverticeshr(DataSp,percent=value)\r\n  \r\n  Data_sf_50<-sf::st_as_sf(Data_50)\r\n  \r\n  return(Data_sf_50)\r\n}\r\n\r\n\r\n\r\nCalculate polygons of 50%.\r\nSome warnings may appear\r\n\r\n\r\nGPS01_50<-create_polygon(Data=GPS01,lat_col=\"Latitude\",lon_col=\"Longitude\",value=50)\r\nGPS02_50<-create_polygon(Data=GPS02,lat_col=\"Latitude\",lon_col=\"Longitude\",value=50)\r\n\r\n\r\n\r\nCalculate polygons of 95%.\r\n\r\n\r\nGPS01_95<-create_polygon(Data=GPS01,lat_col=\"Latitude\",lon_col=\"Longitude\",value=95)\r\nGPS02_95<-create_polygon(Data=GPS02,lat_col=\"Latitude\",lon_col=\"Longitude\",value=95)\r\n\r\n\r\n\r\nCompare\r\nWith the function intersection of the package sf you can obtain the area where both polygons intersect\r\n\r\n\r\nlibrary(sf)\r\n\r\n\r\n\r\n\r\n\r\n\r\nSource: Geocompr\r\n\r\n\r\nIntersection_95<-st_intersection(GPS01_95,GPS02_95)\r\nIntersection_50<-st_intersection(GPS01_50,GPS02_50)\r\n\r\n\r\n\r\nPlot\r\nUsing the following function plot_overlaps and the package ggplot, you can visualize where the intersection is occurring\r\n\r\n\r\nlibrary(ggplot2)\r\n\r\n\r\n\r\n\r\n\r\nplot_overlaps<-function(ID1_95=ID1_95,ID1_50=ID1_50,ID2_95=ID2_95,ID2_50=ID2_50){\r\n  \r\n  Plot<-ggplot2::ggplot()+\r\n  \r\n    ggplot2::geom_sf(data = ID1_95,color='#d00000',fill = \"#d00000\",alpha=0.3,size=1)+ \r\n    ggplot2::geom_sf(data = ID2_95,color='#3f88c5',fill = \"#3f88c5\",alpha=0.3,size=1)+\r\n    ggplot2::geom_sf(data = Intersection_95,  color='#ffba08', fill = \"#ffba08\",alpha=0.3,size=1)+\r\n    \r\n    ggplot2::geom_sf(data = ID1_50,color='#d00000',fill = \"#d00000\",alpha=0.7,size=1)+\r\n    ggplot2::geom_sf(data = ID2_50,color='#3f88c5', fill = \"#3f88c5\",alpha=0.7,size=1)+ \r\n    ggplot2::geom_sf(data = Intersection_50,  color='#ffba08', fill = \"#ffba08\",alpha=0.7,size=1)+\r\n    \r\n    ggplot2::labs(x = \"Longitude\", y=\"Latitude\")+\r\n    \r\n    theme_bw()\r\n  \r\n  return(Plot)\r\n}\r\n\r\n\r\n\r\nIt would show a map with your polygons\r\n\r\n\r\noverlap_plot<-plot_overlaps(ID1_95=GPS01_95,\r\n                            ID1_50=GPS01_50,\r\n                            ID2_95=GPS02_95,\r\n                            ID2_50=GPS02_50)\r\n  \r\noverlap_plot\r\n\r\n\r\n\r\n\r\nCreate table\r\nOnce you have your polygons for each individual and also the intersection between polygons, you can now create a table using the following custom function table_areas\r\nTo calculate the shared area, the function follows the formula as in Hedd et al. 2014 and McFarlane Tranquila et al. 2013\r\n\r\n\r\ntable_areas<-function(ID1_50=ID1_50,\r\n                      ID2_50=ID2_50,\r\n                      ID1_95=ID1_95,\r\n                      ID2_95=ID2_95,\r\n                      Intersection_50=Intersection_50,\r\n                      Intersection_95=Intersection_95){\r\n  \r\n  Tabla<-data.frame(\r\n  UDs=c(\"50\",\"95\"),\r\n  \r\n  ID1_area_km2=c(\r\n    round(as.numeric(units::set_units(st_area(ID1_50),km^2)),2),\r\n    round(as.numeric(units::set_units(st_area(ID1_95),km^2),2))\r\n    ),\r\n  \r\n  ID2_area_km2=c(\r\n    round(as.numeric(units::set_units(st_area(ID2_50),km^2),2)),\r\n    round(as.numeric(units::set_units(st_area(ID2_95),km^2),2))\r\n    ),\r\n  \r\n  intersection_area_km2=c(\r\n    round(as.numeric(units::set_units(st_area(Intersection_50),km^2),2)),\r\n    round(as.numeric(units::set_units(st_area(Intersection_95),km^2),2))\r\n  )\r\n  )\r\n  \r\n  Tabla$shared_area_percent<-\r\n  (Tabla$intersection_area_km2)/\r\n    (\r\n      (Tabla$ID1_area_km2 - Tabla$intersection_area_km2) + \r\n       (Tabla$ID2_area_km2 - Tabla$intersection_area_km2) + \r\n       Tabla$intersection_area_km2)\r\n  \r\n  return(Tabla)\r\n}\r\n\r\n\r\n\r\nThe table contains the area of each polygon, the intersection and the shared areas\r\n\r\n\r\nareas_table<-table_areas(ID1_50=GPS01_50,\r\n                      ID2_50=GPS02_50,\r\n                      ID1_95=GPS01_95,\r\n                      ID2_95=GPS02_95,\r\n                      Intersection_50=Intersection_50,\r\n                      Intersection_95=Intersection_95)\r\n\r\n\r\n\r\nIt should return a table as the following:\r\n\r\n\r\nUDs\r\n\r\n\r\nID1_area_km2\r\n\r\n\r\nID2_area_km2\r\n\r\n\r\nintersection_area_km2\r\n\r\n\r\nshared_area_percent\r\n\r\n\r\n50\r\n\r\n\r\n7.5\r\n\r\n\r\n8\r\n\r\n\r\n5\r\n\r\n\r\n0.4761905\r\n\r\n\r\n95\r\n\r\n\r\n546.0\r\n\r\n\r\n380\r\n\r\n\r\n215\r\n\r\n\r\n0.3023910\r\n\r\n\r\nExport\r\nTo export the table as csv:\r\n\r\n\r\nwrite_csv(areas_table,'areas_table.csv')\r\n\r\n\r\n\r\nTo export the polygons as shapefiles:\r\n\r\n\r\nst_write(GPS01_50, \"GPS01_50.shp\")\r\nst_write(GPS02_50, \"GPS02_95.shp\")\r\nst_write(Intersection_50, \"Intersection_50.shp\")\r\n\r\nst_write(GPS01_95, \"GPS01_95.shp\")\r\nst_write(GPS02_95, \"GPS02_95.shp\")\r\nst_write(Intersection_95, \"Intersection_95.shp\")\r\n\r\n\r\n\r\nRecommended literature\r\nGeocomputation in R\r\nShared areas formula by Hedd et al. 2018 and McFarlane Tranquila et al. 2013\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-01-21-sharedareas/blog7.jpg",
    "last_modified": "2022-03-22T10:53:03+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-11-25-embc/",
    "title": "EMbC",
    "description": "Classify behaviours using Expectation-Maximization Binary Clustering.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2021-11-25",
    "categories": [
      "R",
      "Biologging",
      "English",
      "Y2021"
    ],
    "contents": "\r\nIntro\r\nIn this post, you will learn how to:  - Classify behavioural\r\nstates during foraging trips from test data from Masked boobies.\r\n\r\nData\r\nLoad data. This test data is from masked boobies.  To access the\r\ndata you have to install the package sula:\r\ndevtools::install_github(“MiriamLL/sula”)\r\n\r\n\r\n#devtools::install_github(\"MiriamLL/sula\")\r\nlibrary(sula)\r\n\r\n\r\n\r\n\r\nGPS_raw<-as.data.frame(GPS_raw)\r\nGPS_ind<-subset(GPS_raw,GPS_raw$IDs=='GPS01')\r\n\r\n\r\nNest or no nest?\r\nThe data I am using does not include locations when\r\nthe animal was on the nest.\r\nTo remove the nest locations, in the package sula\r\nthere is this function recortar_periodo which allows\r\nyou to filter your data and keep the period when the bird was at\r\nsea.\r\nFor the example, I know the time when this individual (GPS_01)\r\nstarted and ended its trip and keep the locations inside this time\r\nrange.\r\nIf you dont have this information, you might need to first identify\r\nthe start and end of trips.\r\n\r\n\r\nGPS_ind<-recortar_periodo(GPS_data=GPS_ind,\r\n                                inicio='02/11/2017 18:10:00',\r\n                                final='05/11/2017 14:10:00',\r\n                                dia_col='DateGMT',\r\n                                hora_col='TimeGMT',\r\n                                formato=\"%d/%m/%Y %H:%M:%S\")\r\n\r\n\r\n ES: El track original contenia 1038 filas y el track editado contiene 986 filas \r\n EN: The original track had 1038 rows, and the edited track has 986\r\n\r\nNext, I create a new column named tStamp and transformed it to the\r\ncorresponding class.\r\n\r\n\r\nGPS_ind$tStamp<-paste(GPS_ind$DateGMT,GPS_ind$TimeGMT)\r\nGPS_ind$tStamp <- as.POSIXct(strptime(GPS_ind$tStamp,\"%d/%m/%Y %H:%M:%S\"),\"GMT\")\r\nclass(GPS_ind$tStamp)\r\n\r\n[1] \"POSIXct\" \"POSIXt\" \r\n\r\nCheck that you have the right class for your columns.\r\n\r\n\r\nGPS_ind$lon<-as.numeric(GPS_ind$Longitude)\r\nGPS_ind$lat<-as.numeric(GPS_ind$Latitude)\r\nGPS_ind$id <- as.factor(GPS_ind$IDs)\r\n\r\n\r\nThen I select only columns that will be important in the\r\nanalyses.\r\n\r\n\r\nlibrary(tidyverse)\r\n\r\n\r\n\r\n\r\nData<-GPS_ind%>%\r\n  select('id','tStamp','lon','lat')\r\nhead(Data)\r\n\r\n      id              tStamp       lon       lat\r\n17 GPS01 2017-11-02 18:11:57 -109.4530 -27.20092\r\n18 GPS01 2017-11-02 18:16:04 -109.4531 -27.20096\r\n19 GPS01 2017-11-02 18:20:10 -109.4530 -27.20096\r\n20 GPS01 2017-11-02 18:24:16 -109.4530 -27.20094\r\n21 GPS01 2017-11-02 18:28:24 -109.4530 -27.20096\r\n22 GPS01 2017-11-02 18:32:29 -109.4531 -27.20099\r\n\r\nEMbC\r\nI strongly recommend to read this article by Garriga\r\net al. 2016 and to check the vignette.\r\nAs in vignette: ‘The Expectation-maximization binary clustering\r\n(EMbC) is a general purpose, unsupervised, multi-variate, clustering\r\nalgorithm, driven by two main motivations: (i) it looks for a good\r\ncompromise between statistical soundness and ease and generality of use\r\n- by minimizing prior assumptions and favouring the semantic\r\ninterpretation of the final clustering - and, (ii) it allows taking into\r\naccount the uncertainty in the data. These features make it specially\r\nsuitable for the behavioural annotation of animal’s movement\r\ntrajectories.’\r\nYou need to have the package installed otherwise you need to install\r\nit using the install.packages(‘EMbC’).\r\n\r\n\r\nlibrary(EMbC)\r\n\r\n\r\nIn the package EMbC, the function stbc performs the\r\nstandard velocity/turn clustering of the trajectory.\r\nIn the script, [2:4] means that you are including from the 2nd to the\r\n4th column. These columns should be 2th - tStamp, 3th - lon, and 4th -\r\nlat.\r\nThe -1 in info means that any iteration is supress.\r\n\r\n\r\nData_bc<-stbc(Data[2:4],info=-1) \r\n\r\n[1]   0  -0.0000e+00       4       986\r\n[1] ... Stable clustering\r\n\r\nCheck delimiters\r\nMean and sd\r\nIn the package EMbC, the function stts offers a\r\ncompact view of the parameter set.\r\nLL stands for Low velocity Low turn\r\nLH stands for Low velocity High turn\r\nHL stands for High velocity Low turn\r\nHH stands for High velocity High turn\r\nkn is the marginal distribution of the cluster in absolute and\r\npercentage values\r\n\r\n\r\nstts(Data_bc)\r\n\r\n\r\nMins and Maxs\r\nYou can also check the mimimum and maximum velocity and radians\r\n(turning angle).\r\nX1.min is the minimum velocity\r\nX2.min is the minimum turning angle\r\nX1.max is the maximum velocity\r\nX2.max is the maximum turning angle\r\n\r\n\r\nData_bc@R\r\n\r\n\r\nHere is important that you check that these values make sense.\r\nTurning angle should be between 0 and 3.14. Velocity varies according to\r\nyour species.\r\nFor boobies this information can be translated to:\r\nLL for Resting\r\nLH for Intense foraging\r\nHL for Travelling\r\nHH for Relocating\r\nYou can also compare your results with Table 2 in Mendez et al. 2017, or in\r\nmethods from Lerma\r\net al. 2020\r\nGraphically\r\nTo see this information graphically, you can use the function\r\nsctr from the package EMbC.\r\nLL - Resting - in orange\r\nLH - Intense foraging - in red\r\nHL - Travelling - in light blue\r\nHH - Relocating - in dark blue\r\n\r\n\r\nsctr(Data_bc)\r\n\r\n\r\n\r\nTo see how the track looks according to the classification you can\r\nuse the view function from the package EMbC.\r\n\r\n\r\nEMbC::view(Data_bc)\r\n\r\n\r\n\r\nExport delimiters\r\nTo export the delimiters you can extract information into a data\r\nframe and rename the columns.\r\n\r\n\r\nClass_bc<-as.data.frame(Data_bc@R)\r\nnames(Class_bc)<-c('velocity.min','radian.min','velocity.max','radian.max')\r\n\r\n\r\nOriginally, the values of velocity are in m/s, therefore you can\r\nconvert them to km/h to compare with the literature more easily.\r\n\r\n\r\nClass_bc$velomin_km<-Class_bc$velocity.min*3.6\r\nClass_bc$velomax_km<-Class_bc$velocity.max*3.6\r\n\r\n\r\nYou can use the function write_csv to export the\r\ndelimiters.\r\nIn the example below, I use the function here and\r\ndefine the folder where I want the file to be.\r\n\r\n\r\nlibrary(here)\r\nDatosFolder<-here::here(\"01Datos\")\r\nwrite_csv(\r\n  Class_bc,\r\n  file=paste0(DatosFolder,'/Behavioural_delimiters.csv'))\r\n\r\n\r\nTracking data\r\nBehaviors\r\nYou can add the information of velocity and turning angle into you\r\nGPS data.\r\n\r\n\r\nData$Beha<-Data_bc@A\r\n\r\n\r\nIt returns numbers which correspond to:\r\n1 - LL - Resting\r\n2 - LH - Intense foraging\r\n3 - HL - Travelling\r\n4 - HH - Relocating\r\n5 - Unknown\r\nIf you want to add a column explaining what this numbers mean you can\r\nuse the following functions.\r\n\r\n\r\nlibrary(dplyr)\r\n\r\n\r\n\r\n\r\nData<-mutate(Data, Beha_class = ifelse(Data$Beha == \"1\", \"LL\",\r\n                                        ifelse(Data$Beha == \"2\", \"LH\",\r\n                                               ifelse(Data$Beha == \"3\", 'HH',\r\n                                                      ifelse(Data$Beha == \"4\", \"HL\", \r\n                                                             \"Unknown\")))))\r\n\r\n\r\nor\r\n\r\n\r\nData<-mutate(Data, Behaviour = ifelse(Data$Beha == \"1\", \"Resting\",\r\n                                        ifelse(Data$Beha == \"2\", \"Intense foraging\",\r\n                                               ifelse(Data$Beha == \"3\", 'Travelling',\r\n                                                      ifelse(Data$Beha == \"4\", \"Relocating\", \r\n                                                             \"Unknown\")))))\r\n\r\n\r\nVelocity\r\nYou can add the velocity in a column of your GPS data frame.\r\n\r\n\r\nhead(Data_bc@X)\r\n\r\n\r\nVelocity is in the first column, therefore we use the [,1]. Also, to\r\ntransform it to km/h multiply per 3.6.\r\n\r\n\r\nData$Velocity_ms<-Data_bc@X[,1]\r\nData$Velocity_kmh<-Data$Velocity_ms*3.6\r\n\r\n\r\nHeading direction\r\nHeading direction is on the second column, therefore we use the\r\n[,2].\r\n\r\n\r\nData$HeadingDirection<-Data_bc@X[,2]\r\n\r\n\r\nCheck\r\nFinally you can check the range to coincide with your delimiters.\r\n\r\n\r\nData %>% \r\n  group_by(Behaviour) %>%\r\n  summarise(Velo_min=min(Velocity_kmh),\r\n            Velo_max=max(Velocity_kmh),\r\n            Angle_min=min(HeadingDirection),\r\n            Angle_max=max(HeadingDirection))\r\n\r\n\r\nPlot\r\nYou can plot the GPS tracking data according to their behaviours\r\nusing the function ggplot\r\n\r\n\r\nggplot(data = Data, \r\n           aes(x=lon, y = lat))+\r\n  geom_point(aes(colour = Behaviour))+\r\n  theme_bw()+\r\n  theme(legend.position = \"bottom\") +\r\n   labs(x = \"Longitude\", y=\"Latitude\")+\r\n  ggtitle('Fig. Tracks')\r\n\r\n\r\nFurther\r\nIf you are not satisfied with the classification and the delimiters,\r\nyou can set your own behavioural classification using the turning angle\r\nand velocity.\r\nFor example, using data from Mendez et al 2017.\r\n\r\n\r\nData<-mutate(Data, New_beha = ifelse(Data$Velocity_kmh >= 0 & \r\n                                      Data$Velocity_kmh <= 4 &\r\n                                      Data$HeadingDirection >= 0 &\r\n                                      Data$HeadingDirection <= 0.30, \r\n                                      \"Resting\",\r\n                               ifelse(Data$Velocity_kmh >= 0 & \r\n                                      Data$Velocity_kmh <= 14 &\r\n                                      Data$HeadingDirection >= 0.30 &\r\n                                      Data$HeadingDirection <= 3.14, \r\n                                      \"IntenseForaging\",\r\n                                ifelse(Data$Velocity_kmh >= 4 & \r\n                                      Data$Velocity_kmh <= 90 &\r\n                                      Data$HeadingDirection >= 0 &\r\n                                      Data$HeadingDirection <= 0.31, \r\n                                      \"Travelling\",\r\n                                ifelse(Data$Velocity_kmh >= 14 & \r\n                                      Data$Velocity_kmh <= 90 &\r\n                                      Data$HeadingDirection >= 0.31 &\r\n                                      Data$HeadingDirection <= 3.14, \r\n                                      \"Relocating\",\r\n                                    \"Unknown\")))))\r\n\r\n\r\n\r\n\r\nggplot(data = Data, \r\n           aes(x=lon, y = lat))+\r\n  geom_point(aes(colour = New_beha))+\r\n  theme_bw()+\r\n  theme(legend.position = \"bottom\") +\r\n   labs(x = \"Longitude\", y=\"Latitude\")+\r\n  ggtitle('Fig. Tracks')\r\n\r\n\r\nReferences and\r\nrecommended literature\r\nEMbC\r\nGarriga\r\net al. 2016\r\nVignette\r\nBoobies\r\nLerma et\r\nal. 2020\r\nMendez et\r\nal. 2017\r\nOther Species\r\nConnectedPapers\r\nAlternative options\r\nHidden\r\nMarkov Models\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-11-25-embc/blog6.jpg",
    "last_modified": "2023-04-11T13:28:26+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-27-gitgithub/",
    "title": "Git & Github",
    "description": "A short intro.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2021-10-27",
    "categories": [
      "R",
      "Git",
      "English",
      "Y2021"
    ],
    "contents": "\r\n\r\n\r\n\r\nIntro\r\nIn this presentation, we will have a short intro on:\r\n- Git\r\n- Github\r\n- Reproducibility\r\n- Git+Github\r\n- Naming things\r\n⚡⚡⚡\r\n\r\n\r\n\r\n\r\n Open presentation\r\n\r\n⚡⚡⚡\r\nKeen to learn more?\r\nHappy git:\r\nHappy Git by Jennifer Bryan\r\nTutorials\r\nRLadiesFreiburg\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-10-27-gitgithub/portada1.jpg",
    "last_modified": "2023-04-11T13:19:00+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-09-24-home-range-adehabitathr/",
    "title": "Home Range & adehabitatHR",
    "description": "Export polygons generated from adehabitat.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2021-09-24",
    "categories": [
      "R",
      "Biologging",
      "English",
      "Y2021"
    ],
    "contents": "\r\nIntro\r\nIn this post, you will learn how to:  - Calculate UDs from test\r\ndata from Masked boobies.  - Calculate UDs using adehabitat.  -\r\nExport UDs as shapefiles to visualize in other programs. \r\nNote that reference system must be adjusted, also\r\nhref can be adapted.\r\nData\r\nLoad data. This test data is from masked boobies.  To access the\r\ndata you have to install the package sula:\r\ndevtools::install_github(“MiriamLL/sula”)\r\n\r\n\r\n#devtools::install_github(\"MiriamLL/sula\")\r\nlibrary(sula)\r\nData<-(GPS_raw)\r\n\r\n\r\nYou can use the structure of the data to organize your data\r\nsimilarly. It also works with csv data (if you have excel data you can\r\nalso save it as csv data an import it to R)\r\nTransform to spatial.\r\nYou can use the package sp to transform your data\r\nframe to spatial data (in this case you end up with\r\nSpatialPointsDataFrame). This way you can tell R that\r\nyou have coordinates. If you dont have the package sp you need to\r\ninstall it.\r\n\r\n\r\n#install.packages('sp')\r\nlibrary(sp)\r\nDataSp<-as.data.frame(Data)\r\ncoordinates(DataSp) <- c(\"Longitude\", \"Latitude\")\r\nclass(DataSp)\r\n\r\n[1] \"SpatialPointsDataFrame\"\r\nattr(,\"package\")\r\n[1] \"sp\"\r\n\r\nKernel adehabitat\r\nIf you dont have the package adehabitat you have to install it. I\r\nstrongly encourage you to read the vignette, here is the link..\r\n\r\n\r\n#install.packages('adehabitatHR')\r\nlibrary(adehabitatHR)\r\nDataUD<-kernelUD(DataSp[,3],h='href') #3 is for the ID  #Here I am using the reference h value\r\nimage(DataUD)\r\n\r\n\r\n\r\nNow you have a object class estUDm as a result.\r\n\r\n\r\nclass(DataUD)\r\n\r\n[1] \"estUDm\"\r\n\r\nThe function getvertices calculates the polygon. You\r\ncan adjust the percent, here I stated 95%.\r\n\r\n\r\nDataUD_pol <- getverticeshr(DataUD, percent = 95, unout = c(\"m2\"))\r\n\r\n\r\nOne individual\r\nYou can select the data from one individual to create individual\r\nUDs.\r\n\r\n\r\nGPS01<-subset(Data,Data$IDs=='GPS01')\r\n\r\n\r\nAs before, you transform the data frame to SpatialPointsDataFrame and\r\ncalculate the kernels using the reference value.\r\n\r\n\r\nhead(GPS01)\r\n\r\n   Latitude Longitude    DateGMT  TimeGMT   IDs\r\n1 -27.20097 -109.4531 02/11/2017 17:05:30 GPS01\r\n2 -27.20084 -109.4531 02/11/2017 17:09:35 GPS01\r\n3 -27.20053 -109.4529 02/11/2017 17:13:50 GPS01\r\n4 -27.20092 -109.4531 02/11/2017 17:17:59 GPS01\r\n5 -27.20065 -109.4529 02/11/2017 17:22:13 GPS01\r\n6 -27.20061 -109.4528 02/11/2017 17:26:25 GPS01\r\n\r\nGPS01Sp<-as.data.frame(GPS01)\r\ncoordinates(GPS01Sp) <- c(\"Longitude\", \"Latitude\")\r\nproj4string(GPS01Sp) <- CRS(\"+proj=utm +zone=12 +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs\")\r\nGPS01UD=kernelUD(GPS01Sp,h=\"href\") # Using reference\r\nGPS01UD\r\n\r\n********** Utilization distribution of an Animal ************\r\n\r\nType: probability density\r\nSmoothing parameter estimated with a  href parameter\r\nThis object inherits from the class SpatialPixelsDataFrame.\r\nSee estUD-class for more information\r\n\r\nYou can check the h value used with the following\r\nline. This is important because it can be adjusted and you should state\r\nit while describing your methods.\r\n\r\n\r\nGPS01UD@h\r\n\r\n$h\r\n[1] 0.02096601\r\n\r\n$meth\r\n[1] \"href\"\r\n\r\nThe most common home ranges calculations are the 50% and the\r\n95% areas. Here are some lines to obtain those polygons.\r\n\r\n\r\nGPS01UD95HR<-getverticeshr(GPS01UD,percent=95)\r\nGPS01UD50HR<-getverticeshr(GPS01UD,percent=50)\r\n\r\n\r\nHere you can check on you polygons visually.\r\n\r\n\r\nplot(GPS01UD95HR, col='yellow')\r\nplot(GPS01UD50HR, col='green', add=TRUE)\r\n\r\n\r\n\r\nExport\r\nI advice to first identify which folder do you want to use to save\r\nyour polygons. I have an Rproject and I have created a folder named GIS\r\nwhere I want my polygons to be.\r\n\r\n\r\nlibrary(here)\r\nhere()\r\nGISFolder<-paste0(here())\r\n\r\n\r\nThere are many ways to export your polygons.\r\nOne is using the package rgdal which comes from\r\nGeospatial Data Abstraction Library.\r\n\r\n\r\n#install.packageS('rdgal')\r\nlibrary(rgdal)\r\nwriteOGR(GPS01UD95HR, dsn = GISFolder, layer = 'GPS01HR95', driver = \"ESRI Shapefile\")\r\n\r\n\r\nThe other way to export your polygons is using the package\r\nsf. However, to be able to export your polygons, they\r\nshould be transform to a sf object.\r\n\r\n\r\nlibrary(sf)\r\nclass(GPS01UD95HR)\r\nGPS01SF95<-st_as_sf(GPS01UD95HR)\r\nst_write(GPS01SF95, paste0(here(), \"/\", \"GPS01SF95.shp\"))\r\n\r\n\r\n… and thats it.\r\nHopefully now you have your shapefiles that can be open in any GIS\r\nsoftware such as QGIS.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-09-24-home-range-adehabitathr/blog1.jpg",
    "last_modified": "2023-04-11T13:20:04+02:00",
    "input_file": {}
  },
  {
    "path": "posts/bls7/",
    "title": "BLS7",
    "description": "Diel foraging behaviour of Humboldt penguins *Spheniscus humboldti* at Tilgo Island, Northern Chile.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2021-09-23",
    "categories": [
      "Presentation",
      "English"
    ],
    "contents": "\r\nIntro\r\nThis post is dedicated to the poster and presentation for the Bio-Logging Symposium (https://www.bls7hawaii.com)\r\nDiel foraging behaviour of Humboldt penguins Spheniscus humboldti at Tilgo Island, Northern Chile\r\n⚡⚡⚡⚡\r\n\r\n Preview poster\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n⚡⚡⚡⚡\r\nAuthors\r\nMiriam Lerma1, Camila P. Villavicencio2, Nicolas Luna3, Matías Portflitt-Toro3, Juan Serratosa3,4, Guillermo Luna-Jorquera3, Stefan Garthe1, Rene Quispe5,6\r\nResearch and Technology Center (FTZ), University of Kiel, Hafentörn 1, 25761 Büsum, Germany. Link\r\nInstituto de Ecología y Biodiversidad, Departamento de Ciencias Ecológicas, Universidad de Chile, Las Palmeras 3425, Ñuñoa, Santiago, Chile. Link\r\nMillennium Nucleus for Ecology and Sustainable Management of Oceanic Islands - ESMOI, Larrondo 1281, Coquimbo, Chile. Link\r\nBirdLife International, The David Attenborough Building, Pembroke Street, Cambridge, CB2 3QZ, UK\r\nDepartamento de Biología Marina, Facultad de Ciencias del Mar, Universidad Católica del Norte, Larrondo 1281, Coquimbo, Chile. Link\r\nFacultad de Ciencias Agropecuarias, Universidad Pedro de Valdivia, Av. Cuatro Esquinas 60, La Serena, Chile\r\nReferences\r\nDe La Puente, S., Bussalleu, A., Cardeña, M., Valdés-Velásquez, A., Majluf, P. & Simeone, A. 2020. Humboldt Penguin (Spheniscus humboldti). Birds of the World 269–287. Link\r\nVianna, J. A. Cortes M., Ramos, B., Sallaberry, N., González-Acuña, D.,Dantas, G.P.M., Morgante, J., Simeone, A., Luna-Jorquera, G. Changes in abudance and distribution of Humboldt penguin Spheniscus humboldti. Mar. Ornithol. 42: 153-159. Link\r\nDantas, G.P.M., Oliveira, L.R., Santos, A.M., Flores, M.D., De Melo, D.R., Simeone, A., González-Acuña, D., Luna-Jorquera, G., Le Bohec, C., Valdés-Velásquez, A., Cardeña, M., Morgante, J.S. & Vianna, J.A. 2019. Uncovering population structure in the Humboldt penguin (Spheniscus humboldti) along the Pacific coast at South America. PLoS One 14: 1–19. Link\r\nQuispe, R., Lerma, M., Serratosa, J. & Luna-Jorquera, G. 2020. Foraging ranges of Humboldt penguins Spheniscus humboldti from Tilgo Island: the critical need for protecting a unique marine habitat. Mar. Ornithol. 48: 205–208. Link\r\nNavigation route of proposed industrial project at Tilgo Island by Oceana\r\nHerling, C., Culik, B.M. & Hennicke, J.C. 2005. Diet of the Humboldt penguin (Spheniscus humboldti) in northern and southern Chile. Mar. Biol. 147: 13–25. Link\r\nKaltenberg, A.M. & Benoit-Bird, K.J. 2009. Diel behavior of sardine and anchovy schools in the California Current System. Mar. Ecol. Prog. Ser. 394: 247–262. Link\r\nTaylor, J.C., Rand, P.S. & Jenkins, J. 2007. Swimming behavior of juvenile anchovies (Anchoa spp.) in an episodically hypoxic estuary: implications for individual energetics and trophic dynamics. Mar. Biol. 152: 939–957. Link\r\nHumboldt penguin call by Carlos Pinto xeno-canto\r\nAcknowledgments\r\nThis study was financed by Fondecyt (grant no. 3170936 to RQ and postdoctorate grant no. 3160679 to CPV) and by CONACyT-INAPI (grant no. 411876 to ML).\r\nWe thank Esther Rickert for the transportation of tracking devices, and Henri Kröling for useful discussions.\r\nThis study was carried out in accordance with the recommendations and permit of the Subsecretaria de Pesca y Acuicultura de Chile (resolution N°3367/2017).\r\n\r\n\r\n\r\n",
    "preview": "posts/bls7/Penguin2.jpg",
    "last_modified": "2022-12-04T12:36:32+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-07-05-GIScolores/",
    "title": "Colores en mapas",
    "description": "Cambiar colores en un en un mapa en ggplot2 y en QGIS.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2021-07-05",
    "categories": [
      "GIS",
      "R",
      "Español",
      "Y2021"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nMapa 🌎\r\nDescargar datos\r\nMapa base\r\nAgregar un sitio\r\nAgregar varios sitios\r\n\r\nQGIS 🗺️\r\n\r\nIntro\r\n\r\n\r\n\r\nEste post es acerca de como crear un mapa base de México, incluir\r\npuntos para sitios de muestreo y cambiar los colores de puntos en un\r\nmapa en ggplot y en QGIS.\r\nMapa 🌎\r\nPara crear y modificar mapas siguiendo las instrucciones de este post\r\nnecesitamos los siguientes paquetes:\r\n\r\n\r\nlibrary(raster)\r\nlibrary(sf)\r\nlibrary(ggplot2)\r\nlibrary(ggspatial)\r\n\r\n\r\nSi no los tienes instalados usa la función install.packages()\r\nExisten shapefiles disponibles para México que se pueden descargar\r\ndirectamente en R.  - Para descargar los shapefiles, el paquete\r\nraster cuenta con la función getData. \r\nPara crear un mapa:  - El paquete sf es la que\r\nutilizaremos para el manejo de los shapefiles.  - El\r\npaqueteggplot2 es crear las visualizaciones. - El\r\npaquete ggspatial para agregar la escala.\r\nDescargar datos\r\nLo primero seria descargar los datos usando la función getData. \r\nUna vez cargados los datos, podemos hacer una selección de los estados\r\nque nos interesen. \r\n\r\n\r\nMexico<- getData('GADM', country='Mexico', level=1) %>% st_as_sf()\r\nQueretaro <- Mexico[Mexico$NAME_1 == \"Querétaro\",]\r\nGuanajuato <- Mexico[Mexico$NAME_1 == \"Guanajuato\",]\r\n\r\n\r\nMapa base\r\nPara crear un mapa centrado en estos estados se puede usar el\r\nsiguiente código:\r\n\r\n\r\nMapaBase<-ggplot()+\r\n  geom_sf(data= Mexico, fill='#264653', col='black')+\r\n  geom_sf(data= Queretaro, fill='#2a9d8f')+ #para resaltar estados\r\n  geom_sf(data= Guanajuato, fill='#2a9d8f')+ #para resaltar estados\r\n  \r\n  annotation_north_arrow(location=\"tr\",which_north=\"true\",style=north_arrow_fancy_orienteering ())+ #Norte\r\n  ggspatial::annotation_scale(location = \"bl\",bar_cols = c(\"grey60\", \"white\"))+ #Escala\r\n\r\n  theme_bw()+\r\n  coord_sf(xlim = c(-105,-95), #limites del mapa\r\n           ylim = c(18 ,24), #limites del mapa\r\n           expand = FALSE)\r\nMapaBase\r\n\r\n\r\n\r\nDentro de geom_sf el argumento fill es el color con\r\nel que se rellenaran los polígonos, lo puedes cambiar a como más te\r\nguste. En el mapa use códigos hexa-númericos que pueden ser encontrados\r\nen coolors, para más instrucciones ve\r\naquí\r\nAgregar un sitio\r\nAhora para agregar sitios, se deben especificar las coordenadas. En\r\nel ejemplo el argumento geom_point x y\r\ny son las coordenadas. En color elegí el color que le\r\nquiero dar a ese punto y lo escribí como código hexa-númerico (hex).\r\n\r\n\r\nMapaSitios<-MapaBase+geom_point(aes(x=-100, y=21, \r\n                                    color='#e63946'))+ #elegir el color\r\n  theme(legend.position='none') #evitar la etiqueta\r\nMapaSitios\r\n\r\n\r\n\r\nAgregar varios sitios\r\nOtra opción es que si tienes muchos puntos, es más práctico crear o\r\ncargar un data frame.\r\n\r\n\r\nDatosInventados<-data.frame(long=c(-102,-101,-100,-99,-98),\r\n           lat=c(21.5,21.3,20.9,21,20))\r\n\r\n\r\nPuedes concatenar varios códigos hex y crear tu propia paleta\r\n\r\n\r\npaleta<-c(\"#f8ffe5\",\"#06d6a0\",\"#1b9aaa\",\"#ef476f\",\"#ffc43d\")\r\n\r\n\r\nAgregar la paleta a las especificaciones del gráfico es dentro de\r\ngeom_point, en color. Para hacer los puntos más grandes\r\ntambién puedes agregar el argumento size en\r\ngeom_point\r\n\r\n\r\nMapaSitios<-MapaBase+\r\n  geom_point(data=DatosInventados,aes(x=long, y=lat,color=paleta),size=3)+ \r\n  theme(legend.position='none') #evitar la etiqueta\r\nMapaSitios\r\n\r\n\r\n\r\nPara exportar el mapa, ve aquí\r\nQGIS 🗺️\r\nAhora, para cambiar colores en QGIS.\r\nPrimero asumiré que tienes cargados tus datos en QGIS. Una vez\r\ncargados los datos, elige la capa, y ve a propiedades o\r\nproperties.\r\n\r\n\r\n\r\n\r\n\r\n\r\nAhora dale click en symbology. En la parte superior\r\nelige categorized, elige en value la\r\ncolumna de los nombres de los sitios o algo que los distinga entre\r\nsi.\r\n\r\n\r\n\r\nDale enter al botón de classify. Dale Ok.\r\n\r\n\r\n\r\nAhora debes tener la opción de cambiar los colores de cada\r\npunto.\r\nDale click izquierdo y elige Edit symbol.\r\n\r\n\r\n\r\nAhora puedes darle doble click en el color y en la parte que dice\r\nhtml notation cambiarle el código hexagecimal por el\r\nque te interesa, puedes buscarlo en coolors.\r\n\r\n\r\n\r\nY listo!\r\n\r\n🥳\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-07-05-GIScolores/blog2.jpg",
    "last_modified": "2023-04-11T13:17:57+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-06-03-paquetes/",
    "title": "Paquetes",
    "description": "Como crear tu primer paquete con datos y algunas funciones.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2021-06-03",
    "categories": [
      "R",
      "Español",
      "Package",
      "Y2023"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\n1.1. Nombrar el paquete ✏️\r\n1.2. Iniciar un paquete 👩🏽‍🔧️\r\n1.3. Archivos 📄📂️\r\n1.4. Git & Github 🐱🐙\r\n1.4. devtools ⏳\r\n1.5. Licencia 📋\r\n1.6. metadata ☎️\r\n1.7. README 🏗️\r\n\r\n2. Datos 💾\r\n2.1. Documentar datos\r\n2.2. Resumido\r\n2.3. Actualizaciones\r\n\r\n3. Funciónes 🤸🏾‍\r\n3.1. Función sin\r\ndependencias\r\n3.2. Funciones con\r\ndependencia\r\n3.3. Otros problemas 👻\r\n3.4. Resumido\r\n\r\nOtros\r\n4.1 Warnings ⚠️\r\n4.2. Crear tu propio sticker\r\n❣️\r\n4.3. Zenodo 🔗\r\n\r\nCréditos y recursos 👩🏽‍🏫\r\n\r\nIntro\r\n\r\n\r\n\r\nPara crear un paquete principalmente hay que saber crear\r\nfunciones.\r\nPero ¿Porque crear un paquete? 🤔\r\nAlgunas razones: \r\nRepito pasos y análisis con datos similares, hasta ahora re-uso\r\nfunciones de scripts anteriores. \r\nEstudiantes y colegas me preguntan como realizar análisis similares,\r\npero no están familiarizados con la sintaxis de las funciones\r\n\r\nLos artículos me piden más detalles de como se realizaron los\r\nanálisis y el espacio es limitado para dar detalles.\r\nAunque existan paquetes similares no cubren todos los pasos,\r\nsirven de inspiración pero no resuelven el problema.\r\n1.1. Nombrar el paquete ✏️\r\nPara crear paquetes se puede usar el paquete\r\nusethis\r\n\r\n\r\n#install.packages('usethis')\r\nlibrary(usethis)\r\n\r\n\r\nAntes de iniciar a crear un paquete, se puede consultar si el nombre\r\nno esta siendo usando en otro paquete en la página CRAN. También existe el paquete\r\navailable para revisar si el paquete ya existe en CRAN\r\no en github y si el nombre del paquete puede ser ofensivo.\r\n\r\n\r\ninstall.packages('available')\r\nlibrary(available)\r\navailable(\"nombre_paquete\")\r\n\r\n\r\nTe va preguntar si quieres que revise por contenido ofensivo, puedes\r\nponer Y.\r\n\r\nUrban Dictionary can contain potentially offensive results,\r\n  should they be included? [Y]es / [N]o:\r\n\r\nDespués abre paginas para mostrar que significa el nombre de el\r\npaquete.\r\n1.2. Iniciar un paquete 👩🏽‍🔧️\r\nPara crear un paquete la función create_package crea\r\nel esqueleto de los paquetes.  Dentro puedes poner\r\nel nombre del paquete que te interesa crear.\r\n\r\n\r\nusethis::create_package(\"nombre_paquete\")\r\n\r\n\r\nAparecerá algo así:\r\n\r\n√ Creating 'nombre_paquete/'\r\n√ Setting active project to '...'\r\n√ Creating 'R/'\r\n√ Writing 'DESCRIPTION'\r\nPackage: nombre_paquete\r\nTitle: What the Package Does (One Line, Title Case)\r\nVersion: 0.0.0.9000\r\nAuthors@R (parsed):\r\n    * First Last <first.last@example.com> [aut, cre] (YOUR-ORCID-ID)\r\nDescription: What the package does (one paragraph).\r\nLicense: `use_mit_license()`, `use_gpl3_license()` or friends to\r\n    pick a license\r\nEncoding: UTF-8\r\nLazyData: true\r\nRoxygen: list(markdown = TRUE)\r\nRoxygenNote: 7.1.1\r\n√ Writing 'NAMESPACE'\r\n√ Writing 'nombre_paquete.Rproj'\r\n√ Adding '^nombre_paquete\\\\.Rproj$' to '.Rbuildignore'\r\n√ Adding '.Rproj.user' to '.gitignore'\r\n√ Adding '^\\\\.Rproj\\\\.user$' to '.Rbuildignore'\r\n√ Opening '...' in new RStudio session\r\n√ Setting active project to '<no active project>'\r\n\r\nNota: Si te encuentras dentro de un\r\nproyecto va a preguntar si deseas sobregrabar el\r\nproyecto existente. Si es el caso: 2: Absolutely\r\n\r\nv Writing 'NAMESPACE'\r\nOverwrite pre-existing file 'nombre_paquete.Rproj'?\r\n\r\n1: Not now\r\n2: Absolutely\r\n3: No way\r\n\r\nAparecerá algo como:\r\n\r\nv Writing 'nombre_paquete.Rproj'\r\nv Adding '^nombre_paquete\\\\.Rproj$' to '.Rbuildignore'\r\nv Adding '^\\\\.Rproj\\\\.user$' to '.Rbuildignore'\r\nv Opening '...' in new RStudio session\r\nv Setting active project to '<no active project>'\r\n\r\nSe abrirá el proyecto en otra ventana.\r\n1.3. Archivos 📄📂️\r\nLa función anterior creó los archivos:\r\n- .gitignore  - .Rbuildignore - DESCRIPTION - NAMESPACE\r\n- README.md\r\nLas Carpetas: - R\r\n1.4. Git & Github 🐱🐙\r\nSi ya tienes instalado git puedes directamente conectar el paquete\r\ncon tu repositorio, escribiendo en tu consola:\r\n\r\n\r\nusethis::use_git()\r\n\r\n\r\nAparecerá algo como:\r\n\r\n√ Setting active project to '...'\r\n√ Adding '.Rdata', '.httr-oauth', '.DS_Store' to '.gitignore'\r\nThere are 6 uncommitted files:\r\n '.gitignore'\r\n '.Rbuildignore'\r\n 'DESCRIPTION'\r\n 'NAMESPACE'\r\nIs it ok to commit them?\r\n\r\n1: Absolutely not\r\n2: Yup\r\n3: Negative\r\n\r\n3: Yup… es si\r\nAparecerá algo como:\r\n\r\n√ Adding files\r\n√ Making a commit with message 'Initial commit\r\n A restart of RStudio is required to activate the Git pane\r\nRestart now?\r\n1: Yup\r\n2: No\r\n3: Not now\r\n\r\nSi deseas reiniciar RStudio para activar git:\r\n1: Yup… es sip\r\nSe reiniciara la sesión\r\nPara ahora conectarlo con github, hay que escribir\r\nen la consola:\r\n\r\n\r\nusethis::use_github()\r\n\r\n\r\nAparecerá algo como:\r\n\r\ni Defaulting to https Git protocol\r\n√ Setting active project to 'C:/...'\r\n√ Checking that current branch is default branch ('master')\r\n√ Creating GitHub repository '...'\r\n√ Setting remote 'origin' to 'https://github.com/...git'\r\n√ Setting URL field in DESCRIPTION to 'https://github.com/...'\r\n√ Setting BugReports field in DESCRIPTION to 'https://github.com/...'\r\nThere is 1 uncommitted file:\r\n 'DESCRIPTION'\r\nIs it ok to commit it?\r\n1: No\r\n2: No way\r\n3: I agree\r\n\r\nSi es correcto elegir 3: I agree, que significa de acuerdo\r\nAparecerá algo como:\r\n\r\n√ Adding files\r\n√ Making a commit with message 'Add GitHub links to DESCRIPTION'\r\n√ Pushing 'master' branch to GitHub and setting 'origin/master' as upstream branch\r\n√ Opening URL 'https://github.com/...'\r\n\r\nAbrirá github\r\n1.4. devtools ⏳\r\nEscribir en la consola\r\n\r\n\r\ndevtools::check()\r\n\r\n\r\nEsta función revisa la versión, plataforma, sesiones y demás.\r\nTarda un poquito.\r\n\r\n0 errors √ | 1 warning x | 0 notes √\r\n\r\nEl warning ocurre porque hay que darle una licencia\r\nal paquete.\r\n\r\nNon-standard license specification:\r\n    `use_mit_license()`, `use_gpl3_license()` or friends to pick a\r\n    license\r\n  Standardizable: FALSE\r\n\r\n1.5. Licencia 📋\r\nPara software la licencia más común es MIT\r\n\r\n\r\nusethis::use_mit_license(\"Mi Nombre\")\r\n\r\n\r\nAparecerá algo como:\r\n\r\n√ Setting License field in DESCRIPTION to 'MIT + file LICENSE'\r\n√ Writing 'LICENSE'\r\n√ Writing 'LICENSE.md'\r\n√ Adding '^LICENSE\\\\.md$' to '.Rbuildignore'\r\n\r\nPara revisar si funcionó:\r\n\r\n\r\ndevtools::check()\r\n\r\n\r\nTarda un poquito.\r\n\r\n0 errors √ | 0 warning √ | 0 notes √\r\n\r\n1.6. metadata ☎️\r\nPara agregar metadata se debe abrir y modificar el documento que dice\r\nDESCRIPTION, agregando tus datos.\r\nEsta es la información de contacto si hay problemas con el\r\npaquete.\r\n\r\n\r\nAuthors@R:\r\n  person(given = \"Miriam\",\r\n         family = \"Lerma\",\r\n         role = c(\"aut\", \"cre\"),\r\n         email = \"miriamjlerma@gmail.com\",\r\n         comment = c(ORCID = \"0000-0002-7632-9289\"))\r\n\r\n\r\n1.7. README 🏗️\r\nPara crear un nuevo README, el paquete usethis tiene\r\nuna función para crearlo de manera automática,\r\n\r\n\r\nlibrary(usethis)\r\nuse_readme_rmd(open = rlang::is_interactive())\r\n\r\n\r\n\r\n√ Setting active project to '...'\r\n√ Writing 'README.Rmd'\r\n√ Adding '^README\\\\.Rmd$' to '.Rbuildignore'\r\n Modify 'README.Rmd'\r\n√ Writing '.git/hooks/pre-commit'\r\n\r\n2. Datos 💾\r\nPara agregar datos en tu paquete, puedes cargar tus datos y después\r\nguardarlos dentro de tu proyecto. \r\n\r\n\r\n\r\nPor convención los datos son colocados en una carpeta que lleve el\r\nnombre de data dentro del paquete.  Puedes crear\r\nesta carpeta desde RStudio abriendo la pestaña de Files\r\ny eligiendo New Folder. \r\nPara comprimir datos pesados puedes guardarlos como\r\n.rda.\r\n\r\n\r\nsave(TDR_raw, file=\"TDR_raw.rda\")\r\n\r\n\r\nPara revisar el peso de los datos puedes usar:\r\n\r\n\r\nobject.size(TDR_raw)\r\n\r\n\r\n\r\n\r\npryr::mem_used()\r\n\r\n\r\n2.1. Documentar datos\r\nPara documentar tus datos, puedes abrir un nuevo script\r\n(File>NewFile>R Script) o usar la función del paquete\r\nusethis.\r\nTanto la función use_r como use_data funcionan.\r\n\r\n\r\nusethis::use_r(\"mis_datos\")\r\nusethis::use_data(\"mis_datos\")\r\n\r\n\r\nEsta función agrega comentarios Roxigen y guarda el documento en tu\r\nfolder llamado R.  En mi caso yo le di al script el\r\nmismo nombre que a los datos.\r\n\r\n\r\n#' Mis datos son datos de...\r\n#' Contiene 264197 obs de 1 variable.\r\n#' @docType data\r\n#' @usage data(mis_datos)\r\n#' @format Un data frame con 1 variable\r\n#' @keywords datasets\r\n#' @references Lerma et al. 2021\r\n#' @examples\r\n#' data(mis_datos)\r\n\"mis_datos\"\r\n\r\n\r\nUna vez creado el archivo .rda y .R\r\nse puede revisar si funcionó usando funciones del paquete\r\ndevtools\r\n\r\n\r\ndevtools::check()\r\n\r\n\r\nSi los datos son muy pesados y te aparece un mensaje como este:\r\n\r\nNote: significantly better compression could be obtained\r\n          by using R CMD build --resave-data\r\n\r\nEs mejor agregar el argumento compress.\r\n\r\n\r\nsave(TDR_raw, file=\"TDR_raw.rda\", compress = \"xz\")\r\n\r\n\r\n2.2. Resumido\r\nAgrega datos al paquete\r\n\r\n\r\nsave(mis_datos, file=\"mis_datos.rda\")\r\n\r\n# Tu objeto, tu documento rda y tu R deben tener el mismo nombre. \r\n\r\nusethis::use_r(\"mis_datos\")\r\n\r\n#Insertar Roxigen Skeleton  (CTRL+ALT+SHIFT+R) o copiar y pegar de otro archivo\r\n\r\ndevtools::document()\r\n\r\ndevtools::check()\r\n\r\n\r\nSi después de usar devtools::check(), aparece:\r\n\r\n0 errors √ | 0 warnings √ | 0 notes √\r\n\r\nYa tienes tu primer paquete con datos 🥳.\r\nPara instalar el paquete de manera local\r\n\r\n\r\ndevtools::install(\"C:/....\")\r\n\r\n\r\nPara instalar el paquete desde github\r\n\r\n\r\ndevtools::install_github(\"Desarrollador/paquete\")\r\n\r\n\r\n2.3. Actualizaciones\r\nRData\r\nSi aparece el mensaje WARNING: Added dependency on R >= 3.5.0\r\nbecause serialized objects in serialize/load version 3 cannot be read in\r\nolder versions of R.  Hay que usar .RData\r\n\r\n\r\nsave(TDR_raw, file = \"TDR_raw.RData\", version = 2)\r\n\r\n\r\nLazyData Tambien tener cuidado de incluir en\r\nDESCRIPTION\r\n\r\n\r\nLazyData: true\r\n\r\n\r\nIf LazyData DB of 21.3 MB without LazyData Compression set\r\nAgregar\r\n\r\n\r\nLazyDataCompression:xz\r\n\r\n\r\nIf checking data for ASCII and uncompressed saves … Warning: package\r\nneeds dependence on R (>= 2.10)\r\nIn DESCRIPTION:\r\n\r\nDepends: R (>= 2.10)\r\n\r\nPara poder usar directamente los datos\r\n3. Funciónes 🤸🏾‍\r\nPara este paso deberías tener alguna función en mente.\r\nSi aún no sabes como crear tu primera función puedes ir a r4ds.\r\nLa estructura es algo así:\r\n\r\n\r\nnombre_de_la_funcion<-function(argumentos){\r\n  algo_que_haga_la_funcion_usando(argumentos)\r\n  return(resultado)\r\n}\r\n\r\n\r\n3.1. Función sin dependencias\r\nPara agregar la función al paquete.\r\n\r\n\r\nusethis::use_r(\"mi_primera_funcion\")\r\n\r\n\r\nAbre un nuevo script\r\nPega allí la función\r\nAparecerá algo como:\r\n\r\n√ Setting active project to 'C:/...'\r\n Modify 'R/mi_primera_funcion.R'\r\n Call `use_test()` to create a matching test file\r\n\r\nAhora en la carpeta R aparecerá dentro la función\r\nAgregar un Roxigen skeleton:  - Poner el cursor justo en la\r\nprimera linea de la función.  - Abrir la pestaña de Code>Insert\r\nReoxygen Skeleton (también funciona con Control+Alt+Shift+R). \r\nAparecerá algo como:\r\n\r\n\r\n#' Title\r\n#'\r\n#' @param data \r\n#' @param trip_start \r\n#' @param trip_end \r\n#'\r\n#' @return\r\n#' @export\r\n#'\r\n#' @examples\r\n\r\n\r\nDespués de rellenar la información necesaria, para agregar la función\r\nal paquete, escribe en la consola:\r\n\r\n\r\ndevtools::document()\r\n\r\n\r\nAparecerá algo como:\r\n\r\nWriting NAMESPACE\r\nWriting mi_primera_funcion.Rd\r\n\r\nAl abrir la carpeta man aparecerá un documento\r\nrellenado.\r\nEl nombre man viene de manual y esta es la\r\ndocumentación del paquete.\r\nNo debe ser editado de manera manual.\r\nYa puedes revisar la documentación.\r\n\r\n\r\n?mi_primera_funcion\r\n\r\n\r\n\r\n\r\ndevtools::check()\r\n\r\n\r\n3.2. Funciones con dependencia\r\nTe recomiendo probar tu función con datos de ejemplo, antes de\r\nincluirla en el paquete.\r\nRevisa que paquetes son requeridos, por ejemplo:\r\ntidyr\r\n\r\n\r\n\r\nDefine los argumentos por separado como objeto.\r\n\r\n\r\ndata=misdatos\r\nmi_primer_argumento='mi_primer_argumento'\r\nmi_segundo_argumento='mi_segundo_argumento'\r\n\r\n\r\nPrueba la función\r\n\r\n\r\nmi_funcion(data = mis_datos,\r\n           mi_primer_argumento='mi_primer_argumento',\r\n           mi_segundo_argumento='mi_segundo_argumento')\r\n\r\n\r\nOtra opción es usar el paquete ‘testthat’ para probar tu\r\nfunción.\r\nPara agregar la función al paquete:\r\n\r\n\r\nusethis::use_r(\"tu_funcion\")\r\n\r\n\r\nAbre un nuevo script. Pega allí la función. En la\r\nconsola aparecerá algo como:\r\n\r\n Modify 'R/tu_funcion.R'\r\n Call `use_test()` to create a matching test file\r\n\r\nAhora en la carpeta R dentro del paquete aparece la\r\nfunción.Nota sugiere que uses use_test pero puede en conflicto\r\ncon el siguiente paso.\r\nPuedes usar /rm() para quitar tu función.\r\nPara poner la función en la memoria local y confirmar que se ejecute\r\nhay que incluirla en el paquete y probarla.\r\n\r\n\r\ndevtools::load_all()\r\n\r\n\r\nPara documentar la función hay que crear un Roxigen skeleton.\r\nPara esto se debe poner el cursor justo en la primera linea de la\r\nfunción.\r\nDespués ir a la pestaña de Code>Insert Reoxygen Skeleton (tambíen\r\nfunciona con Control+Alt+Shift+R).\r\nVa a aparecer algo así:\r\n\r\n\r\n#' Title\r\n#'\r\n#' @param data \r\n#' @param mi_primer_argumento \r\n#' @param mi_segundo_argumento \r\n#'\r\n#' @return\r\n#' @export\r\n#'\r\n#' @examples\r\n\r\n\r\nNota que identifica de manera automática las\r\nvariables de la función\r\nAhora que ya esta la función y la documentación para agregar el\r\npaquete hay que escribir en la consola:\r\n\r\n\r\ndevtools::document()\r\n\r\n\r\nAparece:\r\n\r\nWriting NAMESPACE\r\nWriting mi_funcion.Rd\r\n\r\nAhora en la carpeta man, aparece un documento\r\nrellenado.man viene de manual y esta es la documentación del\r\npaquete.\r\nNota No debe ser editado de manera manual.\r\nPuedes revisar la documentación de la función.\r\n\r\n\r\n?mi_funcion\r\n\r\n\r\nDependencias son paquetes necesarios para que la función,\r\nfuncione.\r\nPara revisar si necesitas dependencias se puede usar:\r\n\r\n\r\ndevtools::check()\r\n\r\n\r\nSi tu paquete tiene dependencias, aparecerán errores, warnings y\r\nnotas.\r\nPor ejemplo, un paquete que usa: - un %>% (pipe)\r\ndepende del paquete magrittr, y - la función\r\nseparate depende del paquete\r\ndplyr.\r\nPara agregar las dependencias se puede escribir el nombre de los\r\npaquetes dentro de la función use_package\r\n\r\n\r\nusethis::use_package(\"dplyr\")\r\n\r\n\r\nAparecerá algo como:\r\n\r\n√ Adding 'dplyr' to Imports field in DESCRIPTION\r\n Refer to functions with `dplyr::fun()`\r\n\r\nAsí mismo aparecerá en el documento DESCRIPTION:\r\n\r\n\r\nImports: \r\n    dplyr\r\n\r\n\r\nLo siguiente es especificar el paquete en la función, tal como\r\nrecomienda el siguiente mensaje.\r\n\r\n Refer to functions with `dplyr::fun()`\r\n\r\npipe 🖇️\r\nLa función pipe (%>%) del paquete magrittr es\r\nespecial.\r\nPor lo que hay que usar:\r\n\r\n\r\nusethis::use_pipe()\r\n\r\n\r\nAparecerá algo como:\r\n\r\n√ Adding 'magrittr' to Imports field in DESCRIPTION\r\n√ Writing 'R/utils-pipe.R'\r\n Run `devtools::document()` to update 'NAMESPACE'\r\n\r\nSe recomienda volver a documentar.\r\n\r\n\r\ndevtools::document()\r\n\r\n\r\nAhora deberá aparecer en la carpeta R un script llamado\r\nutils-pipe.R y\r\nen el archivo DESCRIPTION deberá aparecer Imports\r\nmagrittr\r\nPara checar el paquete:\r\n\r\n\r\ndevtools::check()\r\n\r\n\r\n\r\n0 errors √ | 0 warnings √ | 0 notes √\r\n\r\nListo! el paquete esta completo 🥳\r\nstats 🧮\r\nCuando queremos agregar alguna función que incluya cálculos de\r\ndesviación estándar, aunque no se necesite cargar el paquete en RStudio,\r\nla función proviene de un paquete.\r\nEl paquete es stats\r\nPor lo tanto el paquete stats debe ser incluido en\r\nlas dependencias.\r\n\r\n\r\nusethis::use_package(\"stats\")\r\n\r\n\r\nY agregado a la función.\r\n\r\n\r\nresultado<- data %>%\r\n    dplyr::summarise(max_depth_mean=mean(.data[[var1]]),\r\n                     max_depth_sd=stats::sd(.data[[var1]]),\r\n                     max_depth_max=max(.data[[var1]]))\r\n\r\n\r\n\r\n\r\ndevtools::document()\r\ndevtools::check()\r\n\r\n\r\n\r\n\r\ndevtools::check()\r\n\r\n\r\n\r\n0 errors √ | 0 warnings √ | 0 notes √\r\n\r\nListo! el paquete esta completo 🥳\r\nggplot 🎨\r\nCuando creamos una función con ggplot hay que declarar el uso de la\r\nfunción en varios argumentos de la función. Aquí\r\npuedes leer más.\r\nSi no, aparecerá un error:\r\n\r\n1 error x | 0 warnings √ | 1 note x\r\n\r\nEsto occurre debido a que al revisar el paquete, no detecta varias\r\nfunciones del paquete ggplot.\r\n\r\nno visible global function definition for 'aes'\r\n\r\nEjemplo:\r\n\r\n\r\nggplot2::ggplot(data=data,ggplot2::aes(x=.data[[var1]],\r\n                              y=as.numeric(.data[[var2]])))+\r\n    ggplot2::geom_line()+\r\n    ggplot2::ylab(\"Diving depth (m)\")+\r\n    ggplot2::xlab(\"Month.Day Hour:Minute\")+\r\n    ggplot2::scale_y_reverse()+\r\n    ggplot2::theme_bw()\r\n\r\n\r\n\r\nchecking R code for possible problems ...\r\n\r\nTambién pueden aparecer problemas con las variables al usar ggplot\r\ndentro de una función.\r\n\r\nno visible binding for global variable '.data'\r\n\r\nPara resolver esto hay que declarar las variables dentro de la\r\nfunción y posteriormente usar .data\r\n\r\ndata<-TDR_trip\r\nvar1<-time_column\r\nvar2<-depth_column\r\n  \r\nggplot2::ggplot(data,\r\n                ggplot2::aes(x=.data[[var1]],\r\n                             y=.data[[var2]))+\r\n    ggplot2::geom_line()\r\n\r\n\r\n\r\ndevtools::document()\r\ndevtools::check()\r\n\r\n\r\n\r\n\r\ndevtools::check()\r\n\r\n\r\n\r\n0 errors √ | 0 warnings √ | 0 notes √\r\n\r\nListo! el paquete esta completo 🥳\r\n3.3. Otros problemas 👻\r\nProblema En algunas funciones puedes haber usado\r\nassign. Usar assign no es recomendado, por lo que aparecerá una nota.\r\nSolución Usar return().\r\nProblema No nested functions, no circular\r\ndependencies. Solución No puedes usar funciones de\r\ntu paquete en otras funciones del mismo paquete. \r\nProblema Borrar funciones.Solución Para borrar funciones se debe borrar el script\r\nen el archivo R y volver a documentar el paquete para que se reflejen\r\nlos cambios.\r\nProblema El ejemplo tiene más de 100 caracteres, es\r\nconsiderado muy largo. Solución Separar en la\r\ndocumentación.\r\n\r\n\\examples lines wider than 100 characters:\r\n\r\nProblema Solo puedo tener un resultado (return) Solución Crea una lista con los returns. Por\r\nejemplo:\r\n\r\nfuncion(primer_argumento, segundo_argumento){\r\n  multiplicacion<-primer_argumento*segundo_argumento\r\n  suma<-primer_argumento+segundo_argumento\r\n  lista<-(list(\"multiplicacion\"=multiplicacion,\"suma\"=suma))\r\n  return(lista)\r\n}\r\n\r\nProblema Al usar slot en sapply.Solución Hay que agregar la dependencia\r\nmethods.\r\n3.4. Resumido\r\n\r\n\r\nusethis::use_r(\"nombre_funcion\")\r\n\r\n#Insertar Roxigen Skeleton  (CTRL+ALT+SHIFT+R)\r\n\r\ndevtools::document()\r\n\r\ndevtools::check()\r\n\r\nusethis::use_package(\"ggplot2\")\r\n\r\n#Referirse a funciones con ::\r\n\r\ndevtools::check()\r\n\r\n\r\nOtros\r\n4.1 Warnings ⚠️\r\nEs útil agregar warnings para que el usuario (quien sera a veces tu\r\nmismo) pueda corregir errores.\r\nPara checar que el data frame contenga datos, revisa que el numero de\r\nfilas no sea cero.\r\n\r\n\r\n if (nrow(data)!=0){\r\n  } else {\r\n    warning(\"Please check the name of the data frame\")\r\n  }\r\n\r\n\r\nTambién puedes revisar si tu data frame contiene una columna de\r\nacuerdo a su nombre\r\n\r\n\r\nif (\"Nombre_columna\" %in% colnames(data)){\r\n  } else {\r\n    warning(\"Please check that your data frame has X column, otherwise please rename/create the column\")\r\n  }\r\n\r\n\r\nAdemas podemos revisar si una columna en especifico aparece en el\r\ndata frame\r\n\r\n\r\nif (!is.null(data[[columna]])) {\r\n  } else {\r\n    warning(\"The column X is not in your dataframe. Please check the name of the column\")\r\n  }\r\n\r\n\r\n️\r\n4.2. Crear tu propio sticker ❣️\r\nPara crear un hexSticker puedes usar plantillas:  - En powerpoint\r\nplantilla hecha por\r\nEmi Tanaka  - En R paquete hexSticker\r\nhecho por GuangchuangYu\r\nPara instalar el paquete hexSticker, puedes descargarlo desde en\r\nCRAN:\r\n\r\n\r\ninstall.packages(\"hexSticker\")\r\n\r\n\r\n4.3. Zenodo 🔗\r\nZenodo es un repositorio de acceso\r\nabierto operado por CERN (Organización Europea para la Investigación\r\nNuclear).\r\nVentajas Permite que se depositen allí artículos de\r\ninvestigación, datos, software, informes y otro tipo de objeto digital\r\nrelacionado con la investigación. La ventaja frente a github es que\r\nasigna un DOI.\r\nDesventajas Las versiones de paquetes se pueden\r\nregistrar en zenodo. No obstante, NO es tan practico ya que cada versión\r\ntiene su propio DOI y la versión anterior no puede ser eliminada.\r\nCréditos y recursos 👩🏽‍🏫\r\nPaquetes\r\nusethis\r\ntestthat\r\nLibros\r\nR Packages \r\nR Packages 2e\r\nTutoriales sobre datos \r\nIncluir datos \r\nDocumentar datos \r\nTu paquete en una hora \r\nPiping hot data\r\nVideos\r\nRladies como crear funciones\r\nRladies como crear paquetes\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-06-03-paquetes/blog3.jpg",
    "last_modified": "2023-03-28T11:59:27+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-06-03-vitae/",
    "title": "CV",
    "description": "Como crear un curriculo en RStudio usando el paquete vitae.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2021-06-02",
    "categories": [
      "R",
      "Español",
      "Y2021"
    ],
    "contents": "\r\n\r\nContents\r\nIntro\r\nDescargar el paquete 🕯️\r\nIniciar con una plantilla\r\n🧶\r\nTus datos 💾\r\nPartes de tu CV 💭\r\nAgregar tu información ✏️\r\nTus publicaciones 👩🏽‍🔬\r\nHabilidades 🤸🏽‍️\r\nColores de las letras 👩🏾‍🎨\r\nResumiendo ✔️\r\nCréditos y recursos 👩🏾‍🏫\r\n\r\nIntro\r\nPara crear un CV en RStudio, básicamente necesitas saber Rmd.\r\nPara los básicos de Rmd te recomiendo ir aquí.\r\nSi quieres ver como quedo mi cv, puedes descargarlo aquí.\r\nDescargar el paquete 🕯️\r\nPara crear tu CV puedes descargar el paquete vitae\r\ndesde github.\r\n\r\n\r\n# install.packages(\"devtools\")\r\ndevtools::install_github(\"mitchelloharawild/vitae\")\r\n\r\n\r\nPara ver detalles ésta es la página.\r\nNota Al instalar el paquete se tarda descargando\r\nactualizaciones.\r\nIniciar con una plantilla 🧶\r\nFile>NewFile>R Markdown>From template\r\nPara elegir la plantilla (template), en la página puedes ver algunos\r\nejemplos.\r\nPero si no te decides, se puede modificar en el output del YAML\r\ndespués.\r\nAl elegir tu plantilla, se abrirá un nuevo Rmd. Antes de empezar a\r\nrellenar tu CV, te recomiendo probar tener todos las dependencias\r\ninstaladas. Para esto, dale en knit.\r\nTal vez tengas que instalar de nuevo tinytext.\r\n\r\nError: LaTeX failed to compile Untitled.tex. \r\nSee https://yihui.org/tinytex/r/#debugging for debugging tips.\r\n\r\nPara instalarlo:\r\n\r\n\r\ntinytex::install_tinytex()\r\n\r\n\r\nTus datos 💾\r\nLa información que incluyas en el YAML aparecerá en la parte superior\r\nde tu CV.\r\nLa plantilla te da un archivo prellenado, que debes modificar de\r\nacuerdo a tus datos.\r\n\r\n---\r\nname: Marie\r\nsurname: Curie\r\nposition: \"Professor\"\r\naddress: \"School of Physics & Chemistry, École Normale Supérieure\"\r\nphone: +1 22 3333 4444\r\nwww: mariecurie.com\r\nemail: \"Marie.Curie@ens.fr\"\r\ntwitter: mariecurie\r\ngithub: mariecurie\r\nlinkedin: mariecurie\r\ndate: \"`r format(Sys.time(), '%B %Y')`\"\r\noutput: \r\n  vitae::latexcv:\r\n    theme: classic\r\n---\r\n\r\nSi al darle knit te esta causando muchos problemas con LaTex, te\r\nrecomiendo cambiar el output a awesomecv y poner keep_tex en false.\r\n\r\n\r\noutput: \r\n  vitae::awesomecv:\r\n    keep_tex: false\r\n\r\n\r\nPartes de tu CV 💭\r\nDepende para que sea tu CV puedes estructurarlo de manera\r\ndiferente.\r\nSi quieres un CV académico te puedes basar en la estructura del CV de\r\nHan\r\nZhang.\r\nEste CV contiene\r\n- Research interest\r\n- Education\r\n- Peer-reviewed Publications\r\nAgregar tu información ✏️\r\nPara agregar las partes a tu CV, la información se maneja como tribble\r\nUnas de las funciones de vitae es\r\ndetailed_entries, que es como sera mostrada la\r\ninformación en tu pdf, otra opción es brief_entries que\r\npresenta un formato más compacto.\r\nPara llenar un tribble:\r\n\r\n\r\ntribble(\r\n  ~Year, ~Type, ~Desc,\r\n  \"2021-current\", \"Postdoc\", \"Universidad de Kiel\",\r\n  \"2020-2021\",\"Postdoc\",\"Universidad de Kiel\"\r\n) %>% \r\n  detailed_entries(\r\n    glue::glue(\"Trabajos {Type}\"),\r\n    Year, \r\n    Desc\r\n  )\r\n\r\n\r\nTus publicaciones 👩🏽‍🔬\r\nPara agregar publicaciones puedes el archivo .bib\r\ncon tus datos. Si quieres aprender como extraer las citas, te recomiendo\r\nmirar aquí\r\n\r\n\r\nlibrary(dplyr)\r\nknitr::write_bib(c(\"vitae\", \"tibble\"), \"papers.bib\")\r\n\r\nbibliography_entries(\"papers.bib\") %>%\r\n  arrange(desc(author$family), issued)\r\n\r\n\r\nNo obstante, si tus publicaciones incluyen acentos y letras\r\ncursivas. Entonces puede ser más practico usar tribble y\r\ndetailed_entries.\r\nPara agregar letras negritas o cursivas la sintaxis es:\r\n\r\n\\\\textit{} #italicas\r\n\\\\textbf{} #negritas\r\n\r\nEjemplo:\r\n\r\n\r\ntribble(\r\n ~ Year, ~ Place, ~ Project, ~ Position,\r\n\r\n \"2020\",\r\n  \"\\\\textbf{Lerma, M}, Serratosa J, Luna-Jorquera G, Garthe S\",\r\n  \"Foraging ecology of masked boobies \\\\textit{(Sula dactylatra)} in the world’s largest ‘oceanic desert’\",\r\n  \"Mar Biol 167: 87\"\r\n \r\n ) %>% \r\n  detailed_entries(Place, \r\n                   Position,\r\n                   Project, \r\n                   Year,\r\n                   .protect = FALSE)\r\n\r\n\r\nEs importante poner protect en FALSE para que aparezcan los\r\ncambios.\r\nHabilidades 🤸🏽‍️\r\nPara incluir tus habilidades puede que no quieras tener una lista con\r\nmucho espacio vacío. Una opción para evitar esto es crear una tabla\r\nparecida a la que aparece en el CV de Lorena Abad.\r\n\r\n\r\nSkills<-tribble(\r\n   ~Computer, ~Laboratory, ~Fieldwork,~ Languages,\r\n  \"R -- Statistica -- SPSS -- Sigmaplot -- QGIS -- Git -- Markdown\",\r\n  \"Heavy metal analyses -- Stable isotopes -- Plasma metabolites analyses\",\r\n  \"Catching and handling wild animals -- Sample collection: extraction blood & feathers -- Censing populations -- Monitoring breeding success\",\r\n  \"Spanish (Mother tongue) -- English (TOEFL iBT 99) -- German (Basic-A2)\"\r\n)\r\n\r\n\r\n\r\n\r\nSkills %>%\r\n  kbl(booktabs = T, align =\"c\",format = \"latex\") %>% #crea tabla y alinea al centro\r\n  column_spec(column = 1:4, width = '4cm')%>%        #separa las columnas en 4 y las hace de 4 cm\r\n  row_spec(0, bold = T, color = \"#009acd\") %>%       #hace las letras en negrita y cambia el color\r\n  row_spec(1, bold = F, color = \"#7f7f7f\")           #cambia el color del texto a gris\r\n\r\n\r\nPara que no aparezcan las lineas en la tabla, se puede agregar en el\r\nYAML:\r\n\r\n  \\usepackage{colortbl}\r\n  \\arrayrulecolor{white}\r\n\r\nColores de las letras 👩🏾‍🎨\r\nPara cambiar el color del texto se puede ajustar en el YAML.\r\n\r\nheadcolor: 009ACD\r\n\r\nResumiendo ✔️\r\nvitae es una buena opción para crear tu CV y solo se\r\ntiene que hacer la estructura una vez, que además resulta mas atractiva\r\na la vista. No obstante puede traer muchos errores por LaTex.\r\nCréditos y recursos 👩🏾‍🏫\r\n\r\n\r\n\r\nEjemplos\r\nLorenaAbad\r\nHan Zhang\r\nGalería\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-06-03-vitae/blog4.jpg",
    "last_modified": "2023-04-11T13:17:09+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-06-03-paginadistill/",
    "title": "Pagina distill",
    "description": "Como crear tu propia pagina y agregar contenidos.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2021-06-01",
    "categories": [
      "R",
      "Español"
    ],
    "contents": "\r\n\r\nContents\r\nCrear un sitio 👩🏽‍💻\r\nBarra de navegación ⛵\r\nCrear un post 📬\r\nEscribir en el post ✏️\r\nAgregar código 👩🏽‍💻\r\nCSS 👩🏽‍🎨\r\nCitas 🌹\r\nAgregar botones 🛎️\r\nBuild 🔨\r\nDe Rstudio a online 👩🏽‍🚀\r\nCréditos y recursos 🚀\r\n\r\n\r\nCrear un sitio 👩🏽‍💻\r\n\r\n\r\n\r\nPara crear una pagina web usando distill, básicamente necesitas saber\r\nRmd.\r\nEmpecemos por instalar el paquete distill.\r\n\r\n\r\n#install.packages(\"distill\")\r\nlibrary(distill)\r\n\r\n\r\nTienes que preguntarte: ¿Que tipo de página quieres hacer? ¿Sitio web\r\no blog?\r\nPara cualquiera de las opciones puedes ir a File>New Project>\r\nDistill Website o Distill Blog\r\nVer\r\notros detalles\r\nLa estructura del sitio contiene varios archivos\r\nLa configuración del sitio: site.yml\r\nLa primera página que se abre cuando entras:\r\nindex.Rmd\r\nOtros Rmd donde puedes escribir sobre tí. Ej.\r\nabout.Rmd\r\nBarra de navegación ⛵\r\nPara modificar la barra de navegación, abre el archivo\r\nsite.yml  Puedes elegir donde quieres que aparezcan\r\nlos contenidos. Ej. al elegir left aparecerán a la\r\nizquierda.\r\nPara agregar pestañas agrega text y\r\nhref. Pon atención a los espacios vacios. \r\n\r\nnavbar:\r\n  left: \r\n    - text: \"Home\"\r\n      href: index.html\r\n    - text: \"Projects\" \r\n      href: projects.html\r\n    - icon: fab fa-twitter\r\n      href: https://twitter.com/MiriamLermaL\r\n    - icon: fab fa-github\r\n      href: https://github.com/MiriamLL\r\n\r\nCrear un post 📬\r\nUsa la función create_post y escribe dentro el nombre que quieras\r\ndarle a tu post.\r\n\r\n\r\nlibrary(distill)\r\ncreate_post(\"Nombre de tu post\")\r\n\r\n\r\nAparecerá algo como:\r\n\r\nv Created post at _posts/2021-05-14-Nombre de tu post\r\n\r\nY te abrirá un nuevo Rmd.\r\nVer\r\nUwe’s blog para otros detalles\r\nEscribir en el post ✏️\r\nPuedes abrir el Rmd que creaste usando la función create_post y\r\nescribir como en cualquier Rmd.\r\nLa información en el yaml aparecerá en el indice de la pestaña.\r\n\r\n---\r\ntitle: \"sula\"\r\ndescription: |\r\n  A short description of the post.\r\nauthor:\r\n  - name: Miriam Lerma\r\n    url: {}\r\ndate: 05-14-2021\r\noutput:\r\n  distill::distill_article:\r\n    self_contained: false\r\n---\r\n\r\nAgregar código 👩🏽‍💻\r\nPara agregar código en tu post y que no salga por otro lado el\r\ntitulo, texto y código hay que tener espacios entre ellos.\r\n\r\n\r\nTitulo\r\n\r\nTexto\r\n\r\nChunk\r\n\r\n\r\nCSS 👩🏽‍🎨\r\nEn el paquete distill puedes usar la función create_theme, y poner el\r\nnombre que le quieres dar al archivo.\r\n\r\n\r\ncreate_theme(\"mi_estilo\")\r\n\r\n\r\nTe va a crear un archivo css que puedes modificar para cambiar el\r\naspecto de tu página. Una vez creado y/o modificado, debes incluirlo en\r\nsite.yml.\r\n\r\n\r\noutput: \r\n  distill::distill_article:\r\n    theme: mi_estilo.css\r\n\r\n\r\nPuedes cambiar el estilo de las letras,\r\ny los colores.\r\nVer\r\nmás recursos de estilos.\r\nCitas 🌹\r\nPara que aparezcan o no las citas, hay que abrir el\r\nsite.yml y escribir:\r\n\r\n\r\ncollections:\r\n  posts:\r\n    citations: false\r\n\r\n\r\nAgregar botones 🛎️\r\nSe pueden agregar botones en la página para los enlaces. Para la\r\ninspiración y fuente ve al sitio de Ella Kaye\r\nPara agregar botones, empieza por instalar el paquete distilltools\r\ndesde github.\r\n\r\n\r\n#remotes::install_github(\"EllaKaye/distilltools\")\r\nlibrary(distilltools)\r\n\r\n\r\nNota Si tienes algunos problemas con rlang, puedes\r\nintentar reiniciar sesión y reinstalar el paquete rlang.\r\nPara agregar iconos usa la función icon_link\r\n\r\n\r\nicon_link(icon = \"fas fa-images\",\r\n          text = \"slides\",\r\n          url = \"https://miriamll.github.io/Tutorial_distill_es/TutorialPaginaDistill\")\r\n\r\n\r\nPara elegir el icono, entrar a la pagina fontawesome:\r\n(1) Elige el icono; (2) Busca la información de html; (3) Copia lo que\r\nesta dentro de < y >.\r\nPara cambiar como se ven los botones, hay que especificarlo en el\r\ncss. Por ejemplo:\r\n\r\n.icon-link {\r\n    background-color: transparent;\r\n    color: #D40067;\r\n    border: 1px solid;\r\n    border-color: #D40067;\r\n    padding: 5px .4rem 5px .4rem;\r\n    /*margin: 4px;*/\r\n    margin-top: 4px;\r\n    margin-right: 8px;\r\n    margin-bottom: 4px;\r\n    border-radius: 5px; /* Rounded edges */\r\n}\r\n\r\n.icon-link:hover {\r\n    background-color: #D40067;\r\n    border-color: #D40067;\r\n    color: white;\r\n}\r\n\r\nBuild 🔨\r\nEn la pestaña donde tienes environment, history o git, debe aparecer\r\nuna nueva pestaña con el nombre de Build\r\nPuedes elegir esta pestaña, y darle click al martillo que dice Build\r\nWebsite para ver como quedo tu página.\r\nEn la pestaña Viewer… Ya puedes ver tu pagina distill 🥳.\r\nDe Rstudio a online 👩🏽‍🚀\r\nUno de los retos es poner tu pagina online.\r\nSe pueden subir los archivos directamente a: Netlify\r\nSe pueden subir los archivos a github, y conectarlo con\r\nNetlify.Recomendado porque puedes estar actualizando los\r\nmateriales desde RStudio.\r\nDe entrada, tu sitio sera tunombre.netlify.app. Si quieres que sea\r\ntunombre.com u otro, cuesta alrededor de 12 dolares, pero varia\r\nmucho.\r\nPublicar sitio por Lisa\r\nLendway\r\nCréditos y recursos 🚀\r\nTutoriales\r\nCrear articulo en distill\r\nCrear sitio\r\n(Re-)introducing Distill for R Markdown\r\nEjemplos de paginas\r\nBlogs\r\nGaleria\r\nPaso a paso: crear un sitio por Lisa Lendway\r\nVideos\r\nRLadies Crear un sitio por Lisa Lendway\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-06-03-paginadistill/blog5.jpg",
    "last_modified": "2022-11-25T13:41:29+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-05-14-spheniscus/",
    "title": "spheniscus",
    "description": "A package that provides functions to clean the TDR data and to obtain diving parameters from the sampled individuals. | \nUn paquete para limpiar datos de TDR y calcular parametros de buceo durante los viajes de alimentación.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2021-05-15",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntro\r\nInstalación\r\nDatos\r\nTDR_raw 📥\r\nTDR_dives 🤿\r\n\r\nFunciones\r\nextract_rawdata 🧹\r\nextract_trip ✂️\r\nplot_depth 🎨\r\ncorrect_zero 📐\r\nidentify_dives 🐟\r\ndive_parameters 🐧\r\n\r\nCitar\r\n\r\n\r\n\r\n\r\nIntro\r\nEl objetivo de este paquete es:\r\nHacer disponibles datos crudos de TDR para que se familiaricen con el formato.\r\nAyudarte a limpiar los datos de TDR para obtener parámetros de buceo de los animales muestreados.\r\n\r\n English\r\n\r\nInstalación\r\nEl paquete estará disponible solo por GitHub\r\n\r\n\r\ninstall.packages(\"devtools\")\r\ndevtools::install_github(\"MiriamLL/spheniscus\")\r\n\r\n\r\n\r\n\r\n\r\nlibrary(spheniscus)\r\n\r\n\r\n\r\nDatos\r\nTDR_raw 📥\r\nAgrega los datos crudos como objeto.\r\n\r\n\r\nTDR_raw<-TDR_raw\r\n\r\n\r\n\r\nLas columnas no están separadas ya que primero hay que cortar partes del archivo. \r\nTDR_dives 🤿\r\nIncluye todos los buceos durante el viaje. \r\n\r\n\r\nTDR_dives<-TDR_dives\r\n\r\n\r\n\r\nFunciones\r\nextract_rawdata 🧹\r\nExtrae la información de profundidad de los datos crudos de los dispositivos.  En los dispositivos TDR (Cefas G5+) la presión se empieza a medir después de ‘Data Block 1’ y termina de medir presión cuando empieza ‘Data Block 2’. Estos nombres fueron usados como separadores en row_start y row_end. Si tu dispositivo usa otros separadores como por ejemplo ‘Data Block 0’ hay que ajustar acorde.\r\n\r\n\r\nTDR_pressure<-extract_pressure(data=TDR_raw, \r\n                          row_start='Data Block 1', \r\n                          row_end = 'Data Block 2')\r\n\r\n\r\n\r\nextract_trip ✂️\r\nCorta periodos de tiempo de acuerdo a nuestro interés.  La información se obtuvo de dispositivos GPS, trip_start es cuando salieron de la colonia y trip_end cuando regresaron.\r\nLos datos fueron recortados para incluir sólo información durante el viaje de alimentación.\r\n\r\n\r\nTDR_trip<-extract_trip(data=TDR_pressure,\r\n                   timeformat=\"%d-%m-%Y %H:%M:%S\",\r\n                   trip_start=\"30-11-2018 20:43:24\",\r\n                   trip_end=\"01-12-2018 20:16:19\")\r\n\r\n\r\n\r\nplot_depth 🎨\r\nCrea un grafico con el perfil de buceos. Marca el cero con una linea roja.  El objetivo de este gráfico es que te permita decidir si debes corregir el cero.\r\n\r\n\r\nplot_depth(TDR_trip = TDR_trip,\r\n                   depth_column='Pressure',\r\n                   time_column='daytime')\r\n\r\n\r\n\r\n\r\ncorrect_zero 📐\r\nEsta función te permite corregir el cero usando un factor de corrección.  En el ejemplo, corregí el cero usando -0.80 m. Este valor fue ajustado de manera manual.\r\n\r\n\r\nTDR_corrected<-correct_zero(TDR_trip = TDR_trip,\r\n             depth_column='Pressure',\r\n             extra_correction=-0.80)\r\n\r\n\r\n\r\nPuedes volver a crear el gráfico para confirmar que se corrigió el cero.\r\n\r\n\r\nplot_depth(TDR_trip = TDR_corrected,\r\n            depth_column='corrected_depth',\r\n            time_column='daytime')\r\n\r\n\r\n\r\n\r\nidentify_dives 🐟\r\nEsta función identifica cada buceo como unidades individuales, y les asigna a cada inmersión un numero, una profundidad media de buceo, una profundidad máxima de buceo, una duración media de buceo y una duración máxima de buceo.\r\nEn el ejemplo, los buceos reales fueron considerados cuando el animal se encontraba más profundo de 3 metros.\r\n\r\n\r\nTDR_dives<-identify_dives(TDR_corrected=TDR_corrected,\r\n               real_dives=3,\r\n               depth_column='corrected_depth')\r\n\r\n\r\n\r\ndive_parameters 🐧\r\nEsta función calcula los parámetros del viaje completo.\r\nIncluye:\r\n- promedio de la profundidad máxima de buceo,\r\n- desviación estándar de la profundidad máxima de buceo,\r\n- el máximo de profundidad, la duración promedio de los buceos,\r\n- la desviación estándar de la duración de los buceos, y\r\n- la duración máxima de buceo, así como\r\n- el total de buceos durante el viaje.Nota La profundidad de buceo se da en metros, la duración en segundos.\r\n\r\n\r\ndive_parameters<-calculate_diveparams(TDR_dives)\r\n\r\n\r\n\r\n\r\nmax_depth_mean\r\nmax_depth_sd\r\nmax_depth_max\r\ndive_duration_mean\r\ndive_duration_sd\r\ndive_duration_max\r\nn_dives\r\n11.7163\r\n4.836995\r\n39.21\r\n18.86549\r\n7.438373\r\n41\r\n565\r\n\r\nCitar\r\nEste script acompaña una publicación en pingüinos por Lerma et al. (en preparación)\r\nPara dar atribución:\r\nLerma, M (2021). Package spheniscus (Version v1.0). Zenodo. http://doi.org/10.5281/zenodo.4709837\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-05-14-spheniscus/spheniscus-logo.png",
    "last_modified": "2023-02-23T13:35:03+01:00",
    "input_file": {},
    "preview_width": 460,
    "preview_height": 464
  },
  {
    "path": "posts/2021-05-14-sula/",
    "title": "sula",
    "description": "Functions to clean your data and calculate the foraging trip parameters of the individuals.  | Un paquete para editar datos de GPS y calcular parámetros de los viajes de alimentación.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2021-05-15",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntro\r\nInstalación 🤖\r\n\r\nDatos\r\nUn individuo 💃🏽\r\nMultiples individuos 👯‍\r\nNotas de campo ✏️\r\n\r\nFunciones\r\najustar_hora 🕐\r\nrecortar_periodo ✂️\r\nlocalizar_nido 🐣\r\nidentificar_viajes️🛩️\r\ncontar_viajes 🧮\r\ndist_colonia 📏\r\ndist_puntos 📐\r\ncalcular_duracion ⏳\r\ncalcular_totaldist 📐\r\ncalcular_maxdist 📏\r\ncalcular_tripparams 📐⏳📏\r\nrecortar_por_ID ✂️✂️✂️\r\nlocalizar_nidos 🐣🐣🐣\r\npreparar_varios 🔌🔌🔌\r\ntripparams_varios 📐📐📐\r\n\r\nOtras herramientas\r\nInterpolar tus viajes 🛠️\r\n\r\nCitar\r\n\r\n\r\n\r\n\r\nIntro\r\nEste paquete contiene:\r\nDatos de tracks de kena (Sula dactylatra) colectados en Rapa Nui para replicar los ejemplos 🗿\r\nTrece funciones para limpiar y calcular parámetros de viajes a partir de datos GPS\r\n\r\n English\r\n\r\nInstalación 🤖\r\nPuedes instalar este paquete desde GitHub usando:\r\n\r\n\r\n# install.packages(\"devtools\")\r\ndevtools::install_github(\"MiriamLL/sula\")\r\n\r\n\r\n\r\nDatos\r\nCarga la librería\r\n\r\n\r\nlibrary(sula)\r\n\r\n\r\n\r\nUn individuo 💃🏽\r\nCarga los datos de GPS de un individuo.\r\n\r\n\r\nhead(GPS_01)\r\n\r\n\r\n\r\nNota Incluye columna con fecha y hora en formato POSIXct\r\nMultiples individuos 👯‍\r\nCarga los datos de GPS de diez individuos.\r\n\r\n\r\nhead(GPS_raw)\r\n\r\n\r\n\r\nNota Son datos en crudo por lo que las horas no están corregidas.\r\nNotas de campo ✏️\r\nIncluye el periodo cuando se colocó el dispositivo hasta cuando se retiró.\r\n\r\n\r\nNotas<-Notas\r\n\r\n\r\n\r\nNota: no corresponden al periodo real de muestreo. Se proveen estos datos para practicar las funciones.\r\nFunciones\r\najustar_hora 🕐\r\nEsta función corrige el tiempo de acuerdo a la zona horaria, se necesita especificar los datos GPS, el nombre de la columna que contiene datos de hora y día, el formato en el que están éstos datos, y el número de horas de diferencia a corregir de acuerdo al GMT.\r\n\r\n\r\nGPS_gmt<-ajustar_hora(GPS_data = GPS_raw,\r\n                      dia_col = 'DateGMT',\r\n                      hora_col = 'TimeGMT',\r\n                      formato=\"%d/%m/%Y %H:%M:%S\",\r\n                      dif_hor = 5)\r\n\r\n\r\n\r\nRegresa el mismo data frame con dos columnas adicionales: dia_hora con el día y fecha original y hora_corregida con la hora correspondiente al GMT.\r\nrecortar_periodo ✂️\r\nEste función permite recortar periodos dentro de los datos.\r\n\r\n\r\nGPS_recortado<-recortar_periodo(GPS_data=GPS_01,\r\n                                inicio='02/11/2017 18:10:00',\r\n                                final='05/11/2017 14:10:00',\r\n                                dia_col='DateGMT',\r\n                                hora_col='TimeGMT',\r\n                                formato=\"%d/%m/%Y %H:%M:%S\")\r\n\r\n\r\n\r\nNota: El formato de tiempo y hora debe ser el mismo formato que el formato de inicio y final.\r\nlocalizar_nido 🐣\r\nEsta función usa el primer valor de los datos de GPS como punto de la colonia, sirve para identificar la localización del nido por individuo. Regresa un nuevo data frame con dos columnas: Latitude y Longitude correspondientes a la localización del nido.\r\n\r\n\r\nnest_loc<-localizar_nido(GPS_data = GPS_01,\r\n                          lat_col=\"Latitude\",\r\n                          lon_col=\"Longitude\")\r\n\r\n\r\n\r\nNota Asume que los datos del nido corresponde al primer registro de GPS.\r\nidentificar_viajes️🛩️\r\nEsta función agrega una columna de acuerdo a distancia de la colonia para determinar si esta en un viaje de alimentación o no.\r\n\r\n\r\nGPS_trip<-identificar_viajes(GPS_data=GPS_01,\r\n                        nest_loc=nest_loc,\r\n                        distancia_km=1)\r\n\r\n\r\n\r\nEn la columna llamada trip:N=dentro de la distancia considerada como no viaje de alimentación, yY=viaje de alimentación.\r\ncontar_viajes 🧮\r\nEsta función agrega una columna con el número del viaje y elimina locaciones dentro de el radio de la colonia.\r\n\r\n\r\nGPS_edited<-contar_viajes(GPS_data=GPS_trip)\r\n\r\n\r\n\r\ndist_colonia 📏\r\nAgrega una columna con la distancia de la colonia de cada punto. Regresa el mismo data frame con una nueva columna llamada ’maxdist_km.\r\n\r\n\r\nGPS_dist<-dist_colonia(GPS_edited = GPS_edited, \r\n                       nest_loc=nest_loc)\r\n\r\n\r\n\r\nNota usa CRS: 4326. Enlaces: ¿referencia geográfica?, ¿cual usar?\r\ndist_puntos 📐\r\nAgrega una columna con la distancia entre cada punto. Regresa el mismo data frame con una nueva columna llamada ‘pointsdist_km’.\r\n\r\n\r\nGPS_dist<-dist_puntos(GPS_data = GPS_edited,\r\n                      separador='trip_number')\r\n\r\n\r\n\r\nNota usa CRS: 4326. Incluye NAs al inicio del viaje. Enlaces: ¿referencia geográfica?, ¿cual usar?\r\ncalcular_duracion ⏳\r\nIdentifica el inicio y el final del viaje y calcula la duración. Regresa un nuevo data frame con 4 columnas: trip_id, trip_start, trip_end y duration.\r\n\r\n\r\nduracion<-calcular_duracion(GPS_data = GPS_edited,\r\n                            col_diahora = \"tStamp\",\r\n                            formato = \"%Y-%m-%d %H:%M:%S\",\r\n                            unidades=\"hours\",\r\n                            separador=\"trip_number\")\r\n\r\n\r\n\r\nNota la duración se calcula en valores númericos.\r\ncalcular_totaldist 📐\r\nCalcula distancia recorrida de la colonia por viaje.\r\nDebe contener la columna Longitude y Latitude con estos nombres.\r\nRegresa un nuevo data frame con la distancia total recorrida por viaje.\r\n\r\n\r\ntotaldist_km<-calcular_totaldist(GPS_data= GPS_edited,\r\n                                 separador=\"trip_number\")\r\n\r\n\r\n\r\ncalcular_maxdist 📏\r\nObtiene la distancia máxima de la colonia por viaje.\r\nDebe contener la columna Longitude y Latitude con estos nombres.\r\nRegresa un nuevo data frame con la distancia máxima de la colonia por viaje.\r\n\r\n\r\nmaxdist_km<-calcular_maxdist(GPS_data = GPS_edited, \r\n                             nest_loc=nest_loc,\r\n                             separador=\"trip_number\")\r\n\r\n\r\n\r\ncalcular_tripparams 📐⏳📏\r\nCalcula la duración de los viajes, la distancia máxima de la colonia y la distancia total recorrida. Regresa un nuevo data frame con los parámetros por viaje.\r\n\r\n\r\ntrip_params<-calcular_tripparams(GPS_data = GPS_edited,\r\n                              diahora_col = \"tStamp\",\r\n                              formato = \"%Y-%m-%d %H:%M:%S\",\r\n                              nest_loc=nest_loc,\r\n                              separador=\"trip_number\")\r\n\r\n\r\n\r\nrecortar_por_ID ✂️✂️✂️\r\nPuedes recortar periodos en los viajes.\r\nPara el ejemplo hay que tener dos data frames:\r\nUno con los datos de GPS incluyendo las columnas DateGMT,TimeGMT y IDs.\r\nSi no tienen estos nombres favor de renombrarlas.\r\nEl otro data frame son los datos de campo y deben incluir las columnas ‘IDs’, ‘Hora_inicio’ y ‘Hora_final’.\r\nSi no tienen esos nombres favor de renombrarlas.\r\n\r\n\r\nGPS_recortados<-recortar_por_ID(GPS_data=GPS_raw,\r\n                                Notas=Notas,\r\n                                formato=\"%d/%m/%Y %H:%M:%S\")\r\n\r\n\r\n\r\nlocalizar_nidos 🐣🐣🐣\r\nEsta función asume que los datos del nido corresponde al primer registro de GPS y regresa las coordenadas de los nidos para cada individuo.\r\n\r\n\r\nNidos_df<-localizar_nidos(GPS_data=GPS_raw,\r\n                         lon_col=\"Longitude\",\r\n                         lat_col=\"Latitude\",\r\n                         ID_col=\"IDs\")\r\n\r\n\r\n\r\npreparar_varios 🔌🔌🔌\r\nEsta función sirve para preparar los datos antes de calcular parámetros por individuo.\r\nEn la función debes especificar: el nombre de tu data frame, el nombre de la columna de los ID (identificadores por individuo), el nombre de la columna de la longitud y el nombre de la columna de la latitud. Para elegir los viajes elige un buffer de fuera de la colonia (distancia_km). Elige también tu sistema de referencia geográfica.\r\n\r\n\r\nGPS_preparado<-preparar_varios(GPS_data=GPS_raw,\r\n                               ID_col=\"IDs\",\r\n                               lon_col=\"Longitude\",\r\n                               lat_col=\"Latitude\",\r\n                               distancia_km=1,\r\n                               sistema_ref=\"+init=epsg:4326\")\r\n\r\n\r\n\r\nNota que al usar esta función aparecerán warnings. Estos warnings advierten sobre la transformación del objeto espacial.\r\nEnlaces: ¿referencia geográfica?, ¿cual usar?\r\ntripparams_varios 📐📐📐\r\nPara calcular parámetros de viajes de varios individuos especifica el nombre de la columna que contiene los identificadores por individuo, el nombre de la columna que contiene información número del viaje y el nombre de la columna que contiene información del día y hora en formato POSTIXct.\r\nNota para usar esta función tus datos deben tener una columna día y hora, si no es así, puedes hacerlo de manera manual o usar la función ajustar_hora de este paquete y poner 0 en la diferencia horaria.\r\n\r\n\r\nGPS_preparado<-ajustar_hora(GPS_data = GPS_preparado,\r\n                            dif_hor = 0,\r\n                            dia_col = 'DateGMT',\r\n                            hora_col = 'TimeGMT',\r\n                            formato=\"%d/%m/%Y %H:%M:%S\")\r\n\r\n\r\n\r\n\r\n\r\ntrip_params<-tripparams_varios(GPS_data=GPS_preparado,\r\n                               col_ID = \"IDs\",\r\n                               col_diahora=\"hora_corregida\",\r\n                               separador=\"trip_number\")\r\n\r\n\r\n\r\nOtras herramientas\r\nInterpolar tus viajes 🛠️\r\nSi tienes intervalos disparejos, y necesitas interpolar tus datos puedes establecer un intervalo Tu data frame debe contener las columnas Longitud, Latitud, ID, numero de viaje, y hora y dia en formato POSTIXct\r\n\r\n\r\nGPS_interpolated<-interpolar_viajes(GPS_preparado=GPS_preparado, \r\n                                    intervalo=\"900 sec\", \r\n                                    col_diahora=\"dia_hora\", \r\n                                    separador='trip_number',\r\n                                    col_ID='IDs')\r\n\r\n\r\n\r\nCitar\r\nLerma M (2021) Package sula. Zenodo. ttps://doi.org/10.5281/zenodo.4740920\r\nLos datos de prueba vienen de la publicación: Lerma M, Dehnhard N, Luna-Jorquera G, Voigt CC, Garthe S (2020) Breeding stage, not sex, affects foraging characteristics in masked boobies at Rapa Nui. Behavioral ecology and sociobiology 74: 149. 🔓\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-05-14-sula/sula-logo.png",
    "last_modified": "2023-02-23T13:35:03+01:00",
    "input_file": {},
    "preview_width": 454,
    "preview_height": 464
  },
  {
    "path": "posts/2021-04-28-otros/",
    "title": "Talleres diversos",
    "description": "Como crear tus propios paquetes, o como crear tu pagina web.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2021-04-28",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntro\r\n\r\nIntro\r\nHay varias maneras de aprender, aqui te muestro el formato de blog, donde puedes ver detalles en el texto, pero si estas en celular, que es frecuentemente mi caso, lo que hago es que\r\nTaller para crear tus propios paquetes.\r\n\r\n Presentación Descargar\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "https://raw.githubusercontent.com/MiriamLL/Desarrollo_paquetes/main/Figuras/Portada1.png",
    "last_modified": "2022-03-22T10:53:03+01:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-29-rmd/",
    "title": "Clase de Rmd",
    "description": "Desde como crear documentos en Rmd hasta como compartirlos.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2021-03-16",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nRmarkdown\r\nRmarkdown.\r\nRmarkdown para escribir artículos\r\nPresentar tus resultados usando Xaringan.\r\nEstilizar tus dispositivas Xaringan.\r\nGithub, Zenodo y Git.\r\nReproducibilidad.\r\n\r\n\r\n\r\n\r\n\r\nRmarkdown\r\nBienvenido!\r\nEste material fue preparado para técnicos y estudiantes de posgrado del Centro de Investigación de Alimentación y Desarrollo CIAD.\r\nNo obstante, espero sea de ayuda para cualquiera que tenga intenciones de aprender R.\r\nIré subiendo materiales conforme se vayan actualizando.\r\nRmarkdown.\r\nEn esta clase aprenderás como crear documentos en Rmd. \r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nRmarkdown para escribir artículos\r\nEn esta clase aprenderás como agregar citas y formato de revista. \r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nPresentar tus resultados usando Xaringan.\r\nEn esta clase aprenderás como crear presentaciones en Xaringan. Podrás incluir tablas y figuras sin salir de RStudio. \r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nEstilizar tus dispositivas Xaringan.\r\nEn esta clase aprenderás como cambiar el estilo de letras o colores de tus presentaciones en Xaringan. También aprenderás como compartirlas ya sea en github o en pdf. \r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nGithub, Zenodo y Git.\r\nEn esta clase aprenderás como crear un repositorio en github, como utilizar Zenodo para darle un DOI a nuestros materiales y los básicos de Git. \r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nReproducibilidad.\r\nEn esta clase verás básicos de reproducibilidad en la ciencia y en las publicaciones. \r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-29-rmd/rmd.png",
    "last_modified": "2022-12-04T12:36:32+01:00",
    "input_file": {},
    "preview_width": 1236,
    "preview_height": 927
  },
  {
    "path": "posts/2024-01-02-biologging/",
    "title": "Biologging",
    "description": "Desde como descargar tus datos de GPS, como cortar partes de interés, hasta hacer tus primeros gráficos con datos de tracking y exportarlos.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2021-02-16",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nBiologging\r\nDescargar tus datos.\r\nCorregir horas.\r\nEditar GPS.\r\n\r\n\r\nBiologging\r\nBienvenido!\r\nEste material fue preparado para estudiantes de posgrado de la Universidad de Guadalajara.\r\nNo obstante, espero sea de ayuda para cualquiera que tenga intenciones de aprender como manejar sus datos de GPS en R.\r\nIré subiendo materiales conforme se vayan actualizando.\r\nDescargar tus datos.\r\nEn esta clase aprenderás a descargar tus datos de GPS, unirlos y realizar tus primeras gráficas. \r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nCorregir horas.\r\nEn esta clase aprenderás a corregir la hora en tus datos de GPS de acuerdo a tu GMT. \r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nEditar GPS.\r\nEn esta clase aprenderás a cortar periodos de tiempo de tus datos GPS. \r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2024-01-02-biologging/biologging.png",
    "last_modified": "2023-04-11T10:30:24+02:00",
    "input_file": {},
    "preview_width": 1236,
    "preview_height": 927
  },
  {
    "path": "posts/2021-03-01-IntroaR/",
    "title": "Clase R desde cero",
    "description": "Desde como abrir R y RStudio hasta como exportar tus gráficos, la idea es que este curso te haga sentir cómodo trabajando tus datos y análisis en R.",
    "author": [
      {
        "name": "Miriam Lerma",
        "url": {}
      }
    ],
    "date": "2021-01-28",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nClase de R\r\nIntro a R.\r\nCargar tus datos.\r\nGráficos.\r\nOperaciones.\r\nOrdenar, unir y exportar.\r\nProyectos.\r\nModelo lineal simple.\r\nAnalisis de varianzas.\r\nModelos mixtos.\r\n\r\n\r\n\r\n\r\n\r\nClase de R\r\nBienvenido!\r\nEste material fue preparado para técnicos y estudiantes de posgrado del Centro de Investigación de Alimentación y Desarrollo CIAD.\r\nNo obstante, espero sea de ayuda para cualquiera que tenga intenciones de aprender R.\r\nIré subiendo materiales conforme se vayan actualizando.\r\nIntro a R.\r\nEn esta clase aprenderás a abrir RStudio e identificar sus partes. \r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nCargar tus datos.\r\nEn esta clase aprenderás a como cargar paquetes, seleccionar tu directorio y cargar tus datos en R. \r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nGráficos.\r\nEn esta clase aprenderás como funciona ggplot2 y como crear tus propios gráficos.\r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nOperaciones.\r\nEn esta clase aprenderás algunas funciones básicas para realizar operaciones matemáticas en R y como moverte entre tus columnas y filas. \r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nOrdenar, unir y exportar.\r\nEn esta clase aprenderás algunas funciones de tidyverse para poder ordenar tus columnas, limpiar tus datos, unir diferentes archivos y exportar tus nuevos data frames.\r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nProyectos.\r\nEn esta clase aprenderás porque es importante trabajar por proyectos, como crear y compartir un proyecto.\r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nModelo lineal simple.\r\nEn esta clase aprenderás como explorar tus datos, cuales son los argumentos para un modelo lineal simple en R y como agregar la linea de ajuste a tu gráfico.\r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nAnalisis de varianzas.\r\nEn esta clase aprenderás como convertir a factor, cuales son los argumentos para un análisis de varianza en R y como crear gráficos para visualizar tus resultados del análisis.\r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\nModelos mixtos.\r\nEsta clase es una introducción a los modelos mixtos y a la selección de modelos usando el AIC.\r\n\r\n\r\n \r\n Presentación Descargar\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-01-IntroaR/cursoR.png",
    "last_modified": "2022-12-04T12:36:32+01:00",
    "input_file": {},
    "preview_width": 1236,
    "preview_height": 927
  }
]
